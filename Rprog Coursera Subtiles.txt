1 - 1 - Installing R on Windows
[BLANK_AUDIO] I just wanted to briefly describe how to install R for a Windows machine. So the first thing you need to do is load, launch your web browser, so I'll do that here. I'm using Chrome, but it doesn't really matter. And you need to go to the Comprehensive R Archive Network or CRAN. So I'll just type that in here. And you'll see that there's a, at the top, there's three options. There's Linux, Mac and Windows, so you can go to the Mac version here. And you want to go, click on the base link here. [COUGH] And at the very top, you'll see download R 3.0.3 for Windows, and that's exactly what you want. So you can just click on this link, and the download will start. And so, depending on how fast your internet connection is, this might take a few minutes. Okay, so the download's finished. I'm going to click on this. And you'll probably have to click on Yes for this. And so, you can choose your language here, there are a number of choices in terms of the translations that you can choose from. So I'm going to choose English because that's my language, then you can just click through the installer. It will kind of walk you through the various steps and so we'll do that right now, just see what the options are. So you click on Next, you have to agree to the license, which is the gen, GNU General Public License, so. Feel free to read it and then click on Next. The use of the default installation directory is fine so I'm going to go through this. The use, the default user installation is fine. There are other kind of installation setups that you can choose from. If you know you only, you have a 32 bit machine maybe an older machine but you could click on that. By default it will install both versions, so you don't really need to worry about that. So just click through Next on this one. And you can choose to kind of take all the defaults, or you can try to customize your startup. I'm going to customize the startup just so you can see kind of what the options are here. So this option here shows you whether, asks you whether you want an MDI or SDI interface. So what that means is basically, do you want R to kind of run in one big window. With kind of different sub-windows with, inside of a big window or do you want it to run in kind of like separate windows? I prefer to use the SDI mode where the, so the console will be in one window and the kind of graphics window will be a separate window. I just kind of, I feel like it, I like that a little better. It's easier to work with so I'm going to click on the SDI option. And then you can choose how you want to look at your help files. So the HTML help is a little bit nicer, it's prettier to read and the plain text help is well, it's just plain text. So maybe I'll just click on plain text just to be different. And then you can choose whether want Standard or Internet2 internet access. This, generally speaking, you should not mess with, so you just click on Next. You can create a shortcut in the Startup me, Start menu, so that's usually a good idea. And you can usually click choose the defaults here in terms of creating a desktop icon unless your desktop is very cluttered and you want to you know, avoid that. So these are, these defaults are fine, so I'll click on Next, and then it will start installing the files on your computer. So now it's done and we can just click on Finish here and, and you've now installed R on your computer. And so I'll just close this browser here and I see you've got, I got a desktop icon here, so I'll just double click on that and there we are, we're running R. 

1 - 2 - Installing R on a Mac
[BLANK_AUDIO] In this video I'm going to briefly show how you can install R on the Mac. It's a very simple process. You just have to, it only takes a few steps. So the first thing you need to do is open your web browser. And go to CRAN, so that's the Comprehensive R Archive Network, so I can just type in CRAN here. And you'll see that [COUGH] there are a number of options for you to download here for different platforms. And so we're going to download the Mac platform here. So we can go to Download R for the Mac, and you see that the latest version here is version 3.0.3. And you want to download this package file here, so just click on this, and you'll see that the download meter will start going And it might take a few minutes depending on the speed of your internet connection, so just be patient. [BLANK_AUDIO] Okay, so it's finished downloading. So I'm just going to open up here. The package I can see that it'll start the installer. And I'll guide you through all the steps you need to install R 3.0.3. So I'll click Continue here and this is just the description of what's going to get installed. Hit Continue. The Software License Agreement is the GNU General Public License, version 2. So you should agree the license after having read it, of course. And then you can just click Install here. And you might have to type in your administrative password. So just go ahead and do that. And it'll start installing the files on your computer. [BLANK_AUDIO] Now that's finished I can hit Close and then it'll be in my Applications folder. So I can just go to my Applications folder which is right here. And they're in alphabetical order so lets scroll down to R and there it is. And there you have it, you have installed R on your computer. And now you can go ahead you can just use it directly or if you want to you can install an interface like R Studio if you like. 

1 - 3 - Installing R Studio (Mac)
In this video I'm going to talk about how to install R studio for the Mac. It's a very simple process and it only involves just a few steps. The one thing I'll say though is that you must have R already installed before you can install R studio. So once you've installed R already you can go to the RStudio web site, which is rstudio.com. And you can see down here on the lower left, there's a green button that that directs you to, to kind of download RStudio. So here there's two versions of RStudio, Studio that you can download. One is for the desktop and one is for the server down here. Now you, we're not going to be talking about the server version at all here. So you just want to download the desktop version. So that's this button right here. So the website should detect automatically what type of operating system you're running. So here I'm running a Mac, and so it recommends this Mac OS X version, so I'm just going to download that right now. And you'll see the download meter go. Once that's finished downloading you can go to the Downloads folder, and it should be the leftmost thing here. So I'm just going to click on it to install it. And then just like any other Mac application, all you have to do to install it is drag it into the Applications folder, so I'm going to do that right now. And it's already done. So I can just go into the Applications folder here find RStudio, double-click on it. I'll say yes, I want to open this application. And there you go, you're running RStudio. 

1 - 4 - Writing Code _ Setting Your Working Directory (Windows)
In this video I want to talk about two things. How to set your working directory and how to edit R code files in Windows. So you can see I've got R started up here and the first thing you're going to want to do is figure out what your working directory is. Because the working directory is where R finds all of its files for reading and for writing on your computer. So you can find out what your working directory is currently set to be by using the getWD function. You can see its said to be c colon slash user slash rdpeng slash documents. This may differ on your computer depending on what version of Windows you're using and, and what hardware you're using but there will be some directory probably on your c drive. Now it, the reason why it's important to know and to set your working directory, is because when you read data or when you write things out, using functions like Read or Write CSV they will be read or written to your home, your working directory. So for example if I do something like read.csv I want to the read let's say mydata.csv. If the file is not in my working directory you'll get an error one that looks much like this because it can't find the file in the working directory. So one possibility is that you can, if you know where this file is, you can move it to your working directory. Or you can change your working directory to be wherever this file happens to be. So I can go to the file menu here and choose Change dir. And I'm going to go into my local disk here, go to users, RD Peng. And I'll go to my desktop here. So now if I type DIR, I'll get a list of the files that are on my desktop here. You can see that, oh, lo and behold, here is my mydata.csv file. So now I can see read.csv and then mydata.csv. You can see that the data will be printed to the console because now it can find the file in my working directory. So one nice thing, one thing that I suggest that you do for this course is perhaps create a single directory or single folder where you can put all of your materials for the course. And not have to worry about them being scattered all over the place. Anytime you download something from the website or create a new file it's probably best to store it all in one folder so that you don't have to be searching all over for it. That way you can always set your working directory to be that, to be that directory and not have to worry about changing it. So I'm going to minimize R here for a second. I'm going to create a folder on the desktop, called I'll just call it Coursera. And then I'm going to use this folder for everything that I do in this course. So if I go back to R here, I can say change working directory again, Change dir, and go to Local Disk. Users RD Peng. Now this folder is on my desktop, so Desktop, and then it's Coursera here. So now if I say getwd and see the working directory has changed to this Coursera folder. So one of the things you're going to have to do a lot of in the class is to write R code. In order to write R code, you'll need to be able to use a text editor. Luckily R comes with a rudimentary text editor which will be definitely sufficient for this course. So you can load up the text editor by going to File and saying New Script. And this will give you a blank window that you can use to write R code. So I'm going to write a simple function here. It's going to be myFunction. It's not going to take any arguments. And all it's going to do, it's going to simulate some normal random variables. [BLANK_AUDIO] And then it's going to take the mean of those guys. Alright. So this is a simple function. Now the question is how do I get this R code into my R console so that I can actually use the function? because you'll notice that I go into the R console here. I type myFunction. It's the, I can't find the function because I haven't loaded it into R yet. If I type LS, you'll see that there's nothing in my workspace right now. Because I haven't loaded any R code into there. So how do I get the R code into the R console? Well there's two ways if you just have a little bit of code like this function over here, I can click into my R editor. And just hit Ctrl+A to select all and then Ctrl+C to copy. Then I click back into the console and I can hit Ctrl+V to paste. Now I've just pasted the code into R and you'll see that if I type LS I've got my myFunction there, I can execute it by just calling it. And you'll see it'll give you the mean of 100 random normal var random variables. If I do it again, it'll give me a slightly different number because it'll simulate a different set of numbers. The other thing you can do is go into my R editor and you can go to the File menu. Then you click Save As. So now if you save you can hit save as you can save the file into your Coursera folder here which I'm going to do right now. And you can save it as whatever name you want. So I'm going to call it my Code.r. .r is conventional for the extension. So now if I type DIR, excuse me in my console window here, you'll see that there's a file called mycode.r and you can load this into R using the source function. So I can say mycode, .r. And that loads the, all the code that is in this file. Of course, that's just the myFunction, so I haven't done anything new here. But let's say I want to add another function here. We'll say second for my second function. And it'll take an argument x. And it'll take the x, and it'll add, a little bit of noise to it. So, with, with the R norm function. Okay, so now, I've got two functions here. I can save my file with this little disk icon. Or I can go to file men-, the File menu, and hit Save. And I'm going to source this file again. Now when I type LS, you'll see that I've got this second function there, and I type second. Let's say four. I get a number that four plus little bit of random noise. So if I get four again I'll say the same thing will happen. I can say four through ten. And it'll give me each one of those numbers with a little bit of random noise added on. So that's how I edit code and that's how I load the code into R. Every time you edit your file in the editor you have to save it. And then if you want that code to be available in R you have to use the source function to source that file back into R. You don't have to use a single file. You can add a new file. So you can say New Script. It'll open another window. You can save this to be a different file if you want so that way you can separate code for different projects or different assignments. If you close the file here, you can always open it back up again by hitting Op, the Open button and you can see myCode is right there. And if I open it up, you'll see you'll have all your code right back there again. So that's how you edit code in R there's, now there's many other text editors that you might see on the web that you can download. And those are fine to use but they're not really necessary. The text editor that comes with R should be sufficient for this course. 

1 - 5 - Writing Code _ Setting Your Working Directory (Mac)
I'm going to talk about two things in this video. The first thing is how to set your working directory. And the second thing is how to edit R code files using the text editor. So, when you start up R you, it's important to know what your working directory is. Because the working directory is where R reads and write files to the computer. And if you don't know where that directory is, then you're not going to be able to, find any of the files that you save, or any of the data that you write out. So when you start up R, you can find out what your working directory is by just typing the function getwd. And you can see that I've loaded up R here and it, and it sets my working directory to be /Users/rdpeng, which on the Mac is just your home directory. So this may work but in, if you store all your files in your home directory but you may want to change your working directory to be something else if happen to store all of your data and code files in a different directory maybe a sub directory. So for example I can go to the Misc menu here and just hit, and choose Change Working Directory. And I can choose one of these directories to be my working directory. Now before I go, the first thing I want to mention actually is, that if you want to read a file, then that file has to be in your working directory, otherwise you'll get an error. So for example, suppose I want to read a data file using read.csv and I want to read the mydata.csv file, okay? So if this file is in my working directory then I'll be able to read the data, and it will load it into R. But if it's not, I'll get an error like this, because the file can't be found in my working directory. So one thing I could do is I can change my working directory to be, to be wherever that file happens to be. So I'll choose the class directory here. And if I type dir in this directory, it'll list all the files in this directory. And now you can see, oh mydata.csv is in this directory. So I'm going to, now I can read the file into R by typ, using read.csv and now you'll see that the data will appear in R. So so knowing what your working directory is and being able to set it is important because then you'll, it'll give you, it will give you access to all the files that you need in R. In particular, when you save files say from the web on to your computer, you need to know where those files are stored on your computer and so that you can set your working directory to the appropriate place. Or you can move those files into your working directory. I recommend for this class that you, that you create a specific directory for this class and store all the files in that class. That way you don't have to worry about changing directories all the time. One thing you can do is maybe just create a directory right here on your desktop, so I'm going to create a directory here called Coursera. And now, when I'm in R, I can say Change Direc, Change Working Directory here. And if I go to my desktop I can choose my Coursera folder there. And now, when I, when I say getwd, you'll see that it has set the working directory to be my Coursera folder. So now if you save files in there, you, they will be there, then you can, and you can read them from R. So that may be the be, the easiest thing for one to do. So the one thing that you're going to have to do a lot of in this course is to write code in R, and to, and you're going to need an editor to do that. So one nice thing about R on the Mac is that it comes with a text editor that you can use to edit code files. So I can load up the text editor by clicking on this little button right here. And this gives me an empty file. So I'm going to move this over here. And you can start editing code right away. So I can say, I can create a myfunctions, so call it myfunctions, and I can, it, it will start indenting things. So I can say, you know, x is, rnorm, 100. And this function, is going to just take the mean of x here. So, actually, let me just change this to y. And, and it just returns the mean. So it ignores the argument for now. So, and then, and then one thing you're going to have to do is, is figure out how to get this code into R. So what you'll notice, if I just type my function here, it's not going to be able to find it because the code has not been loaded into R. If I type ls, you'll see that there are no objects in my work space. So, the question is, how do I get this code that I've written over here, into R? Well, the easiest thing you can do, if you just have a little bit of the code, is just to hit Select All, so this is Cmd+A. Or you can go to the Edit menu and just hit Select All. And then Cmd+C copies the code and then I can click into my console window over here, hit a Cmd+V and and then return and it will paste my function into R. So now if I type ls you'll see that my function is an object in my workspace. So I can say myfunction. And it will return the mean of a hundred random normal variables, which is not very interesting, but the function does work. So the other thing you can do is you can save this file. I can go to the File menu and I want to Save As. So I haven't saved this file before, so I need to Save As. And I'm going to go into my Coursera folder and I'm, I'm going to save it as myfunction and it is typical to add the .r extension for code files. And I can hit Save. And so now, I want, I can double check my working directory, and make sure I'm in the right place here. Yeah, I'm in the Coursera, working directory. If I type dir, you'll see that my, the myfunction.r file is there now. So I can just source the file, myfunction.r. And it will have the same, it will have the same effect as cutting and pasting. So I, so I haven't done anything new because I already cut and pasted that function. But one thing I can do, I can write, I can write another function here so, say, I'll call it second to indicate it's the second function, and it's going to take the input x, oop, excuse me. And it's going to add a little bit of noise to it. And that's all it's going to do. It's going to return that. So so what, now before I do anything, I need to, now that I've changed the file, I need to save it. So I can just go to File > Save, or you can do Cmd+S. And now I can source my, this, this file into R again. And you'll notice I type ls, I got a, I have my second function there. So if I type this out, you'll see that's the code for it. So now I'll say second I say four and I return four plus a little bit of noise. If I do it again, it'll be four plus a little bit of more noise. I can give it four through ten and it gives me each one of those numbers with a little bit of noise. So that's how I write code in R. And that's how I can use the text editor, that comes with R. If I want to create a new file, I can hit this button. Again it'll give me a new file that I can, you know, save this under a different filename if I want I'm not going to use that now. So I close this window and and that's how you can use the the text editor in R for the Mac. The text editor that comes with R is very simple but it will definitely be sufficient for this class. So there's even though there are other kind of custom text editors that you can, may be able to find on the web and download for free. You don't have to do that, the text editor that comes with R should be sufficient for this class. 

1 - 6 - Use R version 3.1.1
Hi everyone, thanks again for joining our programming. I just want to make one quick note about the version of R that you'll be using in this class. You might notice from some of the videos that the videos are made using R version 3.0.3, which was the most current version at the time when the video was made. However as of now, the most current version of R is 3.1.1. And so I encourage you to install that version of R. Which should be the default version that you find when you go to the R website. So don't try digging around for older versions of R you won't need them. So I, in general I always encourage people to use the latest version of software because those will have the latest features and they will have hopefully fixed bugs that may have been present in earlier versions. So, for this version of the course for use for R version 3.1.1. Thanks a lot. 

2 - 1 - Introduction
Hey everyone welcome to R Programming. This is the second course in the Data Science Specialization and, as the title suggests, we will be focusing on R as a programming language. So in this course, we'll kind of start with the basic building blocks of R kind of different data types in the very, kind of low level details and then we'll kind of move on to writing and formulating our programs or our scripts. This involves things like control structures and writing r functions and kind of doing some basic operations on data. And then, and then we'll talk about kind of profiling your code, some of the tools for debugging and kind of how to work, how to work through longer pieces of code. And then so after this course is done, I think you'll have a pretty solid grasp of R as a programming language. We're not going to cover every last feature of the R packages because of their and some of the other courses in the specialization you'll learn more about, for example, how to use the graphics system, how to make plots, how to use some of the packages for things like statistical inference and machine learning. And so that will be covered in other classes. So, the pur, purpose of this class is to really kind of get you into R programming, in particularly or if you're not very familiar with the language and to make sure you kind of kind of get a hand, get a sense of the on the of the nuts and bolts. So I hope you enjoy it. And I think after this course is done you'll be ready to move on to a bunch of, to mo, to the other courses in the specialization. 

2 - 2 - Overview and History of R [16_07]
And then in this lecture, I'm going to give a little overview and a very brief history of the R statistical programing environment. So the very first question, I think is most obvious, is which is, what is R? And the answer is actually quite simple. It's basically R is a dialect of S. Okay, so that leads to the next logical question, which is what is S? So S was a language, or is a language that was developed by John Chambers and at the now-defunct Bell Labs. And it was initiated in 1976 as an internal statistical analysis environment, so the, an environment that people at Bell Labs could use to analyze data. And initially it was implemented as a series of FORTRAN libraries to kind of implement routines that were tedious to have to do over and over again, so there were FORTRAN libraries to repeat these statistical routines. Early versions of the language did not contain functions for statistical modelling. That did not come until roughly version three of the language. So in 1988, the system was rewritten in the C language and to make it more portable across systems and it began to resemble the system that we have today. So this was version three. And there was a seminal book the, called the Statistical Models in S written by John Chambers and Trevor Hastie. Sometimes referred to as the white book. And that documents, all the statistical analysis functionality that came into the version, that version of the language. Version four of the S language was released in 1998. And its version, it's the version we more or less use today. The book Programming with Data, which is a reference for this course, is written by John Chambers sometimes called the green book and it documents version four of the S language. So, R is an implementation of the S language, that was originally del, developed in Bell Labs. So, just a little bit more history here, in 1993 Bell Labs gave a corporation called StatSci which became Insightful Corporation, an exclusive license to develop and sell the S language. In 2004, Insightful purchased the S language completely from Lucent. So Bell Labs became Lucent Technology for $2 million, and became the current owner. In 2006, Alcatel purchased Lucent Technologies and it's now called Alcatel-Lucent. So Insightful developed a product which was a implementation of the S language under the product name S-PLUS. And they built a number of fancy features into it for example graphical user interfaces and all kinds of a nice tools. that, so that's where the plus comes from in S-PLUS. In 2008 the Insightful Corporation was acquired a company called TIBCO for $25 million dollars and that's more or less where it stands. TIBCO still develops as PLUS, although in a variety of different types of business analytic type products. And it continues to this day. So you can see the history of the language is a little bit tortured because of the various corporate acquisitions but it still survives to this day. The basic fundamentals of the S language have not really changed since 1998 and the language that existed in 1998 looks more or less like we, like what we use today at least superficially. And it's worth nothing that in 1998 the S language won the association for repeating machinery software system award. A very pretigious honor. So in a document called the stages and the evolution of S, John Chambers who was the original writer of the S language the, the original creator kind of laid out his key principal with designing the S language. And it's very important I think to to see this which is that basically. They wanted to create an interactive environment where you didn't have to think of themselves as programming, right. Then he says then as the needs became clearer and their sophistication increased, they should be able to slide gradually into programming, when the language and system aspects would become more important. So the basic idea is behind the S language and then later the R language is that people would enter the language in an interactive environment. Where they could use the lang, the environment, without knowing about any sort of programming, or having to know very detailed aspects of the language. So, they could use the environment to look at data, and do basic analyses. And then when the environment, when they kind of outgrew their environment, then they can get into programming. They could get into learning the language aspects and learning to develop their own tools and, and the system would very kind of, would promote the kind of transition from user to programmer. And so that was the basic philosopy of the S language. So that's enough about S. we, let's go back to R. So what is R about? So basically, R is a relatively recent development. In 1991, it was created in New Zealand by two gentleman named Ross Ihaka and Robert Gentleman. So, and they talked about their experience developing R in a paper writ-, published in 1996 in the Journal of Computation and Graphical Statistics. In 1993 the first announcement of R was made to the public. 1995, Martin Michler convinced Ross and Robert to use, to license R under the GNU General Public License. And we'll talk a little bit about, more about that in a second. And that made R what we call free software. 1996 a mailing list was developed, so there's two main mailing lists. One called R-help, which is a general mailing list for questions. And R-devel, which is a more specific mailing list for people who are doing development work in R. 1997, what's called the R core group was formed. And these contained a lot of, this contained a lot of the same people. From the S-PLUS who developed S-PLUS. And the core group, basically controls the source code for R. So this, so the primary source code for R. Can only be modified by members of the R core group. However, a number of, people who are not in the core group have suggested changes to R, and they have been accepted by the core group. So, some of the features of R the first one, which was important back in the old days, when people were still using S+ but the syntax is very similar to S, which made it easy for S+ users to switch over. This feature isn't quite so relevant today, where most people generally go to R directly. The semantics are superficially similar to S, in that it looks like it's S, but in reality are quite different, but we'll talk more about this in the future lecture. One of the main benefits of R is that it runs on any standard computing platform or operating system. Mac, Windows, Linux whatever you want even on your PlayStation 3 and there are frequent releases, so there are annual major releases and often there are big picks releases in between. There is a very active development going on and so things are happening. The software the core software of R is actually quite lean. Its functionality is divided into modular packages, so you don't have to download and install a massive piece of software. Whereas you can download a very small piece of fundamental core, kind of functions, and then add things on as you need them. So it's graphics capabilities are very sophisticated and give the user a lot of control over how graphics are, are, are created, and in my opinion are better than most stat packages. It might even be the best for the mo- kind of a general purpose statistical package. It's very useful for interactive work as I said before, but it contains this powerful programming language. For developing new tools, so, it eases the transition from the user to the program. And fundamentally, actually, for a language like this, is that there is a very active and vibrant user community. So the mailing lists at R-help and R-devel are very active. There's many, posts per day, and there's also a series on stack overflow where questions can be answered. So, the user community is, is one of the most interesting aspects of R. It's where all the R packages come from and it creates a lot of kind of interesting features. Of course one of the, probably the most critical feature of R is that it's free. Both in the sense of free beer and the sense of speech. So what I mean by that, is that it doesn't cost any money so you can download the entire software from from the web. And also it's free software, so I'm going to divert for a second to talk a little bit about free software. So, with free software there are four basic principles, right? You have four basic freedoms that you have. The freedom zero is the freedom to run the program for any purpose, so you don't need. There's no restrictions on how you can run the program or when you can run the program or what you can or cannot do with it. Freedom one is the freedom to study how the program works and adapt it to your needs. So this happens almost every day which is that you can look at the source code for R itself. You can make changes to it if you want. You can, you may improve it or make a better version of it. You can sell changes to it if you want. You can do, you can modify the program any way you want and adapt it to your needs. Of course, so you can look at the source code for this to get freedom one. Freedom two is that you have the freedom to redistribute copies so you can help your neighbor and so the idea is that you can give copies to other people. You can sell copies. You can do whatever you want with it. Lastly you have the freedom to improve the program and release your improvements to the public so the whole community benefits, so this is freedom three. The idea is that when people make changes to the program they can release them to the public so that everyone gets those changes. And so these basic freedoms are outlined by the free software foundation and you can see more about it at their website there. So, there a couple drawbacks of R. I won't go through all of them and probably other people have many other complaints. But there's some basic drawbacks which are one that it's essentially based on 40 year old technology. So the original S language developed in the 70s was based on a couple of principles, and the basic ideas have not changed too much. Since then and so as, one of the results of that for example is that there is little built in support for dynamic or 3D graphics. But things have improved, greatly and not on that front since the old days and there's a lot of interesting tools now packages for doing dynamic or 3D graphics. Another drawback of R that I, I hear a lot about is that the functionality is based on consumer demand and basically user contributions. So if no one feels like [UNKNOWN] your favorite message then that's your job to do. And so you can't, there is no corporation, there's no company that you can complain to. There's no helpline that you can call to say that, to demand a specific implementation or a specific feature. If the feature's not there, then you have to build it. Or at least you can pay someone to build it. Another drawback which is a little bit more technical is that the objects that you manipulate in R have to be stored in the physical memory of the computer. And so if the object is bigger, than the physical memory of the computer, then you can't load it into memory. And then therefore you can't do something in R with that object. So there have been a lot of advancements to deal with this too. Both in the R language and also just in the hardware side there are computers now that you can buy with tremendous amounts of memory. And so some of those problems had been resolved just by, kind of, improvements in technology. But nevertheless, as we enter the, kind of, big data era where you have larger and larger data sets, the model of learning objects into physical memory can be a limitation. And finally, I'll just say that R is not ideal for all possible situations. And so many people, I think, in ways is a good thing they have high expectations for R. They expect it to be able to do everything. But it doesn't do everything and so you should go into this knowing that fact. So the basic R system is divided into two, what you can think as two conceptual parts. There is the base R system that you download from a CRAN which is the comprehensive R archive network. And that's kind of the go to place for all things R. Then there's kind of everything else. And so the base system contains what's called the base package which has all the kind of low level fundamental functions that you need to run the R system. And then there are other packages contained in the base system which includes for example util stats, data sets, graphics and a bunch of other packages that are kind of fundamental packages that more or less everyone might use. And then there are a series of recommended packages, so, boot for bootstrap, class for classification, cluster, codetools, foreign, and a variety of other packages. These are the commonly used packages, they may not be critical packages, but they're commonly used by many people. So all of these packages come with this, the base R system that you download from CRAN. Now, but there's much more than this obviously, and on the, on CRAN, there are, right now there are about 4,000 packages that have been developed by users and programmers all around the world. These packages are user contributed. They're not controlled by the R core. And they are uploaded to CRAN on a everyday on a periodic basis. And the i-, and CRAN has a few, has a number of restrictions and standards that have to be met in order to get a package on to CRAN. So, one of the nice things about CRAN is that there, that the packages that you download have to meet a certain level of quality. And so there have to be, for example there has to be documentation for all the functions that are in the package, and there has to be and they have to make sure that they pass a certain number of tests. So, so CRAN has, has a lot of different packages written by users and the number is really increasing everyday. So it's very exciting to see all these packages on CRAN and there, and to see new ones come up everyday. There are also packages associated with the Bioconductor project, which is a packaged, which is a project designed to implement R software for, kind of, genomic and, kind of, bio, biological data analysis. and, of course, there are also all their packages made that people make available on their personal websites. And there's really no reliable way to keep track of how many packages are available in this fashion. So, there's really thousands of packages out there written by people. That you can discover and use, to analyze data. So there are a couple of documents that you can find on the R website. As you're learning to use R, you then want to flip through some of these. One is an introduction to R, which is a relatively long PDF document now that kind of goes through the basics of how to use R, how to use the language. There's the Writing R Extensions manual which is really only useful to read if you're thinking of developing R packages. Which are these R extensions to the main system. The R data import and export manual, which is useful for getting R's data into R and the various different ways. The R installation administration manual is, is most useful if you want to build R from the source code, and I'll talk about that in another video. And then the R internals manual. Is is a really technical document for how R is designed. How R is implemented at a very low level. And it's not really for the faint of heart. But if you're that kind of person, who wants to know how R works at a very, very low level, this is the document for you. So, I'm just going to end over here with a couple of texts that are kind of standard or kind of classic texts in this area. Of course the books by John Chambers offers data analysis and programming the data are both published by Springer. And then there's two books by Bill Venables and Brian Ripley. One is called Modern Applied Statistics with S, and another one's called S Programing. Although they have the, the, they talk about S in the title, these books are all, are both very relevant for R programming too. There's a book by Pinheiroand Base, which is Mixed Effects, Models in S and S-PLUS. That's also quite useful, for R programmers too. And finally Paul Murrell who designed the R graphic system has written a book called R Graphics and actually it's currently in its second edition right now. So, a couple other resources, one is that Springer, the publisher Springer has a series of books called Use R, which is, which is a, a lot of very, kind of relatively short books. How to use R for different types of topics, different application areas. This is quite a nice series of books that you may be interested in. And there may be a book written for you particular area of application. And there's a longer list of books on the R website. So, that was a brief overview of R, and the history of how it kind of came to be. and, starting with the next video, I'll start talking about the details of the R programming language, and how we can use it to analyze data. 

2 - 3 - Getting Help [13_53]
This video is about how to get help when learning to use R and taking this course. Because of the, because of the size of the course and the number of students that are enrolled it's going to be difficult to have, to be asking lots of questions on a one-to-one basis. And so we're going to have to resort to a few other tools to get questions answered. In particular, the discussion boards and generally through e-mail. And so, there's a certain type of way to ask questions that will kind of, that will hope to maximize the chance of you getting the right answer or the answer that you're looking for. And so at, the main thing to remember is that asking questions via email is, is a little bit different from asking questions in person. You don't necessarily know that the people on the other side, the people that you're asking, for example, on the discussion board or on a mailing list, have, you don't necessarily know that they have the same background information that you have. furthermore, they may not know you personally, and so may not know your kind of, what you mean when you say certain types of things. so, that's kind of important to keep in mind when you are e-mailing questions as opposed to when you're talking to someone in person. Keep in mind of course that elder people are very busy and their time is limited and although may be willing to help you by answering a question, they may have only a certain amount of time to devote to answering that question. Now, I am here of course to, a the Instructor, to help you in all circumstances but furthermore, I may not be able to answer all possible questions. And so you want to, you're going to want to, use the resource that you have available to you in this course. So in your search for answers there are a variety of things that you can do on your own before venturing off to other people for the answer. So if you are going to be emailing a question to a forum or to a mailing list, it's importnat that you search the archives of that forum for the answer. So, it's possible, and depending on the size of the forum, almost very likely that that someone has asked the same question that you're asking. And if someone else has asked that question and it has been answered then the answers giong to be in the archives for that forum. So if the answer's already there you save everyone a lot of time, including yourself, if you search the archives for that forum and just find the answer. Of course the web is very large and has many answers and your first reaction when you have a question is to search the web. for, given the type of program you're using, for example, here we're using R, there are many manuals that are available and many answers may exists in the manual. There's a frequently asked question, a FAQ that's on the R website that you can look for, that contains many questions that are commonly, come up up on the mailing lists and on the forums. Another thing that you might want to try to do before you go venturing out to ask people the, for the answers, is to play around with the problem and try to find the answer by inspecting or experiment, experimentation. So maybe if you have a function that's not working right, maybe change the inputs and see, see if the outputs change, or if the error message changes. if, if you're lucky enough to have a skilled friend who knows something about R, you can ask them personally. And it will be easier to, it's usually easier to ask a person on a one-to-one basis than to email a group of people in a, in a forum. furthermore, then lastly, if you're a programmer you may be able to find the answers you're looking for by reading the source code. So, all of the things on the previous slide are, are useful things to do on your own before venturing out to ask people questions. However, if you don't find the answer it's, it's important to let other people know that you did all those other things on the previous slide. Because if, for example, the answer is in the documentation, for the program, for example, it's in one of the R manuals then someone who knows the answer will usually respond by saying, read the documentation or read the manual. Ad then you've just wasted one round of email because they'll have to respond saying I did read the manual and I didn't find the answer there. And so if you, letting people know that you've done all, you've done your homework and you've, you've looked in a variety of places, is very useful and it saves a lot of time. So here's a just a very simple example of what might happen as you're using R. So here I'm loading the data sets package. And then I'm going to load the air quality data set from that package. And then I'm going to want to run the correlation function on this air quality data frame. So immediately I get an error. It says error in core, air quality missing observations in cov slash cor. So you might be wondering well why am I getting this error? What does it mean? So the first thing you can do is go to Google. And in many circumstances Google is going to be your friend. And this is no different when you are learning a new programming language or when you are learning R. And so the easiest thing to do is, is to take the error message that you get and literally cut and paste it into the search box for Google. When I search on that I get a number of results, and particularly this third result looks very promising. It looks like someone asked this question on the R help mailing list and it looks like and so maybe, maybe we're clicking that to see, if someone replied with the answer. So, when you ask a question on a mailing list, so assuming that Google wasn't able to help you out you're going, if you're going to ask a question on a discussion board or on the mailing list, there are a couple of things you need to think about before you ask that question. First, is it possible to reproduce your problem? So, is it, so when, if someone else can reproduce your problem, it makes it a lot easier for that other person to figure out what the solution's going to be. And so if you can provide some code or some very simple example that will reproduce your problem, this will be enormously useful to everyone else involved. And if you don't do this typically the first response you get will be can you please provide a reproducable example. Second it's important to understand what you expect the output to be, because if your expectation is wrong, then of course your, it may or may not be an error depending on what your expectation should be. So what you expect the output to be will indicate kind of how, what the nature of the error and what needs to be solved. And then, given your expectation, you'd to say, what do you see instead? So what was the thing that was unexpected that gave you the question? Other information that's important to specify when you're asking a question, is the version of the product you're using. For example what version of R are you using? What version of the R packages are you using, if it's specific to a given package? Because often there may be legitimate bugs and versions and older versions of R or R packages and that the your problem might be solvable if you just upgrade to the latest version. So, if you're using the latest version of R it's important to mention that. Sometimes it's important to know what operating system you're using, so whether you're using a Mac or Windows or Linux or some other Unix machines, it. Some problems can be traced to the type of operating system that you're using. And depending on the question that you have, there may be additional information that you need to provide. So, when you send an email to a forum or to a discussion board. It's important to get as much information in there, as much useful information in there as possible. And, this includes the subject line for the email. So there's a couple of examples of subject lines that kind of range in usefulness. So, that is probably the least useful, just says, help, can't fit linear model. So, here there's, there's very little information here. All I know is that there's something, there's some problem with linear models I don't know anything else about what the user's problem is. So the second version is is, is much better. Eh, it tells me that on R version 2.15.0 the lm() function produces the seg fault which meaning that R crashes, with a large data frame. And it furthermore says I'm using Mac OS 10 10, 10.6.3. So here I've got the operating system, the version of the operating system, I've got the version of R, I've got what function I'm using, and I've got a summary of what actually happened. So, just a little bit smarter than that would, would just be to reformat the message so that I specify what version I'm using the function and then the version of the operating system and then, and then, so that gives me the context and after that I can say what the problem was. In this case it was the seg fault on a large data frame. So, here the important details are right away put into the subject header before I even get to the body of the message. So, a couple of things that you definitely want to do when you're asking a question on a forum or a mailing list first is to describe the goal, not the step. So, you may have many, many steps that you're going through and maybe one of those steps is causing a problem. And it's useful for other people to know what your big, what the bigger picture is in terms of what you're trying to do because, for example, they might have a better idea about how to go about achieving that goal, which may be faster or simpler and may work around whatever problem you're having. So describe the ultimate goal and then talk about what the problems are. And don't just narrow it down to the, to the one little step that you're having a problem with. Be explicit about your questions, so remember, provide details about what you're trying to do. And you have to provide the minimum amount of information necessary. So not the maximum amount of information, the minimum amount of information. And so it's common to see see on some mailing list posts that, you know, lots of outputters produce, and that's not very helpful, because volume doesn't really help you in terms of diagnosing the problem. We need to know exactly, to narrow down kind of where the problem is going to be. So, and of course, a couple things, you know, being courteous never hurts anyone. And it and promoting civility on mailing lists is always a nice thing. And if you find the solution later on, it's useful for everyone else in the community if you follow up with the solution and explain what the problem was, what the problem was and how you solved it. A couple things you definitely do not want to do when posting to a forum. You don't want to claim that you found a bug. This happens all the time and usually, I'd say 99 times out of 100, it's not a bug and it's just a misunderstanding about what should have happened, so a mistake in the expectation of the user. Groveling as a substitute for doing your homework, that's not usually looked well upon and you definitely shouldn't do that. Definitely don't want to post homework questions on a mailing list or forums and, and the reason is because people who write the homeworks, the homework questions are reading those mailing lists and would be able to identify all homework questions without a doubt. So we've seen them all, don't bother trying to get the answers to your homework on mailing lists. Don't ever email multiple mailing lists at once. So this is little bit annoying, because, people will be subscribed to different mailing lists and will be getting your message more then one time. It's useful to, it's important to figure out which mailing list is the most appropriate mailing list for your question and then send the message to that mailing list or forum. And then lastly, don't ask others to debug your code without giving some sort of hint as to what the problem might be. So it's, it's very difficult when a person posts a long listing of code and says, there is a problem in here somewhere, I don't know where, please help. It's better to give to kind of specify where you think the problem is and what you're trying to do so that everyone can save some time. So this is just the very brief case study on using a recent post to the R-devel mailing list. R-devel mailing list is an email list for people who are doing development work in R. So either they're developing packages or they're making modifications to the R source code itself. And so the subject was, you could see from the subject that it's going to be a problem. The subject is large data set dash confused. So right away that much information here to go on. It's not clear what the problem is. And the message just says I'm trying to load a data set into R, but I'm completely lost. This is probably due to, mostly to the fact that I'm on a complete R noob, but it's got me stuck in a research project. So you have to ask yourself, what do I know about this persons problem from reading this message? And the truth is very little. And so the response was somewhat predictable. Basically the first person response said, yes you are lost. And then there is a pointer to the posting guide which everyone should read before sending email through the mailing list. And then also a list of manuals. And so, here you can see that one round of email was immediately wasted because probably the answer to the question was in one of the manuals. And so, and the user didn't specify whether he or she had already done that. So, in terms of what went wrong with this little exchange, first of course the question was sent to simply the wrong mailing list. The R-devel mailing list is for development questions and for more sophisticated programmers. It's not really mailing list for questions as this person stated noobs. So that question really should have gone to the R help mailing list where it would have been better received. However, in addition to that, the email subject was very vague. It was not clear what the problem was. The question itself was very vague. There was no reproducible example there. There was nothing, there's not possible for other people who were reading the e-mail to reproduce what that person's problem was. And further, and there was no evidence that any effort was made to solve the problem. So there's no evidence that they searched the web or checked the manuals or or experimented with the problem or anything like that or even looked at the forums. So the end result was a complete recipe for disaster and there were, it was likely that this person did not get the answer to their question. So, a couple places to turn for this course, first of all the class discussion board I think will be the most useful because your fellow students can help you out there and I can respond to you on the discussion board. Outside of class there's the R help mailing list which I just described. And you can post to this mailing list as long, and it's useful to of course follow all the rules that we talked about just now a bit. And depending on what other projects you might be working on there are other project-specific mailing lists for other types of software. And so this talk was inspired by Eric Raymond's posting called How to ask questions the smart way. And I encourage you to read that. It's much longer. It has a lot of other useful tips. 

2 - 4 - R Console Input and Evaluation [4_46]
So once we start typing things into the R prompt, they we're going to be start, we're going to start coding and doing calculation. So the things that we type into the R prompt are called expressions. So for example, the symbol, which looks like a left-hand arrow and is actually the less than symbol, followed by a hyphen this is what's called the assignment operator. The assignment operator is what assigns a value to a symbol. So, for example, in this first expression here the symbol that I'm creating is called x, and the value that I'm assigning it is call, is 1. And thi, so, and I used the assignment operator to create that. So x is 1, is a, is an R expression. And the next expression I'm going to print that value so print is a function. And I'm passing it the symbol x so that when I print out x I get its value which, in this case is 1. So another thing to think about x is also considered a, is an R object that is a numeric object that has one element. So it's really a numeric factor where the first element is the number one. In the third expression here, you notice, I'm just typing X at the prompt and, and, and when you hit enter what happens is it prints out the value of X. So this is called, this is another way to print out an object without explicitly calling the print function. So in the, in this expression over here, I'm creating a new symbol called message, MS, MSG. And I'm assigning it a value of the string hello. All right? So now, this is a character vector. And the first element of this character vector is the string hello. I could add other elements to this vector if I wanted to, but they would all have to be character. So the grammar of the language determines whether an expression is syntactically correct or not. Or whether it's complete. So for example by this type x followed by the assignment operator and I don't have anything else, that's not a, that's not a complete expression and so when I hit Enter nothing will happen because it's waiting for the expression to be completed. The other thing I've got here is this hash symbol here. So this hash symbol here it indicates that everything to the right of that is a comment. And so the, the, the, the, the R engine will ignore anything that happens to the right of that symbol. So you can put things like comments or notes to yourself in code and R will just ignore those comments. So once you've typed in a syntactically valid and complete expression at the prompt when you hit enter what happens is that the expression is evaluated by the R engine. And the result of that evaluation expression is then returned. And so, so sometimes when you evaluate an expression, nothing happens because there's nothing to really show. And so, for example, in the first expression here when I say x is assigned to be five. So I'm creating an object called x. It's a numeric vector and the first element's going to be five. Now when I hit enter nothing happens because there's really nothing to show. And so but now when I hit x and I hit enter it prints out the value five, so it prints out the value of x. So when I hit x, when, when I type in x and I hit enter, that, and it prints out five, that's called autoprinting, and so when you just type an object's name and hit enter. R will by default autoprint the value of that object. This is the same as calling the print function on that object which will just print out the value of that object. So you can explicitly print an object or you can auto print an object. So this is, this sounds a little complicated but it's really just the natural thing to do and it is what most people would expect. You'll notice that when I print out the object x, there's a little one in brackets here. And you might be wondering what that is. So, all that indicates is that, it, it's telling you what element of the vector is being shown. And this will make more sense when we have longer vectors to look at. But all this is shame, saying is that the number five that you're seeing there is the first element of the vector. So for printing you'll see that here I'm creating an x an object called x and it's the sequence one to 20, so the colon operator here that I've used is what's used to create a sequence. So, when I say one colon 20, that creates a sequence of one, two, three, all the way up to 20. So, now when I autoprint x in this case, you'll see I've got a long, much longer vector here. In this case, it's an integer vector. And you'll see that the first line of the printout it has a one next to it, because that's the first element. And then the, the second line has a 16 in brackets because that's, the first element of that line is the 16th element of this vector. So it's all kind of straightforward but just that's how the printout works 

2 - 5 - Data Types - R Objects and Attributes [4_43]
In this lecture we're going to start getting into the nitty gritty and the details of R. In particular I'm going to talk about different data types that are used in R and some basic operations on those data types. So first it's important to kind of get the language right correctly. So all the things that you manipulate in R, all the things that we encounter in R, are what might be called objects objects can be all different kinds, can contain all different kinds of data. But everything in R, is an object. So the R has five basic atomic classes of objects. So these are kind of the very low level or, or basic classes of objects and they are character, numeric. So these are like real numbers or decimal numbers. integers, complex numbers, and logicals. So logicals are just true a false type things. And so the most basic object in R is called a vector. And a vector conta-, Can contain multiple copies of, for example, of a single type of object. So you can have a vector of characters or a vector of integers, one thing you cannot do with a standard vector is have mixed types of objects you cannot have a vector of characters and numerics, or numerics and integers, or integers and logicals. It, everything in a vector has to be the same class. Of course, with any great rule, there's always an exception, and this, this one is no exception. So, in this, with vectors, there's one type of vector that can have multiple different types of classes, and that's called a list. So a list is represent as a vector, so there's a se, it's a sequence of objects. But each element of that vector can be a different, can be an object of a different class. So for example, you can have a list. That has a character, that has a numeric, it has a logical. You can have a list that's inside the list and one element of the list can be a data frame so, any element of the list can be anything. And that's an, actually why what makes list so useful. So the list is the one exception to the ot to the. General rule that a vectors can only contain elements of the same class. So you can create an empty vector with the vector function. And the vector function has two basic arguments. The first argument is the class of the object, so the type of object that you want to have in the vector. And the second argument is the length of the vector itself. Perhaps the most important type of object in R of course is the number. So numbers in R are generally treated as what are called numeric objectsum, so pretty much all numbers are treated as double number precision real numbers. So, even if you are looking at a number that's like one or two, R thinks of those numbers as numeric objects there is a way to explicitly say you want an integer and you can specify the L subs, the L suf, the capital L suffix there. So for example, if you just enter the number 1 in R, that gives you a numeric object. But entering 1 with a capital L next to it explicitly gives you an integer. This distinction is not very important right now, but, it will become important later. There's also a special number called inf, which stands for infinity and, and inf is like a real number it can be used in calculations and you will get the expected result. So, for example, if you take one, divide it by zero, you'll get infinity and if you take 1 and divide it by infinity you'll get zero. So, emphasis special number, and you can also have minus infinity, too. There's another special value called NAN or Nan. And this represents an undefined value so you can name it as not a number. So, for example, if you take zero over zero that's not a number It's not defined so you'll get a Nan back Nan can also be thought of as a missing value but we'll talk a little bit more about missing values a little bit later so another thing that, that comes with each object in R is an attribute. So not every, object in R necessarily has attributes, but, but they are, but attributes can be part of an object in R. Some of the most common types of attributes that we'll encounter are namesor dim names, or, or dimension names. A dimension, so a matrix will have dimensions for example it will have a number of rows and a number of columns if you have a multidimensional array you'll have more than two dimensions. The class of the object, so every object will have a class. So for example, numeric objects their class is numeric and integer objects, their class is integer. Every object also has a length. So for a vector it's quite simple the length of the object is just the number of elements in the vector. And then there may be other user-defined attributes or metadatas which, so these are things that you can define separately, for an object using various attribute functions. There is a general function called attributes which allows you to set or modify the attributes for an R object. 

2 - 6 - Data Types - Vectors and Lists [6_27]
So the c function is another function that can be used to create vectors of objects, and you can think of c as standing for concatenate because it can be used to kind of concatenate things together. So, for example, I can create an object called x by concatenating 0.5 and 0.6 and that will give me a numeric vector of lenght 2 for the first element is .5 and the second element is .6. In the second example here, I've got a logical vector, we are concatenating through true and false, so shorthand for true and false, you can use t and f, capital T and capital F, so these 2 lines give you the same objectum, you can create a character vector by concatenating a bunch of characters. You can create integer vector by creating a sequence with colon operator, and you can also create a vector of complex numbers where the i is a special symbol, which indicates the imaginary part of the complex number. So using the vector function you can also create, a vector of a certain type and a certain length. So here, I'm going to create a numeric vector of length 10. And by default it will initialize the vector, with a default value for numeric vectors the default value is zero. So what happens if you take a vect you create a vector and you mix tow different types of objects and so the general it that is that r. Will kind of create the least common denominator vector so, will not give you an error but what will happen is that it will coerce the vector to be the, the class that's kind of the least common denominator. So here, in the first example, I've got in trouble concatenating number 1.7 and letter a, so clearly these are not in the same class one is numeric, and the other is character. So the least common denominator here, is going to be character. And so we're, so what you're going to get is that y is going to be a character vector, where the first element is going to be the string 1.7 and the second element's going to be the, the letter A so in the second example here, I've got concatenating true, which is a logical, and a two, which is numeric. And so what's going to happen here is that you're going to get a numeric vector and the true is going to be converted into a number. And so how's that happen, so and the, and by the convention in R true is represented as the number one and false is represented as the number zero. And so what you're going to get here, is a vector 1,2. Lastly this last example here I am calculating the letter A, and the logical true and so here the least common denominator is again going to be character. And so the vector that you end up with is a vector where the first element is A and the second element is the string true, so T R U E. It's not going to be illogical so you need to be a little bit aware, of the types of coercion that can occur in our, when you mix different types of elements in a vector. And because you won't get an error, but, but the coercion will happen behind the scenes. that, in the previous slide we talked about kind of a implicit coercion that occurs behind the scenes, but you can explicitly coerce objects from one class to another using functions that usually start with the word as. So for example, if you want to convert something to a numeric you can use the function called as.numeric. If you want to convert something into character you can use the function as.character now if you apply these functions, so if you apply as.numeric to a numeric vector nothing will happen so, here in this example I'm starting off by creating an object called x which is a sequence of zero to six. So this is going to, this is an integer sequence as you could see when I call class on the object but I convert it into a numeric sequence. And so I can call as.numeric on x, and you can see that it prints out 0, 1, through 6, which look like an integer object but it's actually going to be numeric or I can convert it into a logical and so I can say as.logical on it, and what happens? Well, as you can see, the convention is that 0 is false. And any number that's greater than zero is going to be true so here I've got a, when I convert to logical I get false and then everything else is true when I call as.character on X it takes all the numbers and, and converts them into characters. So now I've got the string zero, the string one, two ect and finally when, if I call as.complex this is fairly straightforward because you can all it does is says that you have a complex number where all the imaginary components are zero, now coercion we'll notice always doesn't work. And when it doesn't work you get what are called NA values. So non sensical coercion will result in NAs. So for example if I take the vector ABC. And call as.numeric. Well there's really no way to convert the letters a, b, and c to numerical variables so what you get is a vector of NAs and plus a warning similarly if you call as.logical on x, you're going to get a vector of NAs The next data type I'm going to talk about is the list. Now I mentioned lists a little bit earlier in this lecture and the idea is that they're, they're like a vector except that every element of a list could be a, an object of a different class and so that makes lists very, very handy for kind of carrying around different types of data. And they're very useful in R and they become very common especially when in conjunction with other types of functions that we're going to learn about. So here I'm creating a list called x by using the list function which is a, which can be used to construct the list. And the first element is a numeric value, numeric object of one. The second element is a character, letter a. Third is illogical and the fourth is a complex number. So this is not a problem with lists and when I autoprint the list you'll see that it prints out a little bit differently It doesn't print out like a vector because every element is different. So you can see that in the double brackets here so the, the elements are indexed by double brackets so the first element is the vector 1. The second element is a vector with A. The third element is a vector with true and the fourth element is a vector. With the complex number 1 + (4i). So lists are indexed you'll notice that el, elements of a list will have double brackets around them elements of other vectors just have the single brackets, so that's one way to separate a list from other types of vectors 

2 - 8 - Data Types - Factors [4_31]
So factor is a special type of vector, which is used to create, to represent categorical data. So, and there's two types of factor, there is unordered or ordered, so you can think of this as being, as storing data that are. Have labels that are categorical but have no ordering, so for example male and female. Or you can have ordered factors which might represent things that are ranked. So they have an order but they're not numerical for example you know, in many universities you'll have assistant professors, associates professors, and full professors. Those are categorical but they're ordered. So one, you can think of a factor as an integer vector where each integer has a label. So for example, you might, you can think of it as a vector as one two three, where one represents you know, high, for example high value and two represents a medium value and three represents a low value. So you might have a, a variable that's called high, medium and low. And underlying in R is represented by the numbers one, two, and three. so, factors are important because they're treated specially by modeling functions like lm and glm which we'll talk about later. But these are functions for, for, for fitting linear models. And factors are with labels generally speaking are better than using simple integer vectors because the factors are, what are called self describing. So having a variable that has values male and female is more descriptive than having a variable that just, that just has ones and twos. So for example, in many data sets you'll find that a var, there will be a variable that's coded as one and two and it's, and it's not. Easy to know whether that variable is really a numeric variable that only takes values one and two, but the problem is that's not something that's coded in the data set, so it's hard to tell. If you use a factor variable then the coding for the labels is all, is kind of built into the variable and it's much easier to understand. So factors can be created with the factor function, and the input into the factor function is a character vector. So here, I'm just creating a simple factor with the which has what, two levels, and the levels are yes and no. And so x is a factor, you can see what, it prints out a little bit differently from a character vector, in the sense that it prints up the value, yes, yes, no, yes, no. And then it has a separate attribute which is called the levels. And so the levels of this factor are no and yes, okay. So there's only two levels. I can, I can call table on this factor and it will give me a frequency count of how many of each level there are. So for example, it'll tell me there are two nodes. And there's three yeses. Now, the un-class function strips out the class for fa, for a vector. So for example, I can, if I call un-class on x it'll, it'll kind of bring it down to an integer vector, and you can see that underlying. The factors represent as 22121 so, yes, it's coded as two and no, it's coded as one. Now it's not really essential for you to know this because you can just treat the factor as being a vector of yeses and nos but it's used sometimes it's it's useful just to know under, underneath kind of how factors are represented by R. And so you see, it's really an integer vector with the attribute, the levels attribute of no and yes. The order of the levels in the factor, can be set using the levels argument in factors. So for ex, and sometimes this is important because in modeling functions and when you include a factor variable this, this, sometimes it's important to know what the baseline level is. And so the baseline level is just the first level in the factor, and the way this is determined by NR is critical. It's determined using alphabetical order, so for example, if I create a factor variable. With the, with the elements yes and no, then the base line level with be the first level that's encountered and because no comes before yes in the alphabet then no will be the base line level and yes will be the second level. Now this may not be something that you want you might want for example a yes to be the base line level and no to be the second level and then in that case you have explicitly tell r. That yes is going to be the first level and you can view that using the levels argument to the factor function. So now when I print out the x object you see that the elements are still the same, still yes yes no, yes no. But the levels attribute is reversed. because yes is the first level and no is the second level. 

2 - 9 - Data Types - Missing Values [2_10]
So there's a special type of object that we haven't talked too much about yet. And these are missing values. Missing values in R are denoted by either NA or NAN which we talked about before. NAN is used for undefined mathematical operations. And NA is pretty much used for everything else. And so, there's a function in R called is.na which is used to test objects to see if they are NA. To see if they are missing values in that object. There's another function called is.nan which is used to test for NANs. So, NA values can have a class, too. So you can have missing integer val, values or you can have missing character values or missing numeric values etc. And so even though it looks like it's all NAs, the NAs can have different classes potentially. And then it's an NA, an NAN value is considered to be also NA, so for example, an NAN value, a NAN value, is missing. Is considered to be missing. So, but the reverse is not true. So an NA value is not necessarily, an NAN value. I've got a few different types of missing values listed here. So, here I created a vector x which is 1,2, NA, 10, and 3. So, now, this is a numeric vector. And the NA value in here's going to be a numeric missing value. So when I call is.na on x, what it returns is a, is a logical vector. And the logical vector indicates whether each element of the vector x is missing or not. And so, there's only one missing element in this vector, and so that's the third element. So you can see that the, that the logical vector that's returned. The first two are false, the third is true, and the fourth and the fifth are false. So the, the, the element that's true indicated where the missing value is. If I call is.man on this vector, you'll see that vector that's returned is all false. Because there aren't any MAN values, or their aren't any MAN values in this vector so everything's false. Of course, if I create a vector that has an end, a NAN value and an, and an NA value in it. You'll see that is.na returns true for both of them. But is.nan only returns true for the for the value that's actually NAN. 

2 - 10 - Data Types - Data Frames [2_44]
The last data type I'm going to talk about here is the data frame. The data frame is a key data type used in R and it's used to store tabular data. So of course, tabular data make up a lot of what we use in statistics. Of course not all types of data are tabular. But because so much data becomes a tabular form. Data frames are very important in R. So data frames are basically represented as a special type of list, where every element of that list has the same length. Right, so you can think of each column of the data frame as an element of the list, and of course, in order to be a table, every column has to have the same length. However, each column doesn't have to be the same type. So the first column could be numbers, the second column could be factor, the third column could be integers the fourth column could be logicals, it doesn't matter what the different types are. so, unlike matrices where, wh, which have to store the same type of object in every single element of the matrix, data frame can store your cla objects of different classes. And so, data frames also have some special attributes. First, the first special attribute is called a row name. And so every row of a data frame has a name. And this can be useful for kind of annotating the data. So for example, each row re, might represent a subject enrolled in a study, and then the row names would be the subject ID for example. however, sometimes the row names are not interesting, and, and, and often you'll just use row names of 1, 2, 3, et cetera. Data frames can be created by calling most often calling the read.table, the read.csv function and we'll get into that a little bit when I talk about reading data into R. And you can also create a matrix from a data frame by calling the data.matrix a function. Now, you can't if you have a data frame that has many different types of objects, and then if you coerce that into a matrix, it's going to force so each object to be coerced so that they're all the same. So you may get something that's not exactly expected. So, data frames can be created besides using read.table or read.csv, you can use the data.frame function and here I've created a very simple data frame where the first the first column is called, is the foo variable, and the second column is the bar variable. The foo variable is an integer sequence from one to four, and the bar variable is a logical vector with two trues and two falses. So when I autoprint the data frame out you'll see the, it prints out the two columns and here the row names since I didn't specify any special row names, just defaults to 1, 2, 3, 4, because there's four rows. And then when I call the nrow function on x, I see that there's four rows in the ncall function, shows me that there are two rows 

2 - 11 - Data Types - Names Attribute [1_49]
R objects can also have names. So this not true for just data frames. It's true for all r objects. And this can be very useful for writing readable code and self describing objects. So for example, I'm creating a vector that's an integer sequence 1, 2, 3 and by default, there's no name. So when I call the names function on x, it gives me a null value. However, I can, I can give a name to each element of the vector x. So for example, if I, I can say the first element's called food, the second element's called bar, and the third element's called norf. So now when I print out my x vector, I get a vector 1, 2, 3 but then each one has a name over it, which is the name I just specified. And so when I call the names function I get the, the names that are associated with each element of the vector foo, bar, and norf. Lists can also have names. And so for example here I'm creating a list with the list function where the first element is called a, the second element is called b, and the third element is called c. And so when I print out the list, it prints out the names of each element and the values associated with those names. Finally matrices can have names. These are called dim names. So here I created a matrix from the sequence 1 to 4. It's a two by two matrix. And so the, when, when I use the dim names function I pass it a list. Excuse me, I assign it a list. Where the first element of the list is the, is the vector of row names and the second element of the list is a vector of column names. So here I want to name the rows a and b, and I want to name the columns c and d. So that's what I passed to the dim names function. And now when I print out my matrix I can see that the row names and the column names are labeled as I wanted. 

2 - 12 - Data Types - Summary [0_43]
So, that's kind of a whirlwind tour of the different basic data types in R. So far, we've talked about the atomic classes in numeric, logical, character, integer, and complex vectors. We talked about how vectors can only have elements of the same class and the main exception to that is lists which can have elements of different classes. There are factors which are used for, for coding categorical data, with ordered and unordered data. There are missing values that are represented by NAs, and NANs. Data frames are used to store tabular data or each COM can be of a different class. And finally, all our R objects can have names which mean usul, which can be useful for creating self-describing data. 

2 - 13 - Reading Tabular Data [5_51]
This lectures going to talk about reading and writing data in R. So there's a few different types of ways you can do this and I want to talk about some of the primary functions that use an R to read and write data. So there are a few principle functions that we're going to talk about for reading into R. The first two are read.table and read.csv and these are for reading tabular data. And they are probably the two most commonly used functions for reading data into R. These functions read text files that, that contain data that are stored in kind of rows and columns type of format and return a data frame in R. The function read lines is for reading lines of a text file so this, this can be any type of file really, it just gives you text in a, as a character vector in R. The source function is important for reading R code, so if you have R code, for example functions or anything written get written to a file the source function will read all that code into R. The dget function is also for reading R code files but it's for reading R objects that have been dparsed into text files. We'll talk a little more about this later. The low and unserialized functions are for reading binary objects into R. So the analogous functions for writing data are write.table, writeLines, dump, dput, save and serialize and those kind of pair up with their reading analog. So, the read.table function is the most commonly used function for reading data into R. It's important that you know kind of, how the arguments work, what the arguments are and understand what they mean. So the first argument is pretty obvious, it's name of a file or the name of a connection, which we'll get to a little bit later. Usually you're going to give this a file name, it's going to be a string and it's going to be a path to a certain file in your computer. The header is a logical flag indicating whether the first line is a header line, so if the first line for example it has all the variable names in it, then that's not really a piece of data, that's just a line that has labels on it. So you want to tell the read.table function whether the first line contains the variable names or not or whether the line just, right away contains data. The sep argument stands for separator. it's, it's a string that indicates how the columns are separated. So for example if you have a file that's separated by commas then the separator has a comma. You may sometimes files are separated by semicolons or by tabs or by spaces. And so you want to tell read.table what the separator is going to be. ColClasses is a character vector which indi wh, wh, which, whose length is the same length as the number of columns the data set. And the character vector indicates what, what is the class of each column the data set. So, for example, is the, if the first column is numeric and the second column is logical, and the third column is a factor, et cetera. And so the colClass is a vector, which is not required but it, it tells the, it tells read.table what the class of the data is for each column. End rows is the number of rows in the data set, this is not required but it it can be used. Comment.char is the character string that indicates what's the comments character So the default, for example, is the pound symbol or the sharp symbol and anything after, anything to the right of that symbol is ignored the comment character. So you can specify other characters to be comment characters, and the lines, lines of the file that begin with that comment character will be ignored. Skip is the number of lines to skip from the beginning. So sometimes there may be some header information or some non-data region at the beginning of the file, and you want to skip right over that. And so you can tell the read.table function to skip the say the first ten lines of the first 100 lines and then only start reading data after that. Last argument is strings as factors this defaults to true. And the idea is that it, the question is whether you want to encode character variables as factors. So by default. Anytime our read.table encounters a column of data that looks like it's a character variable, it will call, it will assume that what, what you mean to read in, is a factor variable. If you don't me, mean to read this in as a factor variable, then you can set strings as factors equal to false. So for small and kind of moderately sized data sets it has computers are going to get better and better everyday, the definition of small and moderate is kind of growing. But you can use read.table usually without specifying any of the other arguments besides the file name. So you can say read.table on, say foo dot text so this is just the name of the file, and it will automatically take care of figuring out, you know, what the c, classes of the different columns are, it'll figure out how many rows there are, et cetera. So you don't have to specify any of that information if you don't feel like it. And, and then, and then, this will return an object here ca, that I call data, and that would be a data frame. So it'll automatically skip any lines and begin with the comment symbol. It will figure out how many rows there are and, agai, and again it'll figure out what type of variable is in each column of the table. So, tell it you can, that you can tell R all these things and if you want to and the reason you might do that is to make it run faster and more efficiently. So with small and moderate size datasets its really not much advantage to doing that because because it'll be pretty fast and pretty efficient as it is. The read.csv function is identical to read.table, except for the key differences that the, the default separator for the read.csv function is the comma, whereas the default separator for read.table is the space. So parti, so read.csv is useful for reading csv files, this, this can usually, this stands for comma separated value. It's usually something that you get from a spreadsheet program, like Microsoft Excel or something similar to that. So csv is a very common format that most spreadsheet types of programs will understand. The other thing that read.csv specifies is that it always specified header to be equal to true. 

2 - 14 - Reading Large Tables [7_08]
So with larger data sets of beyond the small to moderate, then there are a couple of things you can do when reading in tabular data. That will make your life a lot easier, and more importantly it will prevent R from totally choking. So first you should read the help page for read.table. In fact, you should probably have it memorized. There is a lot of key hints in that help page. Lot of useful information. And in my opinion not enough people read this help page carefully enough. So that they can kind of recite in their sleep. And if I, so there's a lot of so once you've read that you'll see there's a lot of important information for kind of how to optimize read.table. In particular for large data sets. And so one of the things you're going to want to do is to make a very rough calculation. Of how much memory you need to store the data set you're about to read. And so that way you can get a sense of well, is there enough memory on my computer to store this data set? Because if you recall correctly,. R will have to, R is going to store your entire dataset in memory unless you do otherwise. So when you call read.table or read.csv, it's reading your entire dataset into the RAM of the computer. And so you need to know, roughly speaking, how much RAM this datasets going to require. And we'll talk about how to calculate that in a second. So another opti, easy optimization you can say is if there's no comment lines in your file. Then just set the comment char to be the comment.char is meant to be blank. So just an empty quote there. The call classes argument is actually very important. Because it whe, if you don't specify it then what R does by default is it goes through every column of your dataset. And tries to figure out what type of data it is. Now, that's all fine, well I'm fine when the dataset is small to moderate. But reading each of these columns and trying to figure out what type of data it is takes time, it takes memory, and it can generally slow things down. If you can tell R, what type of data, is in each column, then R doesn't have to spend the time to figure it out on its own. And so, it'll, it'll generally make read.table run a lot faster. So you can save yourself a lot of time. So if you, if, if you have a few columns in your dataset, then then you can usually just say what, what the classes are. But if you have, or if they are all the same, so for example if all the columns are numeric. You can just say, you can just set call classes equal to numeric. And if you only sent, you give it a single value, it will just assume that every column has that same value. So if you just say numeric it will assume that every column is numeric. Otherwise what you can do if you have a huge data set, you can read in maybe the first 100 or first 1,000 rows. By specifying the nrows argument. And then going through each of the looping over each of the columns using sapply and calling the class function. So the class function will give you, will tell you what class of data is in each column. And then you can use this, and then you can save, store this information. And then read the entire data set after by specifying the call classes argument. So the n rows argument is actually very useful too. It doesn't necessarily make R run any faster, but it does help with memory usage. And so, if you can tell R how many rows are going to be read in to, to the, in to, in to R. Then it can calculate the memory that's going to be required. And not have to kind of figure it out on the go. So even if you mildly overestimate how many rows there are in the data set, that's okay. Because it won't make a difference, it'll still read the correct number of rows. So in general, when you're using R with large data sets, and there's lots of large data sets out there nowadays. It's useful to have a few things, a few bits of information on hand. So, for example, how much memory does your computer have? How much physical RAM is there? These days in most computers will have on the order of a few gigabytes up to many gigabytes of physical RAM. What other applications are in use? So are there other applications that are running on your computer that are eating up some processor time or memory? If you're on a multi-use system, are there other users logged into the system. Are they using up some of the resources on the computer? What is the operating system for your computer? So, is it a Mac? Is it Windows? Is it Unix? Is it Linux? Is it something like that? And then, also it's useful to know whether the O, the operating system that you're running is 32-bit or 64-bit. On a 64-bit system there, there, you'll generally be able to access more memory if the computer has a lot more memory. So if you want to do a rough calculation before you read in a table into R, using the read.table or the read.csv function. You can just do a very quick calculation. So here is, suppose I have a data frame here, with 1.5 million rows and 120 columns. So this is not a particularly big data set but it's reasonable. so, suppose that all of the nu, all the columns are numeric. So, I don't have to worry about different types of data. They're all, all the columns are numeric. The question is how much memory is required to store this data frame in memory, okay? So, I can do a simple calculation. So, the num, the number of elements in this data, in this data frame is going to be 1.5 million times 120, right, because it's a square object. And so that's, so that's the number of elements in the data frame. Now, if it's a numeric all the data are numeric then each number requires eight bytes of memory to store. Because the, because the numbers are stored using 64-bit numbers and there's eight bits per byte. So that's eight bytes of memory per numeric object. So that's going to, so here's the number of bytes, now there's two to the 20 bytes per megabyte. So I can divide that, the number of bytes by 2 to the 20, and that's how many megabytes I got. So it's got, I've got 1,373.29 megabytes. And I can divide that again by 2 to the 10 to get the number of gigabytes, that's going to be roughly 1.34 gigabytes. So the, the raw storage for this data frame, is roughly 1.34 gigabytes. now, you're actually going to need a little bit more memory than that to read the data in. Because there's a little bit of, overhead required for reading the data in. And so, and so the rule of thumb, is to, is that you're going to need almost twice as much memory to read this dataset into R using read.table. Then the, then the object itself requires. So if your computer only has, let's say two gigabytes of RAM eh, and you're trying to read in this 1.34 gigabyte table. You might want to think twice about trying to do it. Because it, you're going to be pushing the boundaries of of memory that, that is required to read this dataset n. Of course, if your computer has like four or eight or 16 gigabytes of RAM, then you should have no problem in terms of the memory requirements. It will still take some time just to read it in just because it takes time to read in all the data, but you won't be running out of memory. So doing this kind of calculation is enormously useful when you're reading in large data sets. Because it can give you a sense of you know do I have enough memory. Is the reason, if you grunt any errors, you'll know whether the error is because of memory, running out of memory or not. So I encourage you to do this kind of calculation when you're going to be reading in large data sets. And you, and you, and you know in advance kind of how big it's going to be 

2 - 15 - Textual Data Formats [4_58]
There are other types of formats that you can save data in beyond the tabular format, beyond, or the CSV file or text file. These are also textual formats, but they are a little bit different for, from the tabular data that we've talked about before. And the two main functions for writing out data and f, are dumping and dputing. So, and, and the idea behind these types of formats is they're text formats, but they're not really, they're not really formatted in a way that's, in the same as like a table because they contain a little bit more meta-data. So data about, for example, the type of the data in, in each class, object for example. So if you, if you dump or dput a data frame. It will include in the output, that the class of each column, of the data frame, so that you don't have to specify it when you read it in. And so the advantage of, of doing, using this type of mechanism to store data or to read, or to read data, is that you don't have, it's still a textual format, which can be useful, but it also contains metadata, so that you don't have to specify it every single time you read it in. Because that, if you don't, ca, if the metadata do not get carried with the data set itself, then it, they ca, they can get lost if you, if they get transferred somewhere else and if you don't remember what the metadata are, for example the classes of the different columns, then you kind of have to reconstruct that from scratch. So that's one advantage of using, using a function like dump or dput to, to output data from R. And similarly the, the, the, the functions for reading data using, fr, that haven't been outputted from dump or dput are source and, dget. So in general, the textual formats are very nice formats for storing data because, there's a number of different types of, different advantages to them. First of all, they're editable, so you can, if you want to you can edit them. I wouldn't say this is something that I would advice, but because of you wanted something that's reproducible. But, for example if something gets corrupted then you can look at the file to see if it's possible to recover it. So textual formats can be a little longer lived, if you're going to be storing data for a long time, sometimes it's useful to, if it's possible to use a type of textual format so that you can avoid problem, potential problems with corruption. Textual formats can also work better if you're using like a version control program, like subversion or git, where you're tracking changes between documents. and, and those types of programs tend to be much more useful with textual data rather than binary data, so that you can track changes meaningfully. Textual formats adhere to the general kind of Unix philosophy, which is to store all kinds of data, which generally stores all kinds of data in text. But the one downside of textual formats is that they tend not to be space efficient, so they tend to, they tend to take up a lot of space, and so, it often need to be compressed. So, d, the dput function takes an arbitrary R object, and it will, use, it will take most types of R objects except for some more exotic ones, and it will create some R code that will essentially reconstruct the object in R. So here's I'm creating a small data frame, it's got two columns, the first column is called A the second column is called B, and then I'm going to dput this data frame. And you'll see the out, if you discall dput it'll just output the results to the console. And you can see that what I've done is that. What it does, it, it's re, it's constructed some R code. For example, it's creating this list that has these two elements in it. And you can see that each element has has the data that's in it. And it has the names embedded here, it's got the row names here. And it has the class of the object which, in this case, is the data frame. And so, all the metadata here like the row names and the names and the class are all included in the output. Now, of course, you generally don't want to print this to the console, that's not particularly useful, you probably want to save it to a file. So you can dput the file to a file and then later on, you can read it into R using dget, and when you dget the object, you will get this object and you will see that it's, you have kind of reconstructed the object from before. So the dput function, essentially writes R code, which can be used to reconstruct an R object. The dump function is a lot like dget however, the difference is that dget can only be used on a single R object. Whereas dump can be used on multiple R objects and so what you do is what you pass a dump is the character vector which contains the names of the objects. So here I created two objects one called x, the other called y and when I pass the dump. Is are the names of those objects? The names are X and Y. And I give it a file, that I want to store the da, the objects in. And then I can remove them if I want to, but to read those objects back into R, I can call the source function on that file and you'll see that the Y object and the X object have been reconstructed. 

2 - 16 - Connections_ Interfaces to the Outside World [4_35]
So there are a variety of ways that you can interface between R, R, wi, with the outside world. And generally speaking there are functions that, that are used to kind of open up the what are called connections to the outside world. Usually you want to, the most common type of connection is to me, is to a file, so for example if you want to read a file then you can, you can create a file connection, you might want to for example o, or read a compressed file, or that's a slight variation on that. And most functions will do this in the background without you having to know what's going on. So for example, when you call read.table with it and you pass it the name of a file, what it does behind the scenes is it opens up a file connection to that file, and then reads from that file connection. The connection can be made to other types of objects too. For example, you can open a connection to a webpage using the URL function. And so, when you open a connection to a webpage, you can read data from that webpage using the URL connection. And so, the idea behind the connection interface is, is that it kind of, that it abstracts out. The mechanism for connecting to different types of objects that are external to R, whether they be files, or webpages, or whatever. So the file function is the function that opens a connection to a standard uncompressed file. So this, this can be useful for text files, for, for reading in other types of text files. Gzfile and bzfile, are used for opening connections to compressed data files. So gz file i, are, is used for files that are compressed with the gzip algorithm and bz files used for, is for opening connections to files compressed with the bzip2 algorithm. Files that are compressed with gzip usually have a gz extension and files compressed with bzip2 usually have a bz2 extension. So the file function here has a few arguments, the description argument is the name of the file and there's a flag that's called, that goes to the open argument and you have to know what the codes are, but basically r is for reading, w is for writing, a is for appending, and then rb, wb and ab are for reading, writing, and appending on binary files. The other options for file are not particularly important at this time. So, connections can be very powerful and they can let you navigate files and other external objects in a more sophisticated way than just, like, reading the whole thing, for example. And generally you don't have to deal with the connect interface in many cases, but sometimes it's useful. So for example, so here I've got a simple example or opening a fi, a file connection to some file called foo.text, I'm going to open it for reading. I can call read.csv on the connection, and that by default will just read the entire file then I can close the connection. So that three line process is the same as just calling read.csv on the file. So in this case there was no need to use the connection to read the file. However, sometimes a connection can be useful if you want to read parts of a file. So for example, here I've got the readLines function which just reads lines from a text file. And I'm going to open up this words.gz file. So, this is a file that has words in it for it's like a dictionary file. And it's compressed using the gz, the gzip algorithm. So I'm going to be using the gz file function to open a connection to that. And I'm just going to read the first ten lines. So now I'm going to re, use this connection, and to read the first ten lines. And here, the first ten lines are printed out here as you can see these are the first top ten words in the file. And similarly, write lines is a, is a function that can be used to write out lines of text to a file. And each, and what you do is pass write lines of character vector and each element of the character vector becomes a line in the text file. You can also use readLines to read elements from a web page, so for example, you can use the URL function to create a connection to a website, so this website here is the Johns Hopkins School of Public Health website. And I'm going to open the connection there for reading, and then I'm going to read lines from this connection. And so and I'm, and then and so the lines of text that come from the connection are going to be stored in this character vector x. So when I look at the first couple of lines from x you can see that it looks like HTML which is kind of what you would expect. And so the URL function is useful for creating a connection to a kind of a non file object. and then using read.lines is useful to read the text from that connection. So this is another way to read data beyond using functions like read.table or read.csv 

2 - 17 - Subsetting - Basics
[NOISE] I'm going to continue to talk about data types, and basic operations in R. In particular in this video I'm going to talk about subsetting objects in R. So there are a couple of different operators that you can use, to extract subsets of diff, of R objects. There's the single bracket. Sorry, the single square bracket. The double square bracket, which we saw in the previous video, and there's the dollar sign. So the sing, the basic kind of principles to remember here is that the single square bracket always returns an object of the same class as the original. So the subset a vector, you're going to get back a vector. If you subset a list, you're going to get back a list. Any time you used the single bracket operator to subset an object, you'll get the same, an object of the same class back. si, furthermore the single bracket operator can be used to select more than one element of an object. With one ex, exception that we'll get to later. But double bracket operator is used to extract elements of a list or a data frame. It can only be used to exa, extract a single element and. Of that object, either the list or the data frame. And the class of the returned object will not necessarily be a list or a data frame. So the idea with the double bracket operator is that, remember that lists can, can, can hold things that are of many different classes. They don't all have to be the same. So, the first element might be a vec a numeric vector, the second element might be a data frame, the third element might be a complex vector, et cetera. And so when you use the double bracket operator to extract an element of a list, the oh, the object that comes back maybe, may not be a list, it may be an object of a totally different class. So that's what the double brack operator is useful for. The dollar sign is used to extract elements of a list, again of a list or data frame that have a name. Very similar objects can have names and the reason, one of the reasons you've used names in an object is so that you can reference elements of the object by the different names. Otherwise the, the semantics of the dollar sign are similar to the double bracket in the sense that when you use the dollar sign to extract an element of an object it may or may not be of the same class as the original object. So, here is the first, the first example, a very simple vector, a character vector called x. And and I'm going to use the single bracket operator to extract the first element. So here, what I get back is a, is another character vector with the single element a in it. If I, if I use, if I try to extract the second element of x, what I would get returned back to me is a character vector with the element b in it. I could also extract a sequence of elements so if I say, If I, If I want to get the first four elements of x I can cre, construct the sequence one through four and then I get a, b, c, c. So in these three examples here what I've done is I, I, is I subset the vector x using a numeric index so the numeric index is one, two or the sequence one through four. The oth, another type of index that you can use is the, is a logical index. So, in this next example here, I'm going to subset the vector x and I want, I only want all the elements were, that are greater than or equ, sorry, that are greater than the letter a, right? So, you might, it might seem strange to you that I'm using the greater than sign with letters instead of numbers but there is a lexicographical ordering to the letters, and all the letters that are greater than a are letters like b, c, d, e, et cetera. So what I get returned to me is a character vector that only contains the letters that are greater than a. So, here I've got b, c, c, and d. The other thing I can do, is I can create a logical vector, which here I call u, which is just the it's a, it's, it tells it's a true or false vector, which tells me, which tells me which elements of the vector x are greater than a. So, if I print out u here I can see that the, the first element is equal to a, so it's not greater than a. Then, the next four are greater than a, but then the last element is equal to a, so again, that's false. And so, I can subset the vector x with this u vector, and then I get out all the elements that are greater than a. So there are two types of indices that I use here, one, the first type with the numeric index. And the second type was the logical index. 

2 - 18 - Subsetting - Lists
So subsetting a list is a little bit different. Because you can use the double bracket or the dollar sign operator. You can also use the single bracket operator. So here I've got a list, the first element is called, is a named element called foo. That's an ind, and it's a sequence 1 through 4. And the second element is named bar, and it's the number 0.6. So this is a list of two elements in it. I can extract the first element by using the single square bracket. And I get, when I, remember the single square bracket always returns the element that's the same class as the original. So if x is a list, than x bracket 1 is going to be a list too. So what I get back is a list that has element call foo, which is a sequence 1 through 4. Now if I use, so if I use the double bracket then if I said x double bracket 1, what I get back is just a sequence, 1 through 4. So, so the difference here is that in the first example, I got a list that contained the sequence 1 through 4, and in the second example, I got just the sequence. That's the difference between the single bracket and the double bracket operator. In the next example here I'm using a dollar sign. And so I'm saying, x dollar bar. And that what that mean is that, that gives me that element that is associated with the name bar. So in that case it's the, it's a single number 0.6. I can also use the double bracket operator and pass in a string. So x double bracket quote bar is the same as doing as x dollar bar and it just gives me 0.6. If I use the single bracket with the name, I can say x bracket quote bar, that gives me a list with the element bar in it. So remember, because the single bracket always returns a list if I'm going to subset a list. So the nice thing about being able to subset an element using its name, is that you don't have to remember where it is in the list. So if I couldn't remember whether bar was the first element or was the second element, I don't have to remember whether, what, where it is in order to use the numeric index. I can just use its name, and then I don't have to, then it will automatically extract that, extract that element from the list. If you want to extract multiple elements of a list then you need to use the single bracket operator. So for example, if I want the third, the first and the third element here, in which case, which is the foo and the baz element, I can pass a, a vector, a 1, 3, the numeric vector 1, 3 to x using the single bracket operator. And that returns to me a list with the elements foo and the elements baz. So that's how I extract multiple elements of a list. There's, you cannot use the double bracket or the dollar sign operators when you only extract multiple elements of a list. The nice thing about the double bracket operator, which is different from the dollar sign, is that you can use the double bracket operator to, to, to index it a list, where the index itself was computed. So, notice that when I used the dollar sign before, I had to, I actually typed out the word bar. I had to type out the name of the object. Sometimes the name of, sorry the name of the element. But sometimes the name of the element is actually the result of some computation. So for example here I've got a list with three elements, foo, bar, and baz. And then I create a variable called name which is actually the string foo. So if I use the double bracket operator on this variable here. Notice that the there's no element in the list that has the name, name in it. But there is an element in the list that has the name foo in it. So now when I, when I pass this variable called name into the double bracket operator, it returns me the, the element that was associated with foo. because that's what the value of the name variable is. So if I can, if I compute the index that I want to use, then I have to use the double bracket operator. If I use the dollar sign, then it's going to literally look for an element of the list that's, that has the word name associated with it, and that of course doesn't exist in this list. So to use the dollar sign I need to use a literal symbol. Now, the double bracket operator can take an integer sequence in as, rather than a single number, and the way you can think of this is that it kind of recurses into the list. So if you look at this current list I've got here, with the first element a is another list which has elements 10, 12 and 14. So suppose I wanted to extract the number 14. Well, that's really the third element of the first element, right? So it's the third element of the list, which happens to be the first element of the other list. And so I can extract the 1, 3 element term by passing the vector 1, 3 to it to the x list using the double bracket operator. And that's equivalent to kind of doing this double sub-setting of one and three. I can also extract the first element of the second element by use, by passing the integer vector 2,1 to get 3.14 

2 - 19 - Subsetting - Matrices
Matrices can be subsetted, in the kind of the, the way that you would expect. So the first index is going to be, the, the row index, the second index is going to be the column index, and we can use numbers for this too. So, so for example, x is a matrix, it's a two by three matrix with the numbers one through six in it, if I take x with the, with the [1, 2] that gives me the first row second column, and so that's going to be the, the number three, and then the, the second row first column is going to be the number two. You don't have to always specify both indices when subsetting a matrix, So for example if I say x bracket 1, comma and then blank for the second index, that's in, that notation indicates that I want the first row of the matrix, in which case the, this is a vector one, three, five. If I wanted the second column of the matrix I could just leave the first index blank and say x bracket and then comma two, that gives me the second column which is three, four. So by default when a single element of a matrix is retrieved, is returned to vector of length one, rather than a one by one matrix. So remember I said that before, the si, the single square operator always returns an object of the same class, so, the one that's, that sometimes is a little bit unexpected, is that if I subset out, a single element of a matrix, I don't get back a matrix, what I get back is just a vector with that number in it, so if I say x, one, two, that gives the first row second column of the matrix, that's just a number three, and what I get back is a number three, [COUGH] not a one by one matrix, with the number three in it. This is usually what you want, although sometimes it can cause problems, and so you can turn off this default behavior by adding an extra argument to the subsetting operation, which is called drop. And the idea is that by default, drop is equal to true, and it drops the dimension, and so rather than getting a two dimensional object back, you, you typically get a one dimensional object back. However if you want to preserve the dimensions of the object, you can say drop equal to false and when I subset out the first row, second column, what I get back is a one by one matrix with the element three in it. Now also when you subset a single column or a single row, you don't, you, you by default, you don't get a matrix back, so for example, if I subset out the first row here you might think that, well, what should be returned, is really a one by three matrix where there's one row and three columns, and the elements are one, three, five. Well that's not actually what you get back, what you get back, is a vector with the elements one, three, five. Usually this is what you want, and it's okay, but if it's not, then you can always set the drop equal to false argument when you subset the matrix, and then you get a one by three matrix with the elements one, three, and five in it. 

2 - 20 - Subsetting - Partial Matching
So partial matching is a handy tool which it, which it often saves you a lot of typing at the command line. It's not particularly useful when you're pro, when you're writing out programs and functions but it's very useful when you're kind of working at the command like typing things as fast as you can. So the idea with partial matching is that it works with the double bracket and the single, and the dollar sign operator. So, suppose I have a list x which has an element in it called aardvark which is the sequence 1 through 5. And suppose typing out the word aardvark every single time is a bit of a pain so I'm just going to type the word a. Well, the way the dollar sign works by default is that it looks for it looks for a name in this list, that matches the letter a. In this case there's only one element. And so you get you get the word aardvark. And then it gives me the, the el, the object associated with aardvark, which is the sequence 1 through 5. So if I use the double bracket operator things are a little bit different. So what the double bracket operator expects, is that it's going to be, that the name that you pass it is going to be an exact match for one of the names in the list. So by default the double bracket operator doesn't do partial matching like the dollar sign does. So now when I pass x double bracket a what happens is I get null back, because there's no element of the list that has the name a. But there's a some, a second argument that you can pass to the dou, double bracket operator, which is the exact argument. And if you specify that exact equals false. And then when I pass at x double bracket a, it gives me the sequence 1 through 5, because that's the one that mat, matches the letter a the closest. 

2 - 21 - Subsetting - Removing Missing Values
Last thing I want to talk about is removing missing values or NA values from an object. This is a very common operation in, in, in data analysis because most realistic data have lots of missing values. And so the way you can do this for, of either a vector, or a matrix, or a data frame is you want to create a logical vector which tells you where the NA's are and so that you can remove them by sub-setting. So here I've got a, a vector x, this is a very simple example. Which has the numbers 1, 2 and 4 and 5. But then there are missing elements NA in the third position and in the fifth position. So what I want to do is I want to get a vector back that's just one two four five, the non missing values. And I want to strip out the missing value so I can maybe do some computation. So, what I, the first thing I do is I use the is.na function to, to go through the vector and tell me which elements are NA and I create a new vector called, which I called bad here. So, bad is going to be a logical vector which tells, which, which is true if the element is missing and false if it's not missing. So, even though I haven't printed it here the, the, the bad vector is going to be a logical vector that has false, false, true, false, true, false. Right, because the third and the fifth elements are missing. So, when I. Now that tells me which ones are missing but actually I don't want the ones that are missing, I want the ones that are non missing. So I need to take the kind of the opposite of bad which I can use with the bang operator or exclamation point. So now I take x single bracket bang bad and that gives me the good elements which are 1, 2, 4 and 5. So what if there are a multiple vectors or multiple objects and you want to take and each one has a kind of missing values in slightly different places and you kind of, you want to take the subset of all the objects that have no missing values, all right? So here I created an x, a vector called x. Which is 1, 2, 4 and 5, and missing values scattered about. And then y is, is a character vector with also some missing values in it. So I can use the complete cases function on both vectors which will give me a vector that tells me which of, of, of the two different vectors, which ones had were, which, which are, which positions are there that have both elements non missing. So you can see the first two are, are both non missing. I got 1, 2, in the first one, and a, b in the second one. The third one's missing, the fourth one is non missing the, the fifth one is missing and the sixth one is non missing. So, of, for the both, for both vectors x and y, I want the first, the second, the fourth, and the sixth elements. So now when I subset x, I get the good elements of that, and when I subset y, I also get the good elements of that. So that's how I can look at multiple objects and kind of subset all the missing values out to get the good elements. You could also remove you can also use complete cases to remove missing values from data frames. So here I've got a simple data frame where I'm showing the first six rows. As you can see there are six columns to this data frame so there's six variables. And there's some missing values in the ozone variable and there's some missing values in the solar.r variable. And so all I want is the is the, is the, are the rows of the data frame where all the values are non missing, right? So in this simple example, the rows that I want are rows 1 through 4. So I can use complete cases on air, on the airquality data frame. And I create a, a logical vector that I called good here, so the logical vector here tells me which rows are complete. And then when I subset out the air quality matrix take and take out the first couple of rows you can see that I now, that none of the rows have any missing values in them. So that's subsetting out missing values. And there, in complete cases of very handy function which is when, when you have multiple sets of vectors or dat, or large data frames or you want to subset all out, all the missing values. 

2 - 22 - Vectorized Operations [3_46]
This is just a simple note on vectorized operations in R. So, vectorized operations, is one of the features of the R language that make it, that makes it easy to use, on the command line. It makes very, kind of, nice to write code, without having to do lots of looping, and things like that. And so, it's kind of a natural thing to have in a computational language. Many other types of languages, like MATLAB have this kind of feature. so, the idea with vectorized operations is, is that things can happen in parallel, when you, for example want to do a computation. For example, suppose I got two vectors here x and y. x is the sequence one through four and y is the sequence six through nine. And I want to add the two vectors together. Now, when I say I want to add them, what I mean is I want to add the first element of x to the first element of y, the second element of x to the second element of y, et cetera, the third element to the third element. So I want to kind of do things in parallel like that. So, in other languages you might have to use a loop to do that, so you'd loop through each element and kind of add them one by one. But in R you can just use the plus to, on the two vectors, and it'll just add them together so x plus y kind of does what you would expect. It adds 1 to 6, 2 to 7, 3 to 8, and 4 to 9, so you get the vector 7, 9, 11, 13. similarly, you can use the greater than, or less than symbols to, give you logical vectors. For example, x greater than 2. So well x is actually a, a vector of 4 numbers. So, which one, so, which number are you comparing to 2? Well, the, the vectorized operation compares all the numbers to 2, and it gives you a vector of falses and trues depending on which numbers happen to be bigger than 2. So you can also use greater than equal to, and that'll tell you which numbers are greater than and equal to 2, and the double equals sign, tests for equality. So it'll take each element of y and test to see whether it's equal to 8. other, and the other kind of, or arithmetic operations like multiplication, by the asterisk, and division, by the solidus, are all vectorized types of operation. So when you want to multiply or divide, add, subtract, vectors, you just you can do the natural thing, just add them together or multiply them together, and they will be, and they will be the operation will be done in parallel. Similarly you can do, you can do You can add make, you can add and subtract, and multiply and divide matrices together. So it's useful to know this because there are different types of mult matrix multiplication. So I've created two matrices here, x and y. X is the matrix 1 through 4, it's a two by two matrix. And y is a, is a matrix that's all tens, it's also a two by two matrix. So if I just do x times y, this is not a mat, matrix multiplication. This is an element-wise multiplication. So the first, the kind of the 1, 1 element of x is multiplied by the 1, 1 element of y. And the 2,2 element is multiplying the 2,2 element of, of the other matrix, et cetera. So, each element is multiplied, together in parallel. Same when you do division. This is not a matrix inverse or something like that, this is just dividing one matrix, literally element by element by another. So if you want to do a true matrix multiplication, you have to use the %*%, that's the symbol for a matrix multiplication. So when you, so, this is just, that's it for vectorized operations for now, You'll see these a lot more often later on, but the idea, but I just wanted to introduce this idea, because it makes code easier to write. And for those of you who are kind of used to other types of programming languages, if you've programmed in languages where you can't do this kind of thing, it's sometimes, it's common to kind of reflexively go to something like a for loop or a while loop or whatever it is. But in the but in a language like R, you can just use the vectorized operations to make the code a lot simpler. 

2 - 23 - Introduction to swirl
Hi, everyone. I just want to introduce a experimental feature that we've, that we've developed for the R programming class. It's called Statistics with Interactive R Learning or SWIRL for short. And it's, and it was developed by Nick Carchedi, who's a student here at the Johns Hopkins department of bio-statistics. This is a system that allows you to kind of interactively learn R at your own pace. And it will walk you through a, a bunch of lessons about different aspects of the R language and you can kind of practice as you go. So, rather than kind of watching a lecture and then, you know, doing an assignment and kind of doing things piece by piece, you can actually work on R right in the R console in, in a kind of guided way. Rather than kind of just figuring things out on your own. So, I think this, the SWIRL modules are really helpful and I encourage you to try to walk through them. If you decide to complete them you'll get you'll get a little extra credit through the programming assignment. But the, the modules are absolutely not required. They are totally optional. And so, you don't have to worry about doing them. You can still do perfectly well in the class without doing the SWIRL modules. Nevertheless, I encourage you to try it out. I think it'll be a lot of fun. 

3 - 1 - Control Structures - Introduction [0_54]
Control structures in R allow you to control the flow of an R program. And are very similar to the control structures that you might see in other types of programming languages. The basic constructs are things like, if else for testing logical conditions. The four for executing a loop a fixed number of times. While executes a loop while a condition is true. Repeat is a, is a construct that allows you to just simp, to immediately execute an infinite loop. Break allows you to break out of any type of loop. And next, skips to the iteration we will loop and return allows you to exit a function. So, most of these control structures are not things that you use in interactive sessions and not like, while you are typing at the command line in R. These are the kinds of things that typically you would use when you are writing a R program or an R function. It's a little bit more of a structured format. 

3 - 2 - Control Structures - If-else [1_58]
So the first structure is if, so this is a, this, the, the if combined with else allows you to test logic conditions, and to let the r program do something, give, whether or not, depending on whether that conditions is true or false. So if the condition is true then you do something else you do something else. That's the typical kind of construct. The else part is optional, so you could just have an if statement to do something if something is true. But you can have the else part if you wanted to do something alternatively. If you want to do more, there's more than one possible type of condition you can tick, you, you want to check. You can say if, and then, else, if and then, else. else, if there can be any number of else, if conditions in a constraint like this and the else one has to be at the end. So there are a couple of different ways that you can formulate the if else construct in r, it's a little, this is a little bit different from other languages. Case you haven't seen something like this. So the first is pretty standard if x, if the con, if sorry if the symbol x is greater than 3 then you select, you set y equal to 10. If it's not greater than 3 then you set y equal to 0. So that's inside the if-else construct, there's, there's an assignment of y to a specific type of value depending on what the value of 3, of x if. But however in r you can do it a different way you can say y is equal to the entire if else construct. So if x is greater than 3, 10 or 0 depending on whether that conditions true or not. So this is a valid formulation also. Sometimes it's, it's, it's useful to read this type of writing because it, it allows you to realize that the entire if else construct is all about assigning a value to y. So as I said before the else clause is not really necessary you can always test the condition and do something and then do nothing if that condition happens to be false. So you can and you can just test multiple conditions in a row if you want 

3 - 3 - Control Structures - For loops [4_25]
So the next contract is a for loop. So this is probably the most common type of loop oper, operator that you're going to use in r. The basic idea is that you have a loop index which is typically called i, but if you have many loops you might say j, k, l, et cetera. And a loop index is going to go from, it's going to cover a sequence of numbers typically in. integers. So for example here I've got a for loop. And it's looping over the numbers 1 through 10. So I've created the sequence of colon operator 1 through 10. And this for loop is not doing anything particularly interesting, it's just printing out the numbers so printing out i at each iteration. After the loop is finished it continues on to the next block of code. So there's different ways to use a for loop and the r is pretty flexible in how you can kind of index the different type of r objects. So here I've created a vector a character with the letters a b c d in it. And all these four loops are equivalent. So for example, in the first one, I kind of done what you might commonly see in other languages like C that have four looping. Here I have an indexed i that I sequenced through 1 through 4, I create an imager sequence. Then I print the i'th element of x, each time. So here this loop just prints out a, b, c, d. Another thing I could do is use the seek along function, so seek_along what it does is it takes a vector as an input and it creates an integer sequence that's. That's equal to the length of that vector. So this is a vector of length 4, so it's going to create an integer sequence 1 through 4. It's exactly the same as, as the previous sequence where I've got the sequence 1:4. However, here I generate the sequence based on the length of the variable x. So now I'm, my index serial i is going through this sequence. It's printing out the i filament of x and exactly the same behavior occurs. I print out a, b, c and d. The third example here, I'm, I've got a different index variable, I'm calling it letter, and the index variable is actually going to be index, is going to be taking values from the vector itself. So there's no reason why the index variable has to be an integer. It can take elements from any arbitrary vector. So now the for loop is going through this vector of letters, a,b,c,d. An it's just going to print out the letter itself, so now I'm printing out the index variable, which happens to be equal to the letters in the vector. And so these three for loops are exactly the same so far. The last version here is, is the, is the same as the first one except I haven't included the curly braces, and so for a single expression if you. If the for loop only has a single expression in this body you can omit the curly braces and put everything on one line, which maybe useful sometimes because it's a little bit more compact. But it's not my particular style. For for loops, I generally like to put the curly braces in, regardless of how many elements are in the body. For loops can be nested so you can have a for loop inside of a for loop, so the common thing for example, and and is, is with a matrix that has two dimensions and then you might want to loop over the rows and then loop over the columns. So here the outer loop the ought with the i index is seek, is looping over the rose. And I'm using a function that's called seek_lense, so, the idea is that, it takes, in, seek_lense takes an integer, which in this case happens to be the number of rows in x, and then it creates an integer sequence out of that. So this particular matrix has two rows, so it's going to create the sequence of 1 to 2. For example, similarly the the nested loop with the j index is using the number of columns to create a sequence so this matrix has three columns, and so the seek_Lense function is going to create an integer sequence 1 through 3. So the, so this doubling nested for loop, is basically printing out all the elements of the matrix. So one thing to be careful with, with nested for loops is that it's going beyond 2-to-3 levels, while it's theoretically okay in r, it makes reading the code a little bit difficult to do. And so if you're reading code that has three or four nested for loops it gets difficult to understand what's, what's going on. Sometimes that's the logical thing to do, but many a times there's ways to get around that, for example, by using functions. 

3 - 4 - Control Structures - While loops [3_22]
So the while loop is a, is the other major looping construct in R. And the basic idea is that the while takes a logical expression and will execute the loop based on the value of that logical expression. So for example, I've got a very simple loop here. It initializes a count variable equal to 0. And then while that count is less than 10 it prints out the count and then increments the count by 1. So, as soon as the, the value of count gets to 10 the loop stops and then it'll go on to the next body of code. So so the, so the while loop makes, the while loop is useful because it makes things easy to read sometimes. It's very obvious here that this loop is supposed to stop working or stop executing when the value of account variable is 10 or more. So it makes a little bit more readable. How after, however you have to be a little bit careful with, with while loops because technically speaking they are infinite loops while the and there's no. You have to make sure that the, the condition that stops the loop will actually occur, otherwise your program will never finish. And so in this case, it's fairly obvious that the loop will eventually stop executing. But a much more piece of code it can be hard sometimes whether the while loop will finish. And so often it's safer to to use something like a for loop that has a hard limit on the number of times it can execute. So, it's not necessarily saying that you should never use a while loop but you just have to be careful when you do use them. So, you can, you can test multiple conditions in a while loop or in any type of construct, like an if statement, for example by using the logical operators. So, here I've got a variable z. Which is equal, which I initialized to the value 5. The condition for the while is basically while z is greater than equal to 3 and is less than or equal to 10. So, while it's between the values of 3 and 10. Then what I'm going to do is print the value of z. I'm going to flip a coin, a fair coin, and if the coin is a 1 I'm going to add 1 to the my value and if it's less than 1, sorry, excuse me, if it's, if the coin is equal to 0 or any other value for that matter I'm going to subtract 1 from z. So this, I'm sharing a little random lock here, and the value of z is going to go up or down depending on my little coin flip here. So when, so here you see it's a little bit harder to tell when the while loop will finish. Because the, the body of the while loop involves ra, random random number generation. So here the z value's going to zigzag up and down until it eventually hits 10 or eventually it hits 3 or something less than 3. And so this, this may be kind of nice, but you have to be careful that it doesn't go off for too long. So, one thing to note, on a more technical level is that the conditions in a, when r tests the condition in a kind of a multi-expression condition here, I've got a c who I created because of the 3 and z less than of equal to the 10. The conditions are always evaluated from left to right, so check to see if the left's most condition is true and then it goes to the next condition. So, first, it'll check to see if z is greater than or equal to 3. If that's true then, if that happens to be true, it'll go to the next expression. It'll say, it'll check to see if z is less than or equal to 10. So then, if those are both true, it goes onto the next into the body of the loop. 

3 - 5 - Control Structures - Repeat, Next, Break [4_57]
Repeat is a construct that basically intiali, initiates and infinite loop. This is not a what I would characterize as a commonly used control structure in R but it does have its use occasionally. So the only way to exit a repeat loop is to call break, so obviously you are going to have to call break at some point, unless you feel like running your program, you know, forever. So here is a pretty simple example, here I am initializing a value of x 0 to be 1, and I am saying what I think of as a tolerance to be 10 to the minus 8, and then I am going to repeat the following structure. Basically, I'm going to, I imagine that some function that keep computing estimate for x and I'm going to call that x1. And basically if, if the new value of x that is x1, is, is, if the absolute value of the difference between x1 and x0 is less than some tolerance, in this case 10 to the minus 8, then I'm going to stop the loop and then move on to the next bit of code. If, if the, if the difference is greater than my tolerance, then I set x0 to be equal to the new value. And then I, I run the loop again, I calculate a new estimate and I check to see if, if the difference is small. So, this is a common type of formulation in in many types of optimization algorithms, for example, if you're trying to find the solution to some set of equations, or you're trying to maximize the function, often you'll iterate over and over again. And and you'll stop when the, when the estimates that you're calculating are getting closer and closer together, because that's usually a sign that you're kind of converging to whatever the minimum or ma, or maximum of the objective function is. So this is a, in theory this is a perfectly reasonable construction. You want to keep recycling through the algorithm until the two values are close. So there's one problem which is that first of all requires an algorithm that is guaranteed to converge and not necessarily every algorithm has that property. Second of all, als, it doe, it, it does depend a little bit on the tolerance of the re, the loop will run longer if the tolerance is smaller, generally speaking. And because it's hard to predict how how long this loop will run. It can be a little bit dangerous because it's a little bit because it's unpredictable, it, it, it could theoretically run forever, and you have no gar, way to guarantee that the program will stop at some point. So this construct, although it's theoretically kind of the right thing to do it's usually not a good idea. It's better, probably be better off to use a for loop that has a, has a hard limit on the number of iterations that it's allowed to run. That way, if you have a problem with your algorithm, it will eventually reach the hard limit and stop and, and you will know that the reason it stopped is because it didn't converge and then maybe you can try to fix something about the algorithm. But with a repeat type of approach if your algorithm is not converging you won't have any warning it will just be running a really long time. The last control structure element I want to talk about is next and then there's also return. Next is basically used in any time of looping construct when you want to skip an iteration. So here I've got a basic four loop which is going to run for 100 iterations. And then but the idea is I want to skip the first 20 iterations and then only kind of execute some code when it's, when it offer iterations 20 through 100. So here I've got a basic, I've got a very simple if condition. So if i is less than or equal to 20 I'm just going to skip, so I hit, I use the next expression, and it will skip everything else in the, in the four loop and go and iterate again. So once i gets beyond 20 then of course the expression i let's less than or equal to 20 will be false. And so it won't execute the next, it will go into whatever the body of the code for the for loop is. so, so next is another, is a way to skip an iteration in, in a loop. And of course break is a way to execute the, exit the loop entirely. The return function is, is another function that can use the exit, exit a loop and it's primarily used to exit a function. So it will, it will exit the entire function and return a value that you pass it, so we will talk more about return when we talk about functions. but, it's something that can break that it can interrupt the flow of a program too. So, that's control structures for now so the basic summary is that control structures like if, while and for that can allow you to control the flow of an R, of an R program. Generally speaking while there are construct, constructs that kind of allow you to execute infinite loops you generally want to be on the look out for these kinds of things and to avoid them if possible. Even if they are kind of theoretically correct because they can lead to kind of some unpredictable behavior in programs. And the other key thing I have mentioned yet is the, the control measures that I've mentioned here are primarily useful for writing programs and think I mentioned that in the beginning. But for command line and interactive work there are other types of looping type functions that we can use, they generally have the word apply in them. And they can be a lot more useful for for command line interactive work when you're exploring data and things like that, not writing programs although they can be very useful in writing programs too. So I'll talk about apply functions except in a separate of videos. 

3 - 6 - Your First R Function [10_29]
In this lecture, I just want to get everyone on board with writing functions, because functions play a critical role in any art programming and you tend to write a lot of them when you're writing doing a lot of data analysis or doing a lot of kind of statistical analysis. And so I just want to make sure that everyone can kind of get started writing functions and and particularly for those who are less familiar with programming languages in general. So this is just going to be about writing your first function. It's kind of like the hello world so to speak of R. So the first thing you're going to want to do is you going to want to write the function in a text file, all right. It's possible to write functions on the command line in R, but it usually no preferrable. So usually you're going to want to put your functions, in a separate file, separate from any interactive stuff that you're doing in the command line. In the future you'll want to put your functions in an R package, which is a kind of a more structured type of kind of, kind of environment with documentation and everything, but we won't talk about that now. Right now the first thing you're going to want to do is put your functions in a text file. Okay, so the first thing we're going to want to do is open up our studio. So lets do that. And so you can see here in R Studio there's some there's some stuff going on here from a previous project that I'm working on. So you, that may happen to you, and generally you can either close it or you can just ignore it. I wanted to create a new R script here, so let's create a clean script here to put our code into. So the first function I'm going to write is really simple it's just going to take two numbers and add them together. So this function obviously doesn't have a real point to it but it shows you how to use the function syntax, how to specify the arguments and how to return the value. So the function that adds two values I'm just going to call it add two. And and so you get it you use the function directive to start it off. Now it's going to take it's going to add two values so it has to take two arguments so I'm just going call the two arguments x and y and then I'm going to take the two arguments and add them together with the plus operator alright x plus y and then I close out the function with the curly brace. So you can see that I didn't have to do anything special to return the value that that's the sum of the two elements because the or any R function, the, the function returns whatever the last expression was. So here there's only really one expression. So therefore its the last expression and, and it equals the sum of x and y. So here I can, I can highlight this guy and run it in the console, and you can see now I've got my function here. I can say add two, and lets give it say three and five and hopefully I get eight. Yes that's a good sign. So it adds the two numbers together, and that's that. So it's a very simple function, and and, you've now written your first function in R. S the next function that I want to talk about is a little slightly more complicated. It's going to take a vector of numbers, it's going to, it's going to return the subset of the vector, that's, that's above the vector value of ten. So any number that's bigger than ten, it's going to return those numbers for you. so, let's bring back our original function. We'll call this one, above ten. Just because it gives you any number that's above ten. snd, it's going to take a vector here, we'll call it x, you don't have to call it x, I'm just calling it that. And I like to open and close the curly braces right away, just so you know where the beginning and the end of the function is. If you happen to have a lot of code in, you know, in, in a single file. So the first thing I'm going to want to do is I want to construct a logical statement that figures out which elements of this vector x are, are greater than ten. All right? So I'm going to assign an object. I'll call it use because these are, these are the numbers that I'm going to use. And I'll say x greater than ten. All right? So this'll return a logical vector, of trues and falses to indicating which element of x is greater than ten. And then I'm going to subset the vector x with this logical vector. So now this function returns, the subset of the vector x that is bigger than ten. Of course if there are no elements of x that are bigger than ten, that it will return an empty numeric vector. Now of course, there's really nothing special about the number ten. I just kind of made that up, and so you may want to created a function that allows people to sub, to kind of extract the elements of a vector. That are above an arbitrary other number, right? And so, so it could be ten, it could be 12, it could be five, it could be anything. So maybe you'll want to allow the user to specify that number. So I'll just call, I'll create a new function here. Call above. So it doesn't have the ten encoded in it. I'll use the function directive, and I'll have a second arbitrary called n, which can be any number really. [SOUND] So let's start it off, we'll get the curly braces in there, and now I'll create a logical statement that x is greater than n. Right? And then I'll subset the vector x based on that logical statement. So now if I can source this into R. Oops, and I can run my function here. So I'll just create a vector. Let's say x is one through 20. And I'll say above x. Oh I, you see, so I didn't specify the number n, so it's not going to know what to cut it off at, so I need to specify the threshold, so let's do ah,12. And you can see it returned all the numbers that are greater than 12. So that's kind of as we expected, and so the function appears to be working well. Now let's suppose that maybe there is something special about the number ten, and maybe it's something that people are going to be kind of be doing very often and it's a very common number. So you might you want to specify a default argument so you might want to the default to be ten, so remember when I ran the function before and I didn't specify the number n. It gave me an error or maybe you don't want people to have to encounter that error, and so you'll specify a default value n equals ten so people don't specify the cutoff value n, it will just automatically default to ten. So now I can run this in R and now if I do above, which is x, you see I don't get the error anymore. It automatically gives you all the numbers that are bigger than ten. So it's kind of nice in R when you're writing functions to be able to specify default values like this that make the life of the user just a little bit easier, specially for very common cases, where it's not important that the user specify an argument. So those are some very simple functions, in R that can be used to kind of process data or make do simple calculations, like adding two numbers. The next function I want to talk about is, is just going to take a matrix or a dataframe and calculate the mean of each column. Right, so this is slightly more complicated you, you have to take your argument and then you have to loop through each column to calculate the mean of each one, right. So this is going to involve using a for-loop and, and so we'll talk about it here. So let's call this function column mean, because that's what it does, and I'll use the function directive here, now it's going to take an argument. I like to call my arguments x, you don't have to so why don't we just call it y for fun. And so y is going to be a data frame or a matrix, and we're going to go through the columns of this data frame or matrix and calculate the mean of each column. So the first thing I need to figure out is how many columns does this thing have, and that can be easily done. I'll call it n c for number of columns and we can use the n call function for that. That will calculate the number of columns, and, and then I need to initialize a vector that's going to that's going to store the means for each column. The length of this vector has to equal the number of columns, right. So I'll just call it means, and it'll be a numeric vector equal to the length of the number, equal to the number of columns. So this is just an empty vector. It doesn't, it's going to have, it's going to be initialized to, to be all zeros. But we're going to fill it as we go through the column. So now we want to for-loop through the columns. And I'll say i is in and then I'll say one through nc. So this creates a, an integer vector starts a one and ends at the number of columns, and then I'm going to for-loop through and for each I, I'm just going to assign to my means vector. The mean of x bracket I, right. Oh sorry that's called y here now. And that's it, and then so for I, I haven't returned anything yet, so right now this function doesn't do anything particularly useful. But what I want to do is return the vector of means and so I'm just going to return that. And that's, since that's the last expression in the function that what will get returned. So I can source this into R, and I'll just find some arbitrary dataset. We can use the air quality dataset I guess. I'll just take the column means of that, and see how it works. Okay, so I, there are six, I think there are six columns in this dataset, so it gave me six means. Now you can see that the first two columns have NAs. And that's because it, if the, if the vector has an na in it, then you can't calculate the mean. And so the one thing you might want to do, is, by default, is throw out all of the missing values and just calculate the mean amongst the observed values. And so, you'll notice that a lot of functions have a feature where it's like, where they, you can, you can choose whether you want to remove the nas or not. But let me just add up an argument here, it's called [UNKNOWN] na. And it will default to true, right. And then I'll pass this argument to the mean function. So the mean has an na.rm argument, and I'll pass at this value. And so now I can default or remove the na's when I, calculate my column mean. So sources send to R and with the run in the console column mean, and so now the default will be now I get my means for those columns because the default was to remove the na's. I could say false here, and then my na's will come back. So I can always choose to kind of go back to the old behavior if I wanted to. So the last thing you want to do any time you're writing a function the most important thing of course is to save your file. So right now this file is unsaved. If you don't save it and R Studio crashes or something happens you'll lose all your work and so you want to go to the save I meant save as menu, and just save your file as, you know, functions or whatever you want to call it. And give it the .r extension, and now you're code is saved to a file. So that should get you started, just writing some simple functions in R, for your programming assignment you'll have to write a few functions that kind of go through and look at data. But I just wanted to get you started writing your first functions so that you know kind of how the directive, the function directive works, how the arguments work, and you can play around a little bit with with more complicated ideas as you work through the assignments. 

3 - 7 - Functions (part 1) [9_17]
Functions represent some of the most powerful aspects of the R language. And they really represent the transition of the user of R into the kind of programmer of R. And the basic idea is that you can type the command line and kind of explore some data, and run some code. But eventually you'll probably get to the point where you need to do something a little bit more complex. A little bit more than, than can be expressed in a single line or maybe in two lines. And if you have to do this over and over again, then you're usually going to want to encode this kind of functionality in a function. I'm going to talk about functions in three parts here. First I'll talk just about the basics of how to write functions and how they are written, in R. Then I'm going to talk a little bit about lexical scoping and the scoping rules, in, for the R language. And then last, I'm going to end with a little example. So, functions in R are created using the function directive and functions are stored as R objects just like anything else. So you might have a vector of integers a list of different things, a data frame, and then you have a function. So, in particular, R objects, R functions are R objects that are of the class function, okay? So, the basic instruction here is that you assign to some object, here I call it F, the, the function directive, which will take some arguments, and then inside the curly braces there is R, there is R code, which does something that the function does. So one nice thing about R is that functions are con, considered what are called first class objects. So you can treat a function just like you can treat pretty much any other R object. So importantly, this means that you can pass functions as arguments to other functions. This is actually ver, a very useful feature in statistics. And also functions can be nested. So you can define a function inside of another function, and we'll see what the implications of this are we talk about lexical scoping. So the return value of a function is simply the very last R expression in the function value to be evaluated. so, there's no special expression for returning something for a function. Although, there is a function called Return. Which we'll talk about in a second. So functions have what are called named arguments. And the named arguments can potentially have default values. So, a lot of these features are useful for when you're designing functions that, that may be used by other people. For example, you may have a function that had a lot of different arguments so you can tweak a lot of different things. But most of the time, you don't have to change all those different arguments. You may only care about one or two. So it's useful for some of the arguments to have default values. So first of all, there's the formal arguments, which are the arguments that are included in the function definition. So if you go back to the previous slide the formal arguments are the ones that are included inside this function definition here. The formal's function actually will, takes a function as an input and returns a list of all the formal arguments of a function. So not every function call in R makes use of all the formal arguments. So for example, if a, if a function has ten different arguments you may not, you may not have to specify a value for all ten of those arguments. So function arguments can be missing or they may have default values that are used when they are not specified by the users. So R function arguments can be matched positionally or by name. So when, this is very, this is key when you're writing a function and also when you're calling it. So for example, take a look at the function sd, which calculates the standard deviation of, of, of a set of numbers. So sd takes a input x, which is the name of the argument and which is going to be a vector of data. And there's a second argument called na.rm and this controls whether the missing values in the data should be removed or not. And the default value is for na.rm to be equal to false. So by default if you have missing data in your, in the, in the set of numbers for which you want to calculate the standard deviation the missing values will not be included. So, here I'm simulating some data and I'm just simulating a hundred normal random variables, and there's no missing data here. So, if I just calculate sd on the vector it'll give me an estimate of the standard deviation. If I say X equals my data that's the same thing. So here I've named the argument but I haven't but otherwise the data are the same so it'll calculate the standard deviation. In the first example I didn't name the argument. So it defaulted to passing mydata to be the first argument of the function. So in the next example here, I'm going to name both arguments. I'm going to say X equals mydata, and na.rm equals false. That calculates the same thing as before. Now when I name the arguments, I don't have to put them in any special order. So for example, I could reverse the order of the argument here. Say na.rm is equals false first, and then say x equals mydata second, and that will produce exactly the same results because I've named the arguments. Now, what happens if I name one argument and don't name the other? Well what happens is that the named argument is set, and you can figure it as being removed from the argument list, and then any other, any other things that are past will be matched to the function arguments in the order in which they, they come. So for example, SD after you remove the na.rm argument only has one more argument left and so mydata would be assigned to that argument. So all these expressions return the same exact value. So although it's generally, all these expressions are equivalent, I don't say recommend all of them equally. So for example, I don't necessarily recommend reversing the order of the arguments just because you can even though if you name them, it's appropriate. so, just, just because that can lead to some confusion. So positional matching and matching by name can be mixed and this is quite useful often for functions that have very long argument lists. And so for example the lm function here which fits linear models to data has this argument list here. So the first is the formula, the second is the data And then subset, the weights et cetera. And you see that the first five arguments here don't have any default value. So, the user has to specify them. So the but then the method, the model, the X argument, they all have default values so if you don't specify them they will use those values by default. And so the following two function calls are equivalent. I could have specified the data first and then the formula and then the model. And then, and then, and then the subset arguments or I could specify the formula first, the data second, the subset and then say model is equal to false. Now the reason why the first one is okay is because I, so I matched the data argument by name. You can imagine that that's kind of taken out of the argument list now, then Y till the X doesn't, isn't specified by name. So it's given to the first argument that hasn't already been matched. And I, in which case that's the formula. Model equal to false, so that's been matched by name so I can kind of get rid of that from the argument list. And then 1 through 100 has to be assigned to the argument that has not yet already been matched. So in this case formula was already matched, data was already matched. And so the next one is subset. So 1 to 100 get's assigned to the subset argument. So this is somewhat a confusing way to call lm, and I don't recommend that you do it this way. But, I, I wrote it this way just to demonstrate how positional matching, and matching by name can work together. A common usage for lm though is the second version here. Which say lm Y til the X. So there is a formula there. And then the next one is mydata, which the data set which you're going to grab the data from. The subset argument and then, so the first three arguments, you know, are commonly specified, every time you call lm. But then, the rest you may or may not specify and so you may, if you just want to specify one of the following arguments. It's easier just to call it out by name. so, most of the time, the named arguments are useful in the command line. When you have a long argument list and you want to use the defaults for everything except for one of the arguments, which may be in the middle or near the end of the list, and you can't usually, you know, you can't remember exactly which argument it is, whether it's the fourth, or the sixth, or the tenth argument on the argument list. And so you just call it by name, and that way you don't have to remember the order of the arguments on the argument list. Another example where this comes in handy is for plotting, because mo, many of the plot functions have very long argument lists. All of which have default values and you may only want to tweak one specific argument. And so it's useful not to have to remember, you know, what the order of that argument is on the arg, on the argument list. So function arguments can, can also be partially matched which is used, mostly useful primarily for interactive work, not so much for programming. But when you call a function, if the argument has a very long name you can match it partially so you can type part of the argument name and as long as there's a unique match there then it will, the R system will match the argument and assign the value to, to, to the correct one. So the, the, the order of the operations that R uses, first it'll check for an exact match. So if you name an argument it'll check, check to see if there's an argument that, that exactly matches that name. If there's no exact match it'll look for a partial match. And then if that doesn't work, it'll look for a positional match. 

3 - 8 - Functions (part 2) [7_13]
So, here's a function with four arguments. A, B, C and D. So, A has no default value. B, C, and D, all have default values. And so, when you define a function. You want it if both specify the names of the arguments. And, whether or not any of the arguments have default values. So null is a common argument. Sorry, common value to assign to an argument. Which mean, which can mean a variety of things, but usually means that, you know, there's nothing there. So, one of the key features of the, our language is what's called Lazy Evaluation. So Lazy Evaluation is a common model in a variety of programming languages. And the way that it works is all of the arguments to a function are only evaluated as they're needed. And so for example, if you take a look at this function over here. You can see it takes two arguments a and b. But the body of the argument only takes one thing, it takes a and then it squares it and then it returns it. And now recall that in a function, the return value whatever the last expression is evaluated. So there's only one expression in this function. So that's the last expression. And so it's the return value. So if I say f(2). What happens? Well, in R what happens is you get 4 because 2 squared is 4. Now you might be wondering what happens to B when I call (f). I never specify what the value of b is. And furthermore, b doesn't have a default value. And so what happens, what, what happens is nothing happens because the function f doesn't actually use b. And so the argument is never evaluated. And so, because it's never evaluated, there's really no error. There's nothing that's going wrong here. Now now you might say there, of course, well, the, the function F is kind of poorly defined. So why would you give and argument where that's never actually evaluated? And that's a reasonable objection, but in this case, the only, the, the function will operate correctly because because it's Because the value of 2, is positionally matched to the arg, to the argument A. Which is then squared. Here's another example of a function that's only slightly more complicated than the previous one. So this is another function that takes arguments a and b, but now what the function does is it prints out a and it prints out b. And so, when I call f of 45, look what happens. I get, well I get an error that says in print b, argument b is missing. So here, what happened is that it printed out 45 because 45 was matched to the argument a, and so there was no error. Up until the first line of the function, there was no error occurring. But then when it got to the second line, It had to evaluate the val, the argument b. And because b had no value assigned to it and no default value, then an error had to occur. So here, but you notice that the error only occurs after the 45 was printed out. And so the lazy evaluation applies, but because the argument is only evaluate when it's needed. Everything else comes before it that's valid, it will execute it until it hits the, the part that which causes an error. So there's a special argument, in. In our functions which is the dot, dot, dot argument. And it's used to indicate a variable number of arguments that can sometimes be passed on to other functions. So the three dots are often used when extending another function and you don't want to copy the entire argument list of the original function. So for example you might want to extend the plot function and just to have a little bit of a tweak or to change some of the defaults, for example. And so for example you might create a function that's called my plot. And the my plot will replicate some of the arguments of the original plot function like x and y. But it's going to change the default type arguments so that instead of creating circles for points. You want it to create lines. So you say type equal to l. So, but of course the default plot function has many, many other arguments. And you want to leave them all ultimately the same. And so, what you, what you can do is pass dot dot dot. And then though, that can used to, be used to kind of absorb all the other arguments in the plot function and then what happens is I'll take the dot dot dot and then pass it down to the original plot function, and so all those original arguments can be preserved then I don't have to retype or reconstruct all of those arguments in my extended function. There is another function. And sorry, there's another use of the dot dot dot argument, and it's for what are called generic functions so that extra arguments can be passed to the methods. So we'll talk a lot about more of this later when we talk about object oriented programming. But the basic idea is that in R there, there can be special functions called generic functions which don't do anything, but what they do is they dispatch methods to put, according for different types of data. And so the dot dot dot is used very heavily in this type of setup. lastly, so the dot dot dot argument is, is necessary when the number of arguments that are passive functions cannot be known in advance. So one good example of this usage is in the paste function. So the paste function, what is does it paste, it concatenates a set of strings together to create one string or a vector of strings and it can take a variable number of arguments. So, there is no way for the function to note advance how many arguments it's going to have to paste together and so the first argument for paste is actually dot dot dot. And therefore you can take a number of different R objects that are character vectors and then, and then paste something together using a separator and in the, which the case the default is the space. So there are other arguments to face which are set to collapse. But they come after the dot dot dot argument. Another function that has the dot dot dot as the first argument is cat. And what cat does similar to paste, it puts together, it pastes together a number of strings then it prints out the, the, the concatenated string either to a file or to a console. So you can see that there are many other arguments to cat but the first argument is going to be the set of our objects that, that are going to be concatenated. So, one catch with the dot dot dot argument is that any arguments that appear after three dots on the argument list must be named explicitly. And furthermore, cannot be partially matched. So you cannot, you can't use positional matching or partial matching for arguments that come after the three dots. because, and this kind of makes sense, because otherwise there's no way for r to know whether you are passing something to the dot dot dot or whether you are passing something to a different argument. So if I say in the first example here, where I try to paste together A and B, so A and B are going to the dot dot dot argument and then I say sep equals colon and then which means that I want to paste something together by separating them into with a colon. However, if I try to do partial matching with set, what happens is that the partial matching gets ignored, and so, when, when I say paste a b and then s e equal to colon, well, the s e is, in another circumstance might be partially matched. But in the pace function, it can't use partial batching. So it gets, it just ignores that and just assumes that colon is just another string to be pieced together. And so then you get the, the string ab:. So just be careful when you're using functions that have dot, dot, dot as an argument. That any arguments that appear after the three dots have to be named explicitly and in full. 

3 - 9 - Scoping Rules - Symbol Binding [10_32]
One topic that's important to discuss in R is a question of, you know, when a function sees a symbol in its body and it's executing inside the R environment, how does it assign a value to that symbol? So for example, take a look at this, this function here that I've defined called lm. So lm here is a function which takes its argument x, and it multiplies it times itself. So you can think of it as squaring the, squaring the input. Now, there's already a function in R called lm, so I've created an, a function here also called lm, so when I call lm somewhere else in R, maybe in another function or something like that how does R know what value to assign to the symbol lm? So it sees the symbol lm, and how does it know whether to call the function that I just defined here or the lm function that's in the stats package that's used to model, you know, to fit linear models. And so the, the idea that R needs to bind a value to a symbol. So in this case the, in the previous slide, the symbol was lm, and it needs to bind a value to it. And the value is going to be a function of some sort. It's either going to be my function or it's going to be the function in the stats package. And so when r tries to bind a value to a symbol what it does is, it searches through a series of environments to find the appropriate value. So environments are kind of, you can think of them as lists of objects and values or symbols and values. And so, when you're working on the command line, and you need to retrieve a value of an R object basically, what happens is, the first thing that happens is, you search the global environment for a symbol name matching the one requested. And so for the global environment, it's just your workspace, and it consists of all the things that you've defined or loaded into R. And so if there's a symbol there that matches the name of the one that you're requesting then it will take that symbol and, and then retrieve the value that's associated with that symbol. So in this case, I've defined lm in my global environment. And so, because that exists, if I'm working the command line, when I call lm, it's going to find that object first. So if there, if there's no match in the global environment, then what happens is, the, R will search the namespaces of each of the packages on the search list. So if you look at. So the search list consists of all the R packages that are currently loaded into R. And so you'll see that there, there's an order to the search list. So, and it goes starts at the first element, which is the global environment. That's number one on the search list. That's always number one on the search list. Now, you can see, second on the search list is the stats package, the graphics package, the GR devices package. All the way down at the very is the base package, okay? And so, somewhere in this list of packages R is going to look for a function called lm. And, of course, if it's not in the global environment, then it will eventually find it in the stats package which is the function that's used to fit linear models. So, as I said before, the global environment is always, is equivalent to the user's workspace, and it's always the first element on the search list. And furthermore, the base package is always the last element on the search list. So, clearly because of the way that the search process works in terms of going down the list of packages, the order of the packages in the search list matters. And so, and furthermore, users can configure which packages get loaded when you start up. And for, and, and users can also load packages whenever they want. So you cannot assume that there's going to be a set list of packages available or that the packages will be in any sort of order. So they can be in different orders at any time to give depending on the user has decided to do in a given session. And so, when a user loads a package with a library function, what happens is, the namespace of that package which is the environment that has all the name, all the symbols, and all those, the values for the symbols. The namespace of that package gets put in the second position of the search list. So right behind the global environment. And then everything else just kind of get pushed down one level. So so, and then the search will kind of go down, will include that new package, including, in addition to all the other packages that were originally on the search list. One thing to note is that R has separate namespaces for functions and non-functions, so it is possible to have an object named c somewhere and the function name c. Of course, in your global environment, there can only be one symbol named c. But it's possible to have for example, a vector named c, and that won't necessarily interfere with the function that already exists that's also named c. so, this leads us to the scoping rules for R. which, which is which I think are the, is the main feature that makes it different from the original S language. Since, since most of you probably did not use the original S language, maybe, this may not, this may be something of a moot point. But the point is that the, the scoping rules are, are essentially what makes R different from the original. So, what are the scoping rules? So the scoping rules determine how a value is bound to a free variable in a function. So if you're in a function there's two types of variables. There's the, there's the function arguments that are passed through the definition of the function, and then there may be other variables or other symbols that are found in the function that are not function arguments. And the question is, how do you assign a value to those symbols. And so R uses what's called lexical scoping or static scoping, and this is a common alternative to something called dynamic scoping. And so this is, related to the scoping rules is how R uses the search list to bind a value to a symbol. And, and one thing that's nice about lexical scoping is that it turns out to be particularly useful for simplifying things like specifically statistical calculations. So take a look at the following function. So, this function has two formal arguments they're called x and y. And the body of the function, basically it squares x and it adds the ratio of y divided by z, okay? So, x is clear, and y is clear, but where did z come from, right? And so, in this case, x and y are formal arguments, but this, the symbol z is what's called a free variable, because it wasn't defined in the function, in the function header. And so the question is, well, what value do we assign to z, assuming that values were inputted to the function for x and y. And so, the scoping rules of a language determine how we assign a value to something like z, which is a free variable. So if I were so this, lexical scoping, the rules in R, can be summarized by the following sentence. Which is basically, the values of free variables are searched for in the environment in which the function was defined. OK, so, think about that for a second, maybe repeat it a few times. And so, what's an environment? An environment is a collection of symbol-value pairs. Right? So, x is a symbol. And 3.14 might be its value. So every symbol has a value bound to it. And, and you can think of everything in R as being pairs of symbols and values. Right, so, a another symbol might be y, and its value is a data frame, for example. And so every environment which is a collection of these symbol-value pairs, has a parent environment. So it's kind of like the, the environment that sits on top of it would that, that it inherits from and it's possible for an environment to have multiple children. So there might be one parent environment and many children environment and so there's only one environment without a parent, and that's the empty environment. And so, when, so, R uses a lot of these types of environments. So you think of the global environment, which is your workspace that is a set of symbol-value pairs, right? So you have a bunch of things that you've created in your workspace, and they all have names. And each one of those things has an object associated with it. So they might be a vector of numerics, or it might be a data frame, or it might be a list, or whatever. And so there are all kinds of these envir, each package has a namespace, and that's like an environment. It has a bunch of symbols and values associated with it. And so what the, the key thing in R is that if you take a function and you associate it with an environment, then that creates what's called a closure or a function closure. And these closures are, are key to a lot of different types of interesting operations in R. So, if you, if you're in a function and you encounter a free variable in that function what happens? So, the first thing you look for is the function in which the environment in which the function was defined. So for example if the function was defined, if I define a function in the global environment, then the global environment is the function's, is the environment in which the function was defined. So if I see a free variable in this function, what's going to happen is that if I can't figure out a value inside the function, then I'm going to look in the global environment, because that's where the function was defined. If I can't find something in the global environment, then the search continues in what's called called the parent environment of the global environment. And so the, what happens in the usual case, if I define a function in the global environment, then the function is defined in the global environment, and then its parent environment is the next thing down on the search list. So, what happens is that you just go down the search list until you eventually find the value for this free variable. Now, it's possible to define a function outside of the global environment, and so generally speaking what happens is that a function will look for a value in the environment in which it was defined. And then it's going to look, if it can't find it there, then it's going to look for the parent environment. And then if it can't find it there the search, it will keep looking at the parent environment or the parent etc, until we hit what's called the top level environment. The top level environment is usually the global environment, however, if the function is defined in a package, then the top level environment is the namespace of that package. once, if you can't find a value there, then once you hit the top level environment, the search will continue down the search list until we have hit the empty environment. So, after the base package, for example, then we hit the empty environment. If you can't find a symbol in all these environments and we've hit the empty environment, then we throw an error saying we can't find a value for this symbol. 

3 - 10 - Scoping Rules - R Scoping Rules [8_34]
Um,why exactly does all this matter? So. It's not immediately clear. No. So typically the function is defined the global environment so that values of the free variables are just found in the user's workspace. So this is kind of the. The right thing to do is kind of what most people are expecting. If there's no, if, if there's, you can't find a value inside the function itself, you just look in the global environment. So this is the, the idea here is that you can define things like global variables, that will be common to a lot of different functions. That you might be defining in your workspace. so, but the key difference in R is that you can define functions inside of other functions. 'n so for example a function can return a function as the return value. So, in most functions they'll return a list, or a vector, or a matrix, or a data frame or something like that, but it is possible for a, for a function to return another function and then that, if that's the case then the, then the function that gets returned. It was defined inside of another function. So, it's an, the environment in which it was defined Is not the global environment. It's really the, the, the insides of this other function. So this is when things get interesting and this is when the scoping rules really have an impact on what you can do. So, I am going to define a very simple function here and often these kinds of functions come [UNKNOWN] where you might think of constructive functions. So, the idea that the function is constructing another function. So, here's what I want to, I want to create a function that that defines another, called make.power. And what make.power takes as input is a number n. Okay? So, and inside the make.power function I define another function called pow. And pow is going to take an argument called x. And and so what's going to happen is that the power function is going to take the, then the, take the argument X and raise to their power N, okay, and so make that power returns, with a function power as its return value and so you see inside the power function X is a, X is a function argument but that's not a problem, but n is a free variable because its not defined inside the power. Function. However, N is defined inside the make.power function and so since that's the environment in which the pow is defined. It will find the value of N. The pow, the power function will find the value of n inside this, it's other environment. So what happens is that I can call make.power and pass it a number like 3. And then, it will return a function, which I'll sign to be called cube. And, similarly, I can pass 2 to make that power and create a function that I'll call square. So, now, when I, when I pass cube, the number 3 What is it does is it raises 3 to the 3rd power, so I get 27. If I call square on the number 3, it, it raises three to the 2nd power, so it gives me 9. And so, so, so now, I've cons, I've got one function that can, that's capable of constructing many different types of functions, and by raising to pow, to various powers. So, how do you know what's in a function's environment? So you can, you can at the function, so, excuse me. You can look in the environment in which the function was defined, by calling the LS function. So if I call, if I call LS on On the environment for cube. You can see that inside the cube function, there's, there's something, there's an, there's an object called N. And if I use get on N you'll see that the value of N is equal to 3. So that's how the power function knows to raise it to the 3rd, to the 3rd power. Excuse me, that's how the cube function knows how to, knows to raise the argument to the 3rd power because it's already defined. In it's, in it's, in it's, closure environment. Similarly the environment for square, you can see it has the exact same objects in it. But now the value of n is equal to 2, in the square function. So, so, I want to make one brief comparison between lexical scoping, which is what R does, and dynamic scoping, which is what maybe some other function, some other programing languages implement. So here I've got, I'm assigning the value of Y equal to 10. Then create a function F, which takes, as an argument, X. And then, it assigns, there it assigns Y equal to 2, it squares Y and then adds G of X. So, what's G? G is another function, which takes as an argument called X, and it multiplies X times Y. So, in the F function, Y is a free variable, and G is also a free variable. So, the G function is not defined. Inside of F of or, it's, it, of, argument to F. Then in the G function, then the var-, the symbol Y is a free variable. And so the question is if I call f of 3 what gets returned? So with lexical scoping, the value of Y and the function G is looked up in the environment in which the function was defined. Which in this case was the global environment. So that the value of Y and the G function is 10. So with dynamic scoping the value of Y is looked up in the environment from which the function was called; sometimes called the calling environment. So in the R the calling environment is known as is what's called the parent frame. In this case the calling environment Y was defined to be 2 and so the value of Y would be 2. So. Calling the function F would produce different answers depending on whether you use lexical scoping or dynamic scoping. So, the one thing that, that, that will make lexical scoping and dynamic scoping look the same is that when a function is defined in the global environment and is subsequently called from the global environment, then the defining environment and the calling environment are exactly the same and so this can sometimes give the appearance of dynamic scoping even when It doesn't exist. So here I've got a function called G. It takes an argument X. It assigns A to be equal to 3. And then it adds X plus A plus Y. So, in this case, X is a function is a formal argument. A is a local variable so it's not a formal argument, but I defined it inside the function. Then so, that's okay. And then Y is a free variable, okay? So if I call G of 2, the function G is going to look for the value of Y in the global environment. If I haven't yet defined Y then there has to be an error because it doesn't know what value to assign to the symbol of Y. So that's what I get in this line here. Now if I define what Y is, say I assign it to be 3, if I call it G of 2, then it returns 8 because now it's able to find Y in the global environment. So even though it looks like the value of Y was looked up in the calling environment, it's actually the defining environment because G happened to be defined in the global environment so, there are a number of other languages that support lexical scoping. Some examples are things like Scheme, Perl, Python, and Common Lisp. And of course there's a, a well known computer science theorem which is that all languages eventually converge to Lisp. And so it's, it's not a, it's not an obscure type of feature. It's actually very common in a number of other programming languages. So, one of the main consequences of lexical scoping in R is that all the objects have to be stored in memory. So, if you're working with a programming language that has very small objects this generally speaking not a big problem. but. Because of nature of the scoping rules and because of the complexity of the environment and the, the way they are all linked together, it's difficult to implement this type of model outside of physical memory, and so. So the consequence was that, when R was originally designed. Everything was stored in memory. Things are getting complicated now, because of very large types of data sets. And, being able to read them into R. It is a challenge. Everything has to be stored in memory. Second now, so every function has a carrier pointer to its respect, to its defining environment. and, and that defining environment could literally be anywhere because there could be functions within functions and then the, and if you do, if one function returns another function, then there has, there has to be a pointer to that piece of memory where the defining environment is stored. And so this makes the model a little bit more complex but but, but all the more useful. So, the, in S plus, which was kind of the original implementation of the S language, the free variable were always looked up in the workspace. Everything could be stored on the disk, because the defining environment of all the functions was the same. 

3 - 11 - Scoping Rules - Optimization Example (OPTIONAL) [9_21]
So far, we've talked about functions and the scoping rules in R, and you might be wondering why any of this information is at all useful. So, in addition to just writing regular functions for manipulating data or for doing calculations, there's one combination of the scoping rules and functions which can be very useful in statistics, and that's for optimization. So there are a few optimization routines in R called optim and nlm and another one called optimize. And they all require that you pass a function to those functions, whose argument is vector parameters. So for example there's going to be some function that you want to minimize or maximize. and, over range of parameters, and functions like Optum and lmand take, take that kind of objective function, and try to find the minimum or the maximum. so, the idea is that, but in statistics this objective function that we're trying to minimize or maximize, just like a log likelihood, is going to depend on other things, besides just the parameters that you're maximizing over. So, for, in particular, it's going to depend on things like data. And so, the question is, well, how do you specify a function. Depend, depends on parameters and data and perhaps many, many other things. In a clean, way and to, to write it in a, in a, in kind of readable programming style and make it easier for the user to kind of use these types of functions. And so. And further more, when you're doing these kinds of optimizations in many cases it's useful to hold certain parameters fixed and for example, fix a parameter to a certain value then optimize over the other parameters. So, the basic idea with any optimization problem in r is you can create a contructor function which constructs the objective function. And then once the ob, and the objective function idea, that idea is that it would have all of the data, and all of the other things that it depends on would be kind of included in the defining environment of that function, so that it would kind of carry along those other things like baggage, you know, in its, in its enclosing environment. And so that way you don't have to specify those things every time you call the function. The only thing that you need to specify is the value of the parameter. So, for here I've got, I've written a constructor function that creates a negative log-likelihood. So just as a note, most of the functions in like optim and anolam and optimize and, in R, they all attempt to minimize functions by default. And so when you write your objective functions if they're designed to be maximized, then you have to kind of take the, the negative of those functions so that you can minimize them. So another thing is that all the code in this example all, will be on the website so you can take a look at the code and try to run it yourself if you want. So here I've got a constructor function that's making a negative log-likelihood because I want to minimize the negative log-likelihood function. So this is my objective function. It's going to depend on some data and so that's the argument. So the data is the first argument to this make.makelike function. The second argument is a logical vector called fixed and it determines whether or not I want to have, want to fix some of the parameters. So, now ins- inside the constructor function I have to find another function which is it takes an argument called p for the parameters. And this is going to be the parameter vector that I want to optimize over. So basically what this function's going to do is going to return log-likelihood for a normal distribution and I'm go- I'm going to want to fit my data to this normal distribution. And so we know that a normal distribution has two parameters, the mean, mu, and a standard deviation, sigma. So those are going to be the two parameters that I want to optimize over. And so here I'm just defining, the law of likelihood, and taking the negative of it, so I can minimize it. And, what, what the constructor function does is returns the function as the return value. [NOISE] So, here I'm going to simulate some normal random variables, mean 1 and vari, and sorry, mean 2. And, and then I'm going to make my constructor function, I'm going to call my constructor function with these random variables. And create my NLL or Negative Log Likelihood function. So,when I print out this function here,you will see that it, I see the body of the function looks like the code for the normal distribution.Its just like in the construction function before, but if you look at the environment, you will see this little tag that at the bottom that says environment. And that's the enclosing environment for this function. And so normally because when you define a function in the global environment, that it would just you, there wouldn't be a special environment tag down here. However, when you define a function inside of another function that and there has to be a pointer to the, to that defining environment so that R can remember kind of what the values of all the free parameters are going to be. And so, if you look at, this, this is, 0 x 16 5 b 1 a 4. That is the hexadecimal of. A number which gives the address of where the defining environment is located in memory. So if you look at the body of the nl function here, you'll see that pretty much everything here is either a local variable or its a param-, it comes with a parameter vector p. However, there was one argument, th-, sorry, there's one variable here, the data variable, which is not an argument to the function And it's not a local variable, so it's a free variable but the data come from the make neglog like functions or constructor function which originally pass the data to that. And so the data can be looked up in the environment that the function is defined and it knows what the data are, you don't have to tell what the data are it's already fixed in the function. So if you look at the environment for this negative log-likelihood function by calling LS, you'll see that the the data variables there. The fixed variable there which indicates which parameter should be fixed, and then there's also the params variable there. So those are all. Those three things are all free variables. Inside this negative log likelihood function, but they're defined in the defining environment. So now I can call optim on my NLL function and I'm going to pass some initial values for musing to zero and sigma to one, and it'll run and you'll see that when it optimizes the function the estimates turn out to be 1.2 for muand 1.78 for sigma. So pretty close to the truth, remember, which was one and two. Now I could, if I wanted to, I could fix sigma to be equal to its true value and then just optimize over mu to get the mean, and so when I call make. So I need to reconstruct my optim, my objective function by calling make.neg log like, and here I set the fixed variable to be false from U. And then two for Sigma. So I'm setting Sigma to be equal to two, and I'm letting U be three. So here. Now I can just call, optimize, because optimize will minimize the function of a single variable only. And because I only have a single variable in this, function, I can use, I can use optimize. And you can see that it, it, it estimates made to be about 1.21 so slightly different from the previous optimization. I can also fix mu to be one and try to optimize over over sigma and but in order, in order to do that I have to construct another function for optimization call optimize on that. Here I get my f cent of sigma to be about 1.8. If I want, I can plot the likelihood, or the log likelihood, and this is very easy to do when I have a function that doesn't depend on a lot of other parameters. So here I'm going to make the neg, the negative log likelihood. I'm going to fix mu to be equal to one and I'm going to plot the negative log likelihood as a function of sigma. And so I construct my function here, in LL. I I construct a sequence of grid values for the X coordinate, and then I apply my NLL function to all those grid points, and create my Y variable. So, now I can just plot this as a, as a, I can plot the Xs and the Ys and connect the dots using the type equal to L. Similarly I can plot the negative likelihood as a function of the mean by fixing sigma to equal to two and letting mu vary. And similarly, I create another grid of points another set of grid points and I evaluate at the NLL function on those grid points and then make a plot. So, the nice thing about lexical scoping in R is that, if you're doing minimization or optimization of some sort, you can build these objective functions, which contain all the necessary data, and all the other kind of bells and whistles that are required, to evaluate that function. Into the closing environment of the function. So that when you call the objective function, you don't need to specify the data, and all those other things every single time. They're kind of built in to the environment and they'll be automatically looked up in the right place. So you don't have to carry on these long argument lists. That in order to evaluate the function every single time. So this can be very useful for interactive work, and for exploratory work like for example making these plots. And this can so the code for these types of functions can be very simple and kind of clean because you don't have to carry on these large argument lists. So just for reference, the main reference for this type of Lexical Scoping rules of R, is the paper in the journal Computation and Graphical Statistics called Lexical Scope and Statistical Computing, and Robert Gentleman and Ross Ihaka who created R, have some very nice examples in this article. 

3 - 12 - Coding Standards [8_59]
Coding standards in R are really important becasue they help you, make your code readable and allow you and other people to understand what's going on in your code. Now, of course, just like it is with any other, style whether it comes, when you, you know, whether it's your clothing or whatever it is, it's difficult to get everyone to agree on one set of ideas. But I think there are a couple of very basic, kind of minimal standards that are important when you're coding in R. Alright, so I'm just going to talk a little bit about some of the coding standards, that I think are important to, when you're writing R code, and I think will help make your code more readable and more usable by others if that's what you're trying to, to achieve. So, the first principle that I think is very important in pretty much any programming language, not just R, is that you should always write your code using a text editor and save as a text file. Okay, so, a text file is a kind of basic standard. It usually doesn't have any sort of formatting or any sort of, kind of special, appearance, it's just text, right? And usually, typically, typically it's going to be ASCII text, but if you're, on, in places outside the US or the UK using non-English languages there may be other standard text formats. But the basic idea is that a text format, can be read by pretty much any basic editing program. These days, you know, when you're writing something there's a lot different of tools that you can use to write. If you're writing a book, or or a webpage or something like that, there's all kinds of different tools that you can use to write, to write those things. But you're, when you're writing code, you should always try to use a text editor, because that's like kind of like the, the kind of least common denominator, and it makes it so that everyone will be able to access your code and improve upon it. The second principle is, which is very important for readability, is to indent your code. So indenting is something that's often hotly debated in lots of mailing lists and other types of discussion groups in terms of how much indenting is appropriate. Now I'm not going to talk about that although I do have some recommendations. But I think the most important thing is that you understand why indenting is important. So indenting is the idea that different blocks of code should be spaced over to the right a little bit more than other blocks of code so you can see kind of how the control flow how the flow of the program goes based on the indenting alone. So coupled with indenting, is the third principle which I think is very simple which is, limit the width of your code. So you have indenting it's possible to kind of indent off to the right forever so you need to limit on the right hand side how wide your code is going to be and usually this is kind of determined by the number of columns of text. And so one possibility is you limit your text to about 80 columns of text and then and so that your, the width of your code never exceeds that. So, let's take a look for, at a quick example here. So here you can see I've got R Studio open, here with a simple code file with some R code in it. And, first of all, let me just mention that the editor in R Studio is a text editor. So it will always save the R files that you write as text format files. So, so we've already got that kind of handled. But you can see the indenting scheme here is equal to one space. So every indent is one space. And you can see that all the code is kind of mashed together here on the left hand side. It's difficult to tell kind of where the if blocks are. Where the else blocks are. Where does the function kind of end and begin? And so the indenting scheme kind of makes the code not very readable in this case. So we can change the indenting in R Studio. If we just go up to the Preferences menu here. And go to Code Editing. And let me just change it to four. And you can see that the column, the margin column is set to 80 characters, so it will show you the margin when you've reached 80 characters. And so I'm going to select all here with Cmd+A, and then Cmd+I to indent it. So now you can see that the indenting is a little bit nicer now. You can see, kind of, where the function begins and ends, you can see where the if blocks start and end, and the, kind of, structure of the program is much more obvious. So, I'm going to change this one more time though and my, because my personal preference for indenting is to use eight spaces, so I'm going to change this to eight. Hit OK, and select all. Cmd+I. And now you can see, I prefer the eight spaces just because it really makes the structure of the code very obvious. And the spacing is nice and clear. And it makes the code very readable in general. So you can see that indenting is very important. And the biggest problem you might have is, with the, with, with too little indenting. If you don't indent at all or if you only use a very small amount the code becomes kind of very mashed together. So I recommend at least four spaces for an indent and I'm pref, I prefer, you know, eight spaces for an indent, just because it makes the code much more readable and spaces it out much nice, much more nicely. One of the advantages of having something like an eight space indent, is coupled with an 80 character margin on the right hand side, is that it forces you to think about your code in a slightly different way. So for example, if you have eight space indents, if you're going to have a for-loop, nested within another for-loop within another for-loop, every time you nest another for-loop, for example, you have to indent over eight spaces. And by the time you get to maybe your fourth nested for-loop you're pretty much hitting the right hand column at the 80 column margin, right? And so the nice thing about the eight space indent, coupled with the 80 column margin, is that it prevents you from kind of writing very basic, making very kind of fundamental, kind of mistakes with, with code readability. So, for example, with an eight space indent and 80 column margin, you might not be able to do feasibly more than two nested for loops, and, but I think that's really the, kind of, the boundary of what is readable in terms of code. Typically except for some special cases, a three, you know, a three nested or four nested four loop is difficult to read, and it's probably better off, you know, splitting off into separate functions or something like that. So a good indenting policy not only makes the code more readable, but it actually can force you to think about writing your code in a slightly different way. And so that's a really nice advantage of, of having a logical indenting policy with, coupled with a, you know, a right-hand side restriction. Alright. So the last thing I want to talk about is to limit the length of your functions. Alright so, functions in R can, can theoretically go on for quite a long time and of course just like in any other language but just like in any other language I think that the, the logical thing to do with a function is limit it to kind of one basic activity. So for example, if you're function's named read the data. Then your function should simply read the data, it should not read the data, process it, fit a model, and then print some output, alright? So you should, the logical kind of steps like that, should, should probably be spit, split, into separate functions. There are a couple of advantages to doing this. First of all, it's nice to be able to have a function written on a single page of code, so you don't have to scroll endlessly to see, you know, where all the code for this function goes. If you could put all the function, the entire function on like one screen of the editor, then you can look at the whole function and see what it does all at once. Another advantage of splitting up your code into logical sections, to logical functions, is that if you use functions like traceback, or the profiler, or the debugger, these often tell you, you know, where in the function call stack you are when a problem occurs. And if you have multiple functions that are all logically divided in to separate pieces then when a bug occurs and you know that it occurs in a certain type of function or a certain function then you know kind of where to go fix things, right? So if you have, but if just have a single function that just goes on forever and a bug occurs then the only thing that the debugger or the traceback or the profiler can tell you is that there's a problem in this one function. But it, it doesn't, it, it's difficult to tell you where exactly the problem occurs. So splitting up your functions has a secondary benefit, which is that it can help you in debugging and profiling. So limiting the size of your functions is very useful for readability and for, kind of, debugging. Of course, it's easy to go overboard and having, you know, a hundred different three-line functions. So that's not really what you want to do. So you just want to make it so that the, the separation of different functions into, is logical, and that each function kind of does, does one thing in particular. So those are my basic guidelines for writing code in R. There are, of course, many other things that you might be able to think about. But then we start bordering into areas that we might, we might kind of disagree on. And so I'm not going to talk about too much more in terms of coding standards, but the basic ideas are always use a text editor, always indent your code, I'd say at least four spaces. Limit on the right hand side how, how wide your code can be. And and always limit the size of your functions, so that you can, so that they're, kind of grouped into logical pieces of your program. So with those four things, I think you'll, your, your code will be much more readable. It'll be readable to you, it'll be readable to others, and it'll make kind of writing R code much more useful to everyone. 

3 - 13 - Dates and Times [10_29]
I want to talk briefly about dates and time in R, which is a very, is a very special topic and could require a lot more time. And I have something I need to talk a little bit about how R represents dates and times, and how you can use them in kind of ara, arithmetic and data analysis types of computations. [NOISE] so R has a special way to represent dates and times. And they're, they're represented using special data classes. So, in the past, we talked about different data types like lists. And character vectors. And, numeric vectors, and so. This is just another type of data on top of those kinds of classes. So dates are represented by the date class. and, times are represented by two separate classes: the POSIXct and the POSIXlt class. So dates are basically. Don't have times attached to them. They represent a day, in a year in a month. And the, kind of, you can figure them in a kind of a year, month, day format so for example, this date is 1970, January 1st and so internally the dates are stored as the number of days since 1970 January 1st. That particular detail is not very important but in case you're wondering you don't know how they, how the, how R actually does calculations based on dates. Times are stored internally as the number of seconds. Since 1970, January 1st. And so, that's, again, another underlying detail. That's not very important, but it maybe useful to know, sometimes. So, the way dates in R, in R work, is you can take a character screen. Like this following 1970-01-01. And convert it into a date, using as.Date function. That's probably the most common way that you'll start your, begin working with dates. And, you'll notice that if you print out this object. You'll get something that looks like a character string. Now it's not actually a character string but it will print out that way because there's a special print method. Now if I unclass the object here you'll see I get the number 0. Remember? Because the dates are stored internally as the number of days since 1970, January 1st and since. 1970 January 1st. 0 days from that point. You'll get 0. If I. If I input January 2, 1970, then you'll see that underline is represented as a number 1, because that's 1 day after 1970 January 1st. If you had a. If you had a date that was before 1970 Then, they'd be represented as negative numbers. so, but that's just for your little background. You don't, you don't have to worry about the underlying representation. Ultimately, what you need to know, is that dates are stored as objects of the date class. Times, on the other hand, are represented as two possible types. One is called POSIXct and the other POSIXlt. So, POSIX is a family of computing standards for how things should be done on certain types of computers or how data should be represented and so there's a there's a family of standards for how to represent dates and times and pos and so POSIX a that's part of the POSIX standard. So [COUGH] in the POSIXct class. Times are represented at just as very large integers. And so it's a useful type of class if you want to say, store times in a data frame or something like because it's basically it's like a big integer vector. POSIXlt stores a time as a list. underlying, and so, and it stores a bunch of other useful information about a given time, for example what's the day of the week of that time, what's the the day of the year, the day of the month, or the month itself. And there are a number of generic functions that operate on both dates and times. That you can use such as the, so the weekdays functions tells you what day of the week a given time is or a given day is. The month function tells you what month that date or time is. And the quarters functions gives you the quarter number. So for example, quarter Q1 would be January through March, Q2 would be April through June, etc. like that. So, these generic functions operate on, on objects of class. POSIXct or POSIXlt or date. So, so, for example, you can, you can, you can coerce things back and forth between POSIXlt and POSIXct. If you want, using the as.POSIXlt or the as.POSIXct function. so, for example the Sys.time function here, just gives you the current time. As it's known by the system. And you can see that when it prints out, it prints out in a year month day format. And then an hour minute second format. And then the, the timezone, which is Eastern Standard Time right now. [COUGH] So you can convert this di to a POSIXlt using pa, as.POSIXlt. And, POSIXlt remember underlying is a list. So you can look at the names of the elements. In this list if you unclass it and you can see that there's an element called seconds that's the seconds and the minutes the hours the M days the day of the month which in this case would be 23. The month is just the month your in so that's a January and then the year. The weekdays or the day of the week. The year, day, which is the day of the year. And then are we on daylight savings or not? [NOISE] So, if I extract the sec, seconds element of this list, you'll see it's 11.86. And so that, and so this actually gives you the seconds in in fractional seconds. So, it's 11 seconds and then .86 seconds. So, that's, that's the number of seconds in the time. The POSIXct format you can see is you can also get it from the sys.time function and you can see that if I un-class the POSIXct object. I get this very large integer, because that's just the number of seconds since January 1, 1970. Now if I try to apply the list operator, the dollar sign to this object, you see I get an error because objects of POSIXct don't have these list elements in them. You want to get those list elements out you have to convert it to POSIXlt using the as.POSIXlt function. Then I can get the seconds out. In this case it's 11.88 seconds. So, finally there's a strptime function which converts dates which are written in character string format into date or time objects. Well, in this case it converts into two time objects. So and they use what are called format strings. So here I've got a string that says January 10th, 2012 and then 10, 40 meaning hour 10 minute 40 and then I have another string that said December 9th 2012. 9, 10. So if I want to convert these strings to time objects I can use the strptime function, what I do is I pass the character vector and I pass it a format string. So in this case I got, and so you'll see how these present signs fall by letters. And then you can, you can look-up what these symbols mean in the help page for strptime. So present B means the month. In an abbreviate [UNKNOWN] name, %d is the day. Then comma and then %Y is the four-digit year. Then %H is the hour, sort of like colon followed by %M which is the minute. And so that's the format. Of the, of the times here. You can see that after I call [UNKNOWN] I print out X, I get these time objects that are formatted, that are printed out in the standard format. When I look at the class of this object you'll see it's in a POSIXlt format and so that's the so you can look at so that's the underlying kind of list format here. Now I personally can never remember what those formatting strings are the %B ,%D, %Y I can never remember what those are and so I always have to look at the help page for [UNKNOWN] to remember what those details are. Now, once you've got data in the date or time format, you can, you can do operations on them, which can be very handy for example, you can you can add and subtract dates, you can compare dates, you can see is, is one date less than another date or are these two dates equal to each other? So, but the end you need to be careful that you can't always mix different classes. So for here, I have X which is a date object, then Y which is a POSIXlt object. If I try to subtract the two, you'll, you'll get an error because they're not the same, type of object. So I can, can, but if I convert the date to a POSIXlt object so I can do as.POSIXlt on it, then if I take the difference it'll say that the, the difference of 356.3 days between the two. The nice thing about the date and time operators is that they keep track of very tricky things like leap years, leap seconds daylight savings and time zones. So just, this first example here, you can see that so 2012, it was a leap year and so there was a February 29th. And so the difference between March 1st and February 28th is actually a difference of two days, not a difference of one day like it is every other year. Similarly I could take two times one which is in my, X which is in my kind of current time and then Y which is in the time zone of GMT, so Greenwich Mean Time. And take the difference between those. So even though it looks like it should be a 5-hour difference, it's actually only a 1 hour difference because of the change in the time zones. So one of the advantages of using the date time classes is that it will automatically take care of these kinds of irregularities. So that was just a quick sum, kind of overview of the, the dates and the time classes in R. So just to summerize there are special classes in R that will, that represents dates and times that'll allow you to do numerical and statistic calculations. dates, date, class, times use either the POSIXct or POSIClt class. And then character strings can be coerced to either a date or a time class, using the strptime function or as.Date.as.POSIXlt, and POSIX, as.POSIXct. The other thing to note, that I haven't really talked about here is that a lot of the plotting functions, will recognize date time objects. So when you try to plot An object that, that's a date time class. It will recognize that object and then format the X axis in a special way so that it will have a time element to it. So you might want to try to experiment with that a little bit to see how plots change when you use a date time class. 

4 - 1 - Loop Functions - lapply [9_23]
Loop functions are some of the most powerful functions in the R language and they make it kind of very easy to use, especially in an interactive setting. The idea behind a loop function is you want to execute a loop over an object or a set of objects in a way that's kind of that does a lot of work in, in a very small amount of space. That way, you don't have to type as much on the command line. Of course, we already learned about loops. We know about for loops and while loops, things like that, and those are all, work very well; however, they are com, less compact in a certain way. So, there are a couple of loop functions in R and they usually have the word apply in them somewhere. So some of the key ones are lapply, sapply, apply, tapply, mapply and the real workhorse function that I, that I'd like to talk about here is lapply. And the idea behind lapply is that you have a list of objects and you want to loop over the list of objects and apply a function to every element of that list. And so it's a very general concept. And it can be used very powerfully to do a lot of computations in a few, in just a little bit of typing. Sapply is a variant of lapply that simplifies the results. Apply is a function that operates over the margins of an array. So, this is very useful if you want to take summaries of matrices or other or, higher dimensional arrays. Tapply is short for table apply. And, it applies a function over subsets of a vector. And mapply is a multivariate version of real of lapply. So I'll go into details about how these work in a, in a, in a minute. There's also another function called split which doesn't actually apply anything to objects. But it's often useful in conjunction with functions like lapply or sapply because it splits objects into sub-pieces. So, lapply. Lapply takes three arguments. Basically the first argument is a list which is called X. The second argument is a function or the name of a function and then there are other arguments that are, can be passed to the dot dot dot argument. And the dot, dot, dot argument is used to pass arguments that go with the function that you're being, that's being applied to each of the elements in the list. If X is not a list, then you will be coerced to a list if possible. If it's not possible to coerce the object to a list, then you will get an error. So the lapply function, you can see, is very simple. The code for it is right here. Basically the func we look for the function if it's, if the object is not a list then it's coerced to a list using as.list and then the, the rest of the Lapply function is, is,is implemented internally in C code to make it a little bit faster. So the idea with Lapply is that you're going to take this list of things. And remember a list can contain any, any number of different types of objects. So they could be vectors, or matrices, or data frames, or whatever it may be and you want to apply a function to each one of these elements of the list. And that function is going to return something. It may not be the same thing that it originally was on the list. So, for example, it may take as an input, as a vector, but then it may return a scalar as a result. So, the function's going to return something for every single object in that list, and the return values are going to be assembled in a new list. And that's what lapply is going to return. So lapply, it's key to remember, it always returns a list. What goes in may or may not a list but it will be coerced to a list. And what comes out will always be a list. So here's a simple example. I'm creating a list of two elements, the first one's called A, and it's a sequence from one to five, the second one is called B, and it's it's ten or more random variables. So what I, and then, what I want to do is I want to loop over this lists of two elements and apply the mean function to each of those elements. So you can see that when I call Lapply on x and I apply the mean function I get another list back, w-, and notice the list has the same names as the original list, a and b. But now I've got the mean of the first element and the mean of the second element. And so that's how lapply works. Here I've got a slightly more complicated list. I've got four elements and I've got, I'm calling lapply to each of those elements and I'm getting the mean of each of those elements. So, now I've got a list with four elements. The names are preserved and notice, of course, you know, each of the elements of the original list was a vector of some, of a numeric vector of some sort. But what I'm getting back is a vector with just a single number in it, for each element of the list. So, here's another way I way to call, lapply. Here I'm creating a sequence one, of x, 1 to 4, and I'm calling runif, so, which generates a uniform random variables, to, using a random number generator. Now, the first argument to runif, is the number of uniform random variables that you want to generate. So if I say runif 1 it's going to generate a single random variable. If I say runif 2, it's going to generate a vector of two random variables. So, here I'm applying l, the runif function to sequence 1, 2, 3, 4. So, what I'm going to get is a list where the first element is a single random number random uniform. The second element's going to be a vector of two random uniforms. The third element's going to be a vector of three. And the fourth element's going to be a vector for random uniforms. And so ret, you'll note, if you know the runif function, you'll know that it has other arguments to it beyond the, the number of uniforms to generate. But those other arguments have default values so I don't need to specify them. Now, suppose I want to call the runif function on each one of these elements of X but I didn't want to just generate a uniform between zero and one which is default. Suppose I want to generate a uniform between zero and ten so now I need to pass some arguments to the runif function which are not the default values. In particular I need to change the max value. So I can do that through with lapply by passing these arguments through the dot dot dot argument. So here I'm calling lapply on X, I'm calling the run, I'm passing the runif function, but that I'm specifying that I want the min to be zero and the max to be ten. So now when I the, the list that I get out of this has random uniforms that are between zero and ten. So lapply and the associated functions make heavy use of what, of what are called anonymous functions. Anonymous functions are functions that don't have names, so you don't assign them a name of some sort but you can kind of generate them on the fly. So here is a just a quick example, I'm going to create a list that contains two matrices in it. The first is a mat, a two by two matrix and the second is a three by two matrix. So you can see the list here. There's two elements. They are named A and B. And suppose I want to, I want to extract the first column from each one of these matrices. So what I can do is I can call lapply so, there's no function that, out there that already extracts the first column of a matrix but this is easy to do. You can just write a function that just takes the first element, the first column of that matrix. So here I'm going to call lapply on x. And I'm, I'm going to write, I'm going to write the function right here, so I'm going to say function, and then I'm, I'm going to give it an argument, and then given that argument, I extract the first column. So here, when I call Lapply with this function I get the first column from A, and the first column from B. So this function doesn't exist except within the context of Lapply, and after the Lapply function is finished, the function basically goes away. So that's an anonymous function, because it doesn't have a name and lapply and a lot of these other types of functions use anonymous functions very heavily. Because unless there already exists a function that does the operation that you want to do, you're going to have to write the function kind of on the spot. So sapply is just a variant of lapply and all it does is it tries to simplify the result of lapply if possible. So recall that lapply always returns a list but sometimes you don't want a list, sometimes you just want something different. So for example, if the, if the result is a list where every element is a length 1 then what sapply will do is it'll return a vector of all,of all, of all those elements. Usually you don't want an ele, a list where every, where every element is a single number, for example, and so sapply will simplify that into just a vector. if, if the result is a list where every element is a vector of the same length. For example, if the, if the list comes back and every element has a length five, for example. Then what sapply will do it'll, it'll put those elements in a matrix that's, that's five by however long the matrix, the, the list is. So that, that's often what you want to happen. But if it, if it can't figure out how to simplify the object when it comes back, for example, if the object has many different types of things that comes back then it's just going to then it won't do anything. It will just return a list. So here in this, in this example when I called lapply and I applied the mean to everything what happens is that I got a list back that's of length four and every element of the list is a single number. So it would make, it would be a lot nicer if I just got my list back that was just, I'm sorry, if I just got a vector back with all these numbers in it. And that's exactly what sapply does. So sapply called on x with the mean function gives me a vector with four numbers in it. Of course, if I called mean on the, on the list by itself, that's not really going to work because mean is not meant to be applied to lists. And so you'll get a warning message of n a back. 

4 - 2 - Loop Functions - apply [7_21]
[BLANK_AUDIO] The apply function is another loop function that's used to evaluate a, a function over the margins of an array. Usu, usually, the function's going to be an anonymous one, like we showed with lapply or it could be a function that already exists like the mean, for example. It's usually used to apply a function to the rows or columns of a matrix. Of course, matrices which are two dimensional arrays, are going to be the most common type of array that we're going to use in R. But you may have three dimensional arrays and such. But you, so you can use apply on general arrays such as taking the average of an array of matrices, for example. One thing to note, and you may hear this out in the wild, occasionally, that apply, using apply is somehow better than ta, using a for loop or somehow it's faster than using a for loop. And that's, generally speaking, not true. It was true a long time ago in older versions of the S language in R but right now, it's not true at all. The main reason you want to use a function like apply is that it involves less typing. And less, less typing is always better, because good programmers are always lazy. So, apply is very useful, but in particular on command line, because on the command line, when we're interacting with data, we're doing exploratory analysis, we want to do as little typing as possible because it just makes our fingers tired. So, how does apply work? So the first argument acts as an array. An array is a vector that has dimensions attached to it. So a matrix is a two dimensional array, for example. A margin, which, which we'll get to in a second. This is a vector, an integer vector that indicates which margin should be retained. And the last important argument is the function that you want to apply to each of the margins. So, and then the dot dot dot argument are other arguments that you want to pass, include other arguments that you want to pass to the function. So here's a matrix that I'm creating, it has 20 rows and ten columns. so, in, in, in the matrix it's just normal random variables that I've generated. So when I apply, so what I want to do is, I want to take this matrix and I want to calculate the mean of each column of the matrix. So the way I can do this is I can apply, use the apply function on x. I give it the margin, two, and I'll say what that means in a second. And I pass the function, mean. And so what happens is, I get back a vector of length ten that has the mean of each of the columns of the matrix. And so the idea is that, so the matrix has ten, sorry, it has 20 rows and ten columns, and so that you can think of the matrix as, as, and so dimension one has 20 rows and dimension two has ten columns. So, when you apply the function, mean, over the matrix, well, the idea is that you want to keep the second dimension, which is the number of columns, and you want to collapse the first dimension, which is the rows. So that, so the idea is that you're taking the mean across all the rows in each column, and then you're, and you're essentially limiting the, the rows from the array, so what you get back is actually has the, has one of the dimensions has been eliminated. It's really the first dimension that's been eliminated. And so you get this number which this vector which has each of the means for each of the columns. similarly, you can take the means of all the rows of the array. And I can, I can call the apply function on x. I give it the dimens, the margin, one, which means preserve all the rows, but collapse all the columns. And then I, I, here I'm calculating the sum of each the rows, instead of the mean. So the, so, I cast the one because it says I want to, I, because of what I mean is I want to preserve the rows and collapse the columns. So here, I got a vector of 20, because there's 20 rows. And each, and inside each and for each row, I calculate the sum of that row. Now for, for simple operations, like calculating the sum, or calculating the mean of a column or a ma, or, or, of a row there are special functions that are highly optimized to do this very quickly. So for calculating the row sums and row means, there's the functions rowSums and rowMeans. And similarly, there's colSums and colMeans, which do the same things for the columns. These are equivalent to using the apply function, but they're very much faster than using the apply, because they're optimized to specifically to do those operations. So if you want to calculate the sum or the mean of a, of a column or row of a matrix, use those functions instead. Now you can, you know, use the apply function to apply other types of functions. For example, suppose you have a matrix. Here, I've generated, again, a matrix of random normal variables, that's 20 rows by 10 columns. And suppose I want to go through each row of the matrix and calculate the twenty-fifth, and the seventy-fifth percentile of that row. So, I can apply on x I, I get, I pass the margin of one, because it means I want to preserve the rows. And then I'm going to pass it the quantile function. Now the quantile function needs, needs, the quantiles that you want to calculate. So there's no default value for that, so I actually have to pass it to the quantile function through the dot dot dot argument of apply. So here, the argument for quarntile is called probs. And I, and I give it 0.25 and 0.75 meaning I want to calculate the twenty-fifth percentile and the seventy-fifth percentile. So what this funct, what this call does is, it goes through each row of the matrix, and for each row, it calculates the twenty-fifth and seventy-fifth percentile. So there's, so for each row, there's going to be two numbers that are returned. And what apply will do is, it'll create a matrix that has two rows, and the number of columns is equal to the number of rows in this matrix, which happens to be 20. So here, I'm going to get a 2 by 20 matrix, where in each column of this return matrix, I've got the twenty-fifth and the seventh, seventy-fifth percentile for the corresponding row. So, for example, in the first row, the twenty-fifth percentile is minus 0.33 and the seventy-fifth percentile is mi, is 0.92 and in the sixteenth row the seventy-fifth, the twenty-fifth percentile is minus 0.95 and the seventy-fifth percentile is 0.88. So you see how that works. Now, suppose I had more than just a matrix. Suppose I, I had an array that I want to do something with. So, the so, here, I'm creating an array with, which has normal random variables and it has two rows and two columns and it's ten and the third dimension is ten. I guess I'm not sure what you would call that dimension. But you can imagine this. You can think of this as being, the, they're a bunch of 2 by 2 matrices that are kind of stacked together. And the idea is that, you can imagine I have a be, a bunch of 2 by 2 matrices, and I want to take the average of those 2 by 2 matrices. So, the average of the, of a bunch of 2 by 2 matrices is going to be another 2 by 2 matrix, which is the mean. And so, I can call apply on this array... And I want to keep the first, and the second dimension, but I want to collapse the third dimension. So here, when I, when I give the margin, I give it one and two, which I want to preserve, and then three is not there, which means I want to collapse third dimension. So here, and then the function I pass it is the mean. So, what this will do is, it'll take my array and it'll collapse, it'll average over the third dimension and give me the mean matrix. Another way that you can do this is to use the rowMeans function, so even though this is in a matrix, you can apply rowMeans to an array. And you give it, and you pass the argument, dims, equal to two. 

4 - 3 - Loop Functions - mapply [4_46]
mapply is a loop function that tries, is a multivariate version of the kind of lapply and sapply functions that you've seen previously. And the idea is that it applies a function in parallel over a set of different arguments. So one thing we have noticed about the previous functions, lapply, sapply, tapply, is that, they have only, they only apply a function over the elements of a single object. So, for example, if you think about lapply, the input to lapply was a list. A single list, that is. And then the function was applied over the elements of that list. So, what happens if you have two lists that you want to apply a function over? And so, and suppose you have two lists, and the elements of the first list go into one argument of the function, and the elements of the second list go into another argument of the function. So lapply and sapply can't really be used for that purpose. So one way to do that is just to write a for loop, where the for loop will index the elements of each of the different lists, and then you can pass a function to each of those elements of the list. Another way to do that though is with mapply, where mapply can take multiple list arguments and then apply a function to the, to the elements of those, of the multiple lists, in parallel. So the function arguments for mapply are a little bit different, just because it has to allow for the possibility of a variable number of arguments. So here, the first argument to mapply is the function that you want to apply. And the function that you're going to pass to mapply has to have, the number of arguments that the function takes has to be at least as many as the number of lists that you're going to pass to mapply. So the list that, the things that will be coerced to a list, will be passed through the dot dot dot argument. And so if you have three lists, you'll pass three objects and then your function has to take at least three arguments to it. So, the more args, argument is just if you have more arguments and you need to pass to your function. And a simplified argument is similar to the simplify arguments that you saw in sapply and also in in tapply. So, here, for example, I'm creating a list here, and the list has, I'm going to repeat 1 four times, the integer 1 four times, I'm going to repeat 2 three times, I'm going to repeat 3 two times, and repeat 4 just once. So it's a little bit tedious to have to type something to do, even though this is a fairly artificial example, but with mapply, it's actually quite simple. I can just do mapply rep, so, rep is the repeat function And then, repeat, it has two arguments, so, the first set of arguments is going to be 1 through 4, and the second set of arguments is going to be 4 through 1, and you can see that in list above here. The first argument was 1, 2, 3, and 4, and the second argument was 4, 3, 2, and 1. So, that's, so those are the two sets of arguments that I'm going to pass to mapply. And you can see that when I do that, I get my list of four 1s, three 2s, two 3s and one 4, just like the list that I have above here. So mapply is, can be used to apply a function to multiple sets of arguments. So, here's just another very simple function. It just generates some random normal noise. And these, and, see, the rnorm, the, the, I'm sorry, the function has three arguments the, the number of observations the value of the mean, and the value of the standard deviation. So, if I just apply noise to, with a single set of arguments, 5, 1 and 2. I get 5 random normal variables with the mean 1 and standard variation 2. However, this function doesn't work really correctly if I pass it a vector of arguments. So, now what's happening is, I get a vector of 5, here. When I pass it 1 through 5 and 1 through 5. But, really what I want to happen is to have one, one random normal with mean 1, two random normals with mean 2, three random normals with mean 3, etc, and then five random normals with mean 5. And, so that's what I get here, when I use the mapply function onto the and if I vectorize this noise function I give it, you know, three sets of arguments, so it's 1 through 5, 1 through 5, and then 2. So I, I'm always going to fix the standard deviation to be 2, but I'm going to be changing the n and I'm going to be changing the mean. So now I've got one random variable with a mean 1, I got two with mean 2, three with mean 3, four with mean 4 and then five with mean 5. So that's how I can instantly vectorize a function that doesn't allow for vector arguments. So this is the same as, as I were to manually type out a list with these five different function calls. So this way, it's, it's nice to be able to instantly, kind of, create a function that doesn't allow for vector inputs and to and to kind of instantly vectorize it. 

4 - 4 - Loop Functions - tapply [3_17]
[BLANK_AUDIO] Tapply is a very useful function and it's used to apply a function over subsets of a vector. So the idea is basically, imagine you have a vector usually it's going to to be numbers, so a numeric vector. And there are, there are pieces of this vector that you want to calculate a summary statistic over. So and so you, you're going to have to have another variable or another object which identifies which element of this, of your numeric vector belongs to which group. The idea is that for each group in the numeric vector you're going to calculate a summary statistic like a mean, or a standard deviation, or whatever. So the basic idea behind tapply is that the first argument is a numeric vector or a vector of some sort. The second argument is, is another vector of the same length which identifies which group each element of the numeric vector is in. So for example, suppose there are two groups suppose you have men and women, for example, in two groups, and maybe the first 50 observations are men and the second 50 observations are women. Then you need to have a factor variable which indicates, you know, which, which observations are men and which, which are women. And so if you want to take the, the, the mean of the numeric factor within men or within women, then you can use tapply to do this. So FUN is the function that you want to apply and so this is going to be the same as before. It's going to be the, either a function or you can pass in an ano-, an anonymous function. And then the dot, dot, dot contains the other arguments that may go to this function. And then the simplify argument indicates whether you want to simplify the argu-, simplify the results, kind of like the sapply simplification. So, here's a very simple example. I'm simulating a vector of normal random variables and uniform random variables and, and there's ten normals, ten uniforms, then ten normals that have a mean of one. So you can think of this vector as having three groups. So then I'm going to create another factor variable using the gl function, and its going to be, this factor variable going to have three levels. And each level is going to be repeated ten times. So when I print out the factor variable here, you can see that there's ten ones, ten twos, and there's ten threes. So each, so that the factor variable indicates kind of which group the, the observation is in. So now I can, I can, tapply on x, pass it the factor variable f in the mean function, that allows me to take the mean of each group of numbers in, in x. [BLANK_AUDIO] If you don't simplify the result, then what you get back is going to be a list. So so tapply applied for the same numeric vector and factor as on the previous slide. I want to calculate the mean and say simplify equals false then I get back a list with three elements and e in each element is the mean of that subgroup. I, I can pass at slightly more complicated summary statistics. So here, instead of calculating the mean, which, which returns one number I'm going to calculate the range of observations. So this gives me the min and the max of the observations within that subset of the vector x, and so here I'm getting a list where each element is a vector of length 2. 

4 - 5 - Loop Functions - split [9_09]
Tapply is useful because it splits up a vector into, into little pieces and it applies a, a summary statistic or function to those little pieces, and then after it applies a function it kind of brings the pieces back together again. So so split is not a loop function but it's a very handy function that can be used in conjunction, with functions like lapply or sapply. And so I just want to mention it here. So split takes a vector. So it's kind of like tapply, but it, but it's like tapply but without applying the summary statistics. So what it does, is it takes a vector, or an object x and it takes a factor variable, f. Which again identifies levels of a group. And then it splits the object x into the number of groups that are identified in, in factor f. So for example, if f has three levels identifying three groups, then the split function will split x, into three groups. And so, and then once you've got those groups split apart, you can apply, you can use lapply, or sapply to apply a function to those individual groups. So here is, is a simpler example, similar to what I had before. With tapply example, I've simulated a normal 10 normal random variables with mean zero, 10 uniforms, and 10 normal's with mean one. And has created my factor variable here. And now I'm just going to split the vector into three parts. Because because the factor variable has three levels. So now you can see when I split the x vector. The first, I got a list back and the first element is 10 normals, the second element is 10 uniforms and the third element, which gets a little cutoff here is 10 normals again. So that's what the split function does. And now I've got a, so a split always returns a list back. And so if you want to do something with this list, you can use lapply or sapply. So, here for example, it is common to use the lapply function in conjunction with the split function, so the idea that you split something that lapply function over it. Now, this case, this use of lapply and split is not necessary, because you can use the tapply function which will do the same exact thing. It's not anymore efficient or any worse to do it this way but the tapply function is a little bit more compact. But the nice thing about the split, using the split function is that it can be used to split much more complicated types of objects. So for example, here I've got a data frame for. I'm loading the data sets package and I'm, and I'm looking at the airquality data frame, from the data sets package. So, you can see that this is the first six rows of the data, of this... Data frame I think there's about a hundred some rows total in this data frame. And you see there are measurements on ozone, solar radiation, wind, and temperature, and then the month and the day within that month. And so, one thing I might want to do is, is calculate for example the mean of ozone, solar radiation, wind and temperature in, within each month. So, so for in each month, there's you know, 30 some observations. And I want to calculate the mean within each month. All right, so how do I do this? Well, what I'd like to do is I'd like to split the data frame into monthly pieces. And then once I've split data frame into separate months, I can just calculate the means, the column means using either apply or call means, on those other variables. [SOUND]. So that's what I've done here. What I've done is I split the airquality data frame and this, and the factor I'm going to use to split is the month variable. So the month variable technically speaking, in the data frame is not a factor variable but it can be converted into a factor variable, because it only takes the values 5, 6, 7, 8 and 9. Basically because the measurements are only taken in the, kind of, warmer months of the year. So here I've split the airquality variable according to the month variable, and then I'm going to apply. An anonymous function and the anonymous function here, what it does is it takes the column means of just the ozone, solar radiation and wind. So I'm not going to take the mean of temperature here. So I'm just going to take the column means of the, those three variables for each month each column monthly data frames. So here you can see the results. You can't see them all but you can see most of them into lapply is returning a list back, where each element of the list is a vector of length three which is, which is the mean for ozone, the mean for solar radiation and the mean for wind, within that month. As you can see that for, for most of the months the ozone value is NA and that's because when I take the mean of that column there are, and there are missing values in that column and I can't take the mean if there are missing values. So the, the result, when I think the mean is that I just get a missing value back. So one thing I can do is I can. So before I fix the missing value problem, I can also call sapply here. And the idea is that sapply, instead of returning me a list, it will simplify the result because each element of the returned list has a, has a vector of length 3. They're all the same length. So what I'll do is put, put all these numbers into a matrix. Where the three rows and in this case 5 columns. So here you can see the monthly means. For each of the three variables, in a much more compact format, it's in a matrix, instead of a list. Of course I still got NA's for a lot of them, because the missing values in the original data. So one thing I knew is I was going to pass the na.rm argument to call means that would remove the missing values from each column, before its calculating the mean. And that, now when I call sapply on the split list, I can get the, the means of the observed values for each of the three variables for each of the five months. So, so split is a very handy function for splitting arbitrary objects according to the levels of the factor and then applying any type of function. To those split elements of that list. And so here I split a data frame, you can split other lists, you can, and, or other kinds of things too. [SOUND]. So the last thing I want to talk about is splitting on more than one level. So you, in the past couple of examples what I've, I've only had a single factor variable. And I've split whatever the object is with a vector or a data frame. According to the levels of that single factor. But you might have more than one factor. For example, you might have a variable, that, you know, it's gender, so it has male and female. And you might have another variable. That has, for example, the race. And so, you might want to look at the combination of the levels within those factors. And so so here, we've got, I've got f1, which is a factor with two levels. And so I've simulated a normal random variable with 10, with 10 observations. I've got a factor with two levels, and each repeated five times, and then I've got another factor with five levels. If repeated two times. So there are my kind of two category, two group, grouping variables here. And I want to look at the kind of combination of the two. So I can use the interaction function to combine all the levels of the first one with the, all the levels of the second one. And so because there are two levels in the first factor and there is five levels in the second factor and there is a, the total combination of 10 different levels that you can have when you combine the two together. So when you see, when I call, when I called the interaction function I get another factor, that kind of concatenates the levels of one with the other, and you can see that it prints out that there is a total of ten levels. Okay. So, what now I can slit my numeric vector x according to the two different levels. So now, when I Iike, when I use, now one thing, when I use the split function I don't have to use the interaction function. I can just pass it a list with the two factors and it will automatically call the interaction function for me, and create that 10 level interaction factor. So I can just pass the list of these two factors in it, and you can that, it create, it returns me a list with the levels of the 10 different kind of interaction factor levels. And then and then, and then the elements of the numeric factors that are within those 10 levels. Now of course there are, although there are 10 levels between the two different factors, that we don't exactly observe every single combination. And so there are some empty levels here and you can see that some of these levels have nothing in them. They have zero elements, whereas other levels have a number in it. And so, so one thing you can do. Well first I can, I could take this list and, and, and lapply or sapply a function over it, if I wanted to. But, sometimes it's a little bit handy to not have to keep these empty levels. So, so the split function has an argument called drop. And if you specify drop equals true, it will drop. The empty levels, that are created by the splitting. And, and this can be very handy, when you're, you're combining, multiple different factors. If you're only using a single factor, then doesn't, that argument doesn't really do anything, because you'll just use all the, all the levels but, usually. But if you have multiple factors then typically you're going to have empty levels, just because you don't observe every single combination of the two factors. So, so drop equals true will drop those empty levels and then you can have, you'll, you'll will be returned a list, with only the levels, that have observations in them. [SOUND]. 

4 - 6 - Debugging Tools - Diagnosing the Problem [12_33]
[MUSIC] Alright, so so today's lecture is about the debugging tools that are built into R. So these come with R. They're not part of any package and they can be useful for kind of figuring anything out, figuring out what's wrong after you've discovered there's a problem, right. So how do you know that there's a problem? So, there are a couple of indications that R, will produce that that will give you the sense that there's something going on. And they kind of, and this is the, roughly the gradient. And so I think I mentioned this before. But, basically there are three main types of indications. The first is a message. And a message is a very tame notification. It's just an in, it could be a diagnostic message that something happened. But it could, it could be nothing. Okay? And and so the message won't stop your function from executing. It will just it will print. There will be a message that gets printed to the screen and the execution of the function will continue and that's all. The next level up is the warning. All right? So the warning is another indication. Usually, if you're writing a function, you are choosing, you're trying to figure out, okay, what's a message and what's a warning. furthermore, or if you're using a function and you're figuring out well what does that mean, a warning is an indication that something unexpected happened it's not necessarily a problem, and may, and many times you, you, you explicitly want to ignore warnings but there's something unexpected happened. So the function was expecting one thing, and it got something slightly different. It wasn't enough to kill the whole thing, But it was enough to kind of trigger this warning. So execution of the function will continue if a warning occurs but you'll get a message after the end, so once you'll get a message when the function completes execution. So when the function comes back, when you get your console back, that's when the warning appears. So you won't get a warning in the middle of the execution. By default. So this is, these are generated by the warning function, sorry I should say the messages are generated by the message function. And then an error is the last stop, right? So an error is a fatal problem. This stops execution of the function. And and these, and error messages are produced by the stop function. So and then there's a general notion of a condition. Which is it's the higher level concept. It can, all three of these things are, are conditions. And so you can, you can imagine that, and so it, you can create new conditions if you wanted to. So if you have, and generally you're not going to be doing this at this level but if you have a, a, another type of of, condition that you want to, kind of trigger when something, when a special thing happens. So it's not an error, it's not a warning, and it's not a message. You can create your own conditions and and using some of the functions that are available. So we won't be doing that now, but there is this notion of a condition and it's, it's generic. So this is your basic warning, right? You take the log of a negative number. You can't do that, right? Now notice that you get a value back. It's a NaN, right? Not a number. And, but you also get this warning which occurred after the execution of the function. And it just says that in the log of minus 1 NaNs are produced, right? So this is your typical and, and sometimes that's fine. Because maybe you're taking a log of a bunch of numbers and maybe some of them are negative, but you don't really care and then you're going to make some sort of plot or something like that. So so this is the kind of thing where you probably wouldn't want the function's behavior to just stop anytime it sees a negative number because sometimes these things just happen. You get negative numbers on occasion and you want to take the log anyway. So so that's a warning. Now I've got a little function here that I've created. It's very simple it takes your input. It checks to see if it's greater than zero. If it's greater than zero, it prints a message saying x is greater than zero. [COUGH] If it's less than or equal to zero, you get a message saying that it's less than or equal to zero. So very handy function I'm, I'm sure you'll all be using soon. and, and then last I want to mention this part here. So invisible is a function that that, that stops or I should say prevents auto printing. So normally when you, if I if I'm at command line and I type a function, remember the, and I execute a function the, the function will return the last element of, that's in its function body, right? So if the last sum in this function body is like is numeric vector, it will return that numeric vector. Now what happens is that if you just execute the function, that numeric venture, vector will be automatically printed to the console because it got returned by the function and R will use auto printing to just print that to the console. If I call invisible on the return object, then it will still return the same object but it won't, it wont do the auto printing. So you can call the function and the object will be returned. But there won't be any auto printing. So a, a, a, a, an example of a function like this is the load function. So we haven't really used that much, but the load functions loads objects from what, from a saved work space, so it's like the opposite of of save, right? and, but when, and when it loads the objects, it actually returns a character vector containing the names of all the objects that it loads. But that doesn't get printed to the screen and because, it's, it's returned invisibly. Okay. So if you have a function that returns something invisibly then the return, what happens is that the object that gets, that gets returned by that function doesn't get printed to the console and so sometimes you want that to happen and sometimes you don't. Sometimes it doesn't matter. So here I've, I've just added this here just so I can, you know, tell you about it. It's not particularly important. But actually, the print, actually I should say that any print function here actually all print functions will return the string that it prints. Okay. So when you say print X, what gets returned is a string, X. Right? But you don't actually see that, because it, the, the, the, the return value is, is, is returned invisibly. Right? So it actually. So, so, so, so you could assign the output of print to, like, an, an object. But you. Generally speaking, you never do that. So, anyway. That was a little diversion on invisible. So here I, I create my printmessage function, and I call printmessage(1), great. No problem. I get the message x is greater than 0. Okay. So and so what does printmessage return, just before I go on? Printmessage returns its argument, alright. And so actually, if I had assigned print, the output or printmessage to some other object, it would be the number one in this case, right. Even though it didn't printout the number one anywhere. So now, I'm going to pass it directly an NA, right. And and, and we're going to get an error here because you can't make the comparison if NA was greater than zero, it's not defined, right. And so it doesn't know what to do it can't move on. It, and so it has to error out. Okay, so you get an error saying that in this expression if X is greater than zero the missing value, you, you have a missing value where, so it was expecting true or false and instead it got NA, which is neither true or, nor false. Right, okay. So something happened there that's wrong. Now, I'm going to to fixed this problem so to speak. I've got a new function print message two and the first thing we are going to do is I'm going to check to see if the argument is NA, right? So, now I if it's NA, I'm going to print this message, right. So it's not going to produce an error, it's just going to print, print a different message. So this function's going to print one of three messages for now and then it's going to return its argument, invisibly. So when I call this, so now what, so what's something that might typically happen? Well I, I calculate the log of minus 1 and I assign it to X. So that doesn't stop anything. I just get a warning, and I move on, all right? Now I'm going to printmessage on x, and I'm getting x as a missing value, right? So, now that, now there's no error there but it's, it may be unexpected, right? Because maybe I, I, I, maybe I thought that, okay, well the thing that I'm inputting into printmessage2 is, is like some positive number, so I thought I was going to get the message X is greater than zero. But instead I'm getting this message x is a missing value. So what happened right? So um,this is the kind of thing where where what you thought you were going to get, where your expectation is different from actually kind of what the function produced, right? And so all I'm trying to say here is how do you know when something's gone wrong, right? And sometimes it's easy to tell like in the case where you got the error message. But sometimes it's not easy to tell because here there's no error but it's not exactly what it, what I was expecting, okay. It's when you, when you're looking at a function, you think something's gone wrong, there's a couple questions you want to ask yourself. To see whether there something actually is wrong, or maybe, or is there is something we call user error, okay? So what was your, so the thing about when you're kind of thinking about, when you're debugging a function you want to answer all these questions as you're going through your process here. So what was the input that you put? What, what did you feed into that function? Okay, not what you thought you fed into that function, what did you actually into that function? Okay, so I thought I fed that function a positive number but in reality I fed it a, a NaN. Alright, so how did you call the function? What are were the arguments that you gave? Things like that. What were you expecting? So you, and this is important when you're asking someone for help, or you're asking someone a question. I can't just, it's not that useful to say oh the printmessage2 to function didn't work. How do you know it didn't work, alright? Because, and then you say, well I was expecting this, but I got that, okay? That's how you know it doesn't work. And then, someone could say, well you shouldn't have expected this, because that's not what that function does, or you know, or something like that. But or you can say, okay, here's the problem. So what were you were expecting is then very important to be able to articulate at least to yourself and maybe to other people. What was the output that you were expecting, were the were you expecting some message that you didn't get? Or other results, other numerical results, things like that. So what we're expecting, and then of course, what did you actually get? How do, how did what you actually get differ from what you're expecting? And then of course were expectations correct in the first place? So, if you were expecting something that was, that was in fact incorrect then your notion of what is correct and incorrect is now being challenged, right? So an important, and another key aspect of debugging of course is you have to be able to reproduce the problem, right? Because if you can never reproduce the problem, you'll never have a chance in figuring it what went wrong, because it only happened that one time, right? So this is very, very, very, very important. And unless it's a very I mean unless it's like the most basic problem. And I can't even say what that would be. You have to be able to reproduce the problem. You know, because you have to be able to show someone this is how I created the problem. Because most people are not going to know if you just show them the output of the error message, or what that means, or where it came from or how you got there. Okay, so the process by which you encounter the error or the problem is very important. So you, you have to know how to reproduce the problem. There are some problems, and so when I was talking about, for example, when in random number generation you need to set the seed because it may be that only under a certain sequence of random numbers that a problem occurs. And, if you're not setting the seed, you will never be able to reproduce that problem, because every time you run it, it's going to be a different set of random numbers. There are other types of problems that can be hard to reproduce. They, and, but they're more complex. They're usually, for example, if you're writing networking co, networking functions, you know, something, so you're doing like parallel programming, often, those kinds of problems can be very hard to reproduce because they depend on activity in other machines and things like that. You can't really reproduce that. Things that, if you're getting code over the internet, and so if you're getting data over the internet, and your code is kind of interacting with things in the web, that can, problems there can sometimes be hard to reproduce because servers on the other side may change or whatever. And so you, you can't always freeze things in time. If it's something that's just happening on your computer it's usually going to be easier to reproduce the problems. so, unless, I mean only under very esoteric circumstances, circumstances will it be hard to reproduce a problem on your computer. 

4 - 7 - Debugging Tools - Basic Tools [6_25]
so, what are the tools that R comes with to help you to debug a program? Right, so there are five basic functions and a few associated ones that I want to talk about. But the first most basic one is the traceback function. Okay? Now, one thing I want to say, you can get pretty far in R without using any of these functions. I actually, I worked with R for like six years and didn't even know these functions existed so, and So, I'm, I'm not saying that you necessarily have to, that you will always be using these functions, but they're actually quite handy in some, some cases. So, the traceback function, what does is it prints out what's called the function call stack. So you know, typically when you call a function, you call, you call the function and that function calls another function, and then that function calls another function, and it's like, and then you're four functions deep, and then maybe the error happens way down here, right? And so, traceback just tells you how many function calls you're in and where the error occurred, right? And so you can try to identify where in the sequence of function calls the error occurred. Otherwise, all you know is that you called one function and then an error occurred. But you've no idea, you know, how many other functions are called underneath. So the traceback function will tell you that, and I'll give you an example. So the debug function is probably the handiest function. It, what it does is it, as you give it a function as an argument, and it flags that function for debug mode. Okay, what debug means, that anytime you execute that function, anytime, anywhere even if another function calls it, it will, it will halt, it will suspend execution of the function at the first line, and then you can, in what's called a browser. And I'll show you how this works and then you can step through the function line by line. And then you can see you can execute one line, one expression at a time, I should say inside the function. So you can try to pinpoint, okay, if there's a specific line of code when the error occurs, you'll be able to find out which line that is, okay. The browser function's relativity to debug in the sense that you can stick the browser, the browser, of, of call to the browser function anywhere in your code, and then when that, when that line of code gets hit, when that browser call gets hit, the execution of the function will suspend, okay? And then you can, and then you can go line by line from there. So sometimes, for example, you don't, the debug function by the, will always start the, start the debugging, start the browser right at the top of the function. But sometimes, you kind of want to run through the beginning and then stop it somewhere in the middle. And so, so the browser function allows you to stick the browser call anywhere in your code and then it will run the function up until that point and then suspend it. So so that, so there, those two are obviously related. The trace function allows you to insert debugging code into a function without actually editing the function itself. and, and this is handy if you are debugging someone else's code. Right, so for example, there's code in the package or the, and you can't easily edit the code in that package, or there's code in the base R itself or there's you know, something like that. And you don't want to go and edit that code, because you can't find the file, or whatever. So, you can use the trace function, just insert a little snippet of code, and using that snippet is just a call to the browser function. And then and, and then, and then you can kind of browse through that function, and then you can turn the trace off, and it's, and the function's back to normal. So that, and then the recover function is the last function. It's actually, I should put it up here, it's related to the traceback. What recover does, so normally when you get an error you get, you usually get a message saying what the error was and then the, and then you get, and then the console kind of comes back to you. And then you can start, you can just enter more commands, you can do whatever you want. But execution of that function stops and you get the console back. What we were, that's the default behavior. You can change that default behavior by, by, by creating what's called, or setting what's called an error handler. And recover is an error handler function which means that any time you encounter an error, anywhere in a function, rather than getting the console back the R interpreter will stop the execution of that function right where the error occurred, and will kind of freeze it there. And then it will print out the function call stack, so you'll see how far deep you're in, and then you can go, you can kind of jump around to the different function calls to see, and to look around. Now you're in the browser, and you can look around in the different function calls to see kind of, okay, what happened here, and happened here, what did the, how did data get corrected here and things like that. It's a little hard to talk about in the abstract so I'll give you the example. So there's also, so these functions kind of allow you to pick apart the kind of the details, the lines of code and try to figure out, okay, nail down where exactly the the bug may be. You can also just put things like print, and cat, statements in your code to print out things. So if you want to know, well what's the value of x at line 42, you can just print it out, right, and then see what it is. And you can get a lot of mileage out by just putting in print statements. The only problem with print statements and things like that, is that you often you'll put in like a lot of these, it's a long piece of code, you'll put in like 40 print statements. And then you're like, okay, I'm ready to go. And then I go back through and, like, delete all the print statements. So that's, that can be a little bit kind of a pain, but you know, there's nothing terribly wrong with it. Some people I've, I've, that I've worked with are actually against, they like, oppose the use of debugging tools. I've ever software engineer company many years ago and there was an engineer there who was, he, he was opposed to any debugging tools. He'd never used a debugger. All he did was print and you know, print statements basically. And because he thought that the use of the debugger encouraged bad habits, right? So, what do you, and it's true. I've seen it happen in other places. Where you just write some code. I don't care how it's going to work. I'm just going to run it. If there's a problem, I'll just run it through the debugger. Right, and I'll just step through line by line to find out what the problem was. And, and it encourages kind of a sloppy code development process because you know that if there's a problem you can just step through execution with the debugger. And I have to say, that's probably not a good habit to get into. It's probably better to think about your code, write it in, in a kind of intelligent way and then if there's a problem resort to the debugger. But I use the debugger all the time. I use the browser function, I use all these functions all the time. So maybe I just have bad habits but that, that memory is burnin' my mem, mem, burnin' my brain for some reason. 

4 - 8 - Debugging Tools - Using the Tools [8_21]
Let's take a look, I'll just give you a couple examples and then I'll move to the actual [UNKNOWN] just so you can see things. So here's the mean. I took the mean of x, x doesn't exist. So if you take the mean of something that doesn't exist you're clearly going to get an error. Here it says so you get the error message this is produced by the stop function. And I call the traceback. It tells me where the error occurs. Well the error just occurs like right away at the top of the mean function. So that, so the function mean didn't actually call any other functions, right because it couldn't because it couldn't figure out, it couldn't evaluate your argument. And so, that's where the error occurs so, you know that may or may not be. Many times that's just that is where the error will occur at the top level function. so, that in that case the trace-back's not very handy. One thing that's useful to, that, that the trace-back is useful for, is for when you're communicating with someone else over email, for example, me. And you say, you know I get an error when I call, you know, whatever function. Its very useful if we just say use the trace-back, when I get after I get the error. And then I can see okay, wha, what was the list of function calls, I mean. Unless the trace-back looks like this, then near dud bug, but when you're communicating with someone about an error and a function, its very handy just to print out the trace-back, so that they can seek out where the error occurred in the hierarchy of functions. You have to call traceback immediately after the error occurs. If you execute some other code and then call traceback it's not going to work, right? Because the traceback will only give you the most recent error. If you execute another function and there's no error well then there's no traceback to give because there's no error in the, in the next. ex, execution. So you have to you've to call it right away. Here's a slightly more interesting trace back so I call it LM, which is the linear modeling function. I said y tilda x. So y tilda x. They don't exist. And so I'm getting an error that says y cannot be found. Were to that error occur? Well actually it occurred several levels deep actually. So here I called L M and the L M arrow function is a little funky. So I don't expect you to understand all this but L M called e val on what's called a mono frame. Then that, it's then and then that called e val again which called the model frame function which called the model frame default. Model frame is a generic function that called a model frame default function. Then it called the eval function again on this. And then, the and at the seventh level, here. That's where the error occurred. Okay. So and it basically it occurred because it tried to evaluate my formula here. Which is y tilda x. That's what all e val calls are for. And and it couldn't. And when it evaluated the formula it couldn't find the actual value of y and x. So then, that's where the error occurred. So printing out something like this can be very useful. If you're trying to get help from someone else and you're, and you're, and you're kind of trying to debug your function together, okay? So so that's the traceback, there. The debug function doesn't really work well in the static format like this, but I'll show, I'll just show you that, but But, basically I could debug the l m, so you can debug any function, doesn't matter if you wrote it or not. So I can debug the l m function, and now when I call l m y fill the x it you get this debugging in and I'll give you the the expression that you called. And I'll first thing it will do is it will print out the entire code of the function, so this is a lot longer than so I just I just put I just cut cut it off in the middle here but the first thing it does is it prints out the whole function body code okay. And then you get this little prompt at the bottom here the browse [UNKNOWN] so now you're in what's called the browser. Okay? And the browser is just like your r workspace, actually. you, you can think of it like a work space embedded within a work space. Right? So, and but, but the elements of the workspace. Are, sorry, so the environment of that workspace in the browser is your function environment. So the things that are in your function are what are in your environment. So at, at the very top of this function you just actually, there's nothing in your environment except for the function arguments, right. So what are the function arguments? Well, the first one is the formula? So I have a formula in my environment which is this y tilda x, but that's it. So anyway so now I can well there are actually I should say there are other arguments so l'm too which are default values. But they are not, they are not listed there, but they do, they also, they, I shouldn't say there is more than just a formula because there is other arguments. So here what I do is I press n for next and it runs the first line. When I hit n and then enter and it runs the first line. N then enter runs the second line. N enter third. I just keep hitting n, n, n, so I run, and I just execute each line until I get to the line where the error occurs. So when you get to the line where the error occurs. And you execute it. You'll get an error just like you did before. It's not going to magically fix the problem by itself. But, at least you'll know where that error occurred, okay? So and further more, suppose you want you can debug functions within the debugger, right? So, you can I can call, if I want so, I can call. So this match.call function I just kind of stepped right over it but I could have gone into this function by calling debug on match.call before executing it and then when this got executed I'd be in the third level of the browser. Ah, so these things can nest and then as you go so they come like a stack of browser frames right? So so you can, you can, you can call the debug function on functions. While you're, even while you're in the debugger. And you can step through functions even while you're kind of debugging your top level functions. The recover function, so the you can set the recover to be this kind of error handler by using the options function. So you say options error equals recover. And, and that will set a global option, right? So now this will, this will, this behavior will curve ever, everything you do as long as your r session is open. As soon as you quit it will go away and then if you start up R somewhere else it's not going, it's not going to save that option. So now I'm going to what I'm trying to do is I'm going to read that csv some file that doesn't exist. Okay, and then you get an error and you get the error message, cannot open the connection. And you get some warning also. And now bu, but instead of getting my console back, I get a little menu here. And this menu is the function call stack, okay. So it's the same thing that you would get back, if you called trace back after the error. Right, so reed.csv is that I called, remember reed.csv is just a [UNKNOWN] for reed.tables. So Reed.csv called reed.table and then reed.table called the file function, because we wanted to create a file connection with my file, no such file. Right? And then when it tried to create that file connection. Obviously you couldn't find the file, and that's where the error occurred, okay? So the error occurred at the third level in the function call stacks, so what you can do, is you can press a number one, two, three [SOUND] and then you can kind of browse the environment of that function. So if I want to see okay, what was the read, what was going on in read.csv, I can just press one here, and then it would show me kind of the environment of the read.csv. And, and then I can break out of that and look at the environment for read.table, and et cetera. And so you can, if you have a very long function call stack, you can kind of jump back and forth to see what was going on at each, at each function call. To to try out a pinpoint kind of where the problem occurs. Okay. Okay. So so just to summarize really quickly there's, there are basically three main indications of some sort of problem or condition. There's the message warning error and of the three only the error will stop execution of the function. When you're analyzing a function that has and you think has a problem make sure you can reproduce that problem. And then you make sure you can articulate how what do your expectations and how'd and what the output are that and how the output differs from what you were expecting or [LAUGH] I'd like to say what you are expecting. And so that the, the interactive tools trace back, debug, browser, trace, and recover can be used. And it's, and the keyword actually here is interactive. The, the reason these tools are useful is because they are interactive. You can kind of do things on the console. And of course the debugging tools are not a substitute for thinking. And so you should always think about writing your code before, you know, just throwing it to the wind and hoping the debugger will catch it. 

5 - 1 - The str Function [6_08]
This video is about the most important function in all R, the str function. This function is really handy. It's really useful. I use it all the time. And you can use it in all kinds of situations just to help you out, to look at R objects. So the idea behind the str function is, is that it's suppose to compactly display the internal structure of an R object, so str, str, you can think of as being, meaning structure. So it's a very simple diagnostic function. It's very versatile. And, the idea's that it's, you can use it as, like, an alternative to summary. You want to look at an object, and see, and see you know, what is it. And, what's in it. You can use summary which will often be very useful. But str is another option. It's partic, particularly well suited for compactly displaying large lists which may contain nested lists. And also and, and its goal is to produce roughly one line of output per basic object. For example so if you give it a simple object like a vector, it'll give you one line of output backup. It will print it to the console. And so the basic goal of str is to answer the question, what's in this object? I'm going to start up R here and I'm going to just give a little demonstration of how the str function can work. So here, you can apply str to itself and see it's a function that takes an object. It can take any R object. So, so you can apply str to other functions. So let's say I want to know what the lm function does. So here, what it gives you it gives you the, the function arguments for the lm function. So just, so here you can see it's a very brief summary, you know, take the first argument's a formula, the second argument's data, et cetera. I can look at maybe ls function and it gives me, you know, what are the arguments for the LS function? So if you want to look at some data, though. Let's say I'm going to generate some normal random variables here, 100 of them, let's say mean two variant, and standard deviation four. Now one thing you can do is, is just do summary on x, and that will give you like a five number summary plus the mean. So you get the mean, median that is 25th, 75th percentiles and the min and the max. So that gives you a rough sense of kind of what the range is and how it varies. You can also call str on x and it will give you a little bit more information. So it'll give you a one line output. It tells you that x is a numeric vector. There are 100 elements. And then, and it'll give you the first five numbers in this vector. So you can get a sense of kind of what the data looked like. So you can apply str to other types of vectors. So here I can create like a factor variable. So this is the factor that has 40 levels and each one is repeated ten times so if I call str on it. And it'll give me a one line output again. So here, it tells me it's a factor. It's got 40 levels. The level, the first four of them are named 1, 2, 3 and 4. So that's not particularly interesting. And then here, I've said the first couple of elements of this factor are all in the, k-, all have the label, one. You can also call summary on a factor, and you can see that the output's a little bit different. And what this does is it, is it gives you the number of elements in each of the 40 different levels. So that's another piece of data that's not quite as compact of output as str gives you. So you can use str for other types of data types. So here, I can, I can load like a data frame. Here's the airquality data set. So, you know, if I look at the airquality data set, I can use the head function to look at the first six rows, or I can call str to get a little some different output. So here, it tells me it's a data frame. It tells me that there's a 153 observations, so 153 rows in this data frame with, of six variables and then for each variable, it, it gives me a little output. So it tells me that the name of the first variable is Ozone. It's an integer. Variable and, and here are the first could of observations. You can see there are some NAs there, so that's useful to know. The second variable is called Solar.R, and it's also an integer, and you can see the, the first couple of values. So, the Str output here is very useful for kind of just getting a quick examination of data that you might have in R and what the structure of different R objects is. We can take this a little bit farther, so for example, we could create a little matrix here. I'm going to put some random normals in there. That will be a 10 by 10 matrix. I'll call str on m. See, it will give me a little bit more information. So now it knows that it's a matrix. It'll say that it's a, it's a two-dimensional array. That it's got 10 rows and 10 columns. And here are the first couple of elements. So that's going to be the first column that you're seeing there. So if I, so if I just print out the first column here, you'll see that it, that's what it's giving me in the str output. The last thing I'll do here is create a little list by using the split function and see how str can look at the list and give a compact summary of it. So, I'm just going to take this air quality data frame And split it by the month. So here I go to airquality, going to split it by the month variable. So now if I call str on S you'll see, well there's a little bit of output that flies by. You see now this is a list, that contains five different data frames where each data frame corresponds to the data for a given month. So the months are, the data are only collected over five different months so that's why there's only five elements. So here you can see that the month, the month five, which is May has 31 observations on six variables and that's a little bit of what the data looked like. And you'll see for June, here, there's 30 observations on six variables again, same six variables, of course. And that's what the data look like there. And then for July, the data are here. And August and September. So you can see the you can have a representation of this split list that's kind of, that's not as compact as it was before but it's about as compact as you can make it and str will provide a very nice summary. You can take a quick look at the data. See if there's any problems. See if there's missing values and get a sense of what to do next. So that's the str function. I'll, I'll repeat again, I think it's the most useful function in all of R and you can use it in all cases. I encourage you to use it anytime you have an R object and, you don't know what's there. 

5 - 2 - Simulation - Generating Random Numbers [7_47]
I'm going to talk about simulation in this lecture. Simulation's a very important topic for statistics and for a number of other applications, so I just want to introduce some of the functions in R that can be useful for doing simulation. So, there are a couple of functions that are available for simulating numbers or variables from given probability distributions, probably the most important of which is the normal distribution. And so we can generate variates from the normal distribution by specifying a mean and a standard deviation for that distribution and then calling the rnorm function. So the rnorm function will simulate normal random variables that from a distribution has a given mean and standard deviation. So the, there's a cor, there are corresponding functions for the R, for the normal distribution that can be used to evaluate the probability density, to evaluate the cumulative distribution function and for also for evaluating the quantile function. So, another function for generating random variables is the rpoirs function or the, which generates Poisson random variables from a Poisson distribution with a given rate. And so, so there are number of functions for generating random variables from the, from kind of the standard probability distributions. And you can use these to do, to run simulations. So, probability distribution functions ha, there are basically four functions associated with them. And so for any given distribution like the normal distribution there will be a function that starts with the d, a function that starts with an r, a p, and a q. So there'll be four different functions for each distribution. So we've ready, I've already mentioned that there's the rnorm function. The rnorm function is for generating the, is for random number generation. There's a dnorm function, which evaluates the density of the probability dist distribution for given mean and standard deviation. There's the pnorm function, which evaluates the cumulative distribution. And there's the qnorm function, which evaluates the quantile function. So every distribution has these four types of functions. So for the gamma distribution, there'll be a dgamma, an rgamma, pgamma, and a qgamma function. And for the Poisson distribution there's the rpoise dpoise ppoise, and qpoise functions. So working with the normal distribution re, requires these four functions. So I mentioned there's dnorm, pnorm, qnorm, and, and rnorm, and you can see they each take a number of different parameters. All the functions have required that you specify the mean and the standard deviation, because that's what specifies the actual probability distribution. If you do not specify them, then the default values are a distribution, a standard normal distribution, which has mean zero and standard deviation one. For the dnorm function the, you wa you can evaluate the density. And there's an optional, there's a, there's an option that allows you to evaluate the log of the density. Most of the time, when you evaluate the density function for a normal distribution, you're going to want to use the log of that value. But the default is false. For the pnorm function and the qnorm function there's also an option to evaluate it on a log scale. but, but, but another option is to evaluate, is whether or not you want to evaluate the lower tail of the distribution. So the lower tail, which is the default, is the kind, if you think of it, if you look at the probability distribution it's the part that goes to the left. It's the lower tail. If you want to evaluate the upper tail, sometimes you want to do this. Then you want to say lower tail equals false, and that will evaluate the upper tail of the distribution. And finally for rnorm, there's only two parameters, mean and standard deviation, and an n, which is the number of random variables that you want to generate. So if n is 100, you'll get a vector of 100 numbers that are drawn from the, from the normal distribution. So just to be more explicit, if phi is the cumulative distribution function for the standard normal distribution, then pnorm is equal then to phi and qnorm is equal then to the inverse of phi. So, just to quickly, if you want to generate some random normal ren, er, variates. You can just rnorm and pass in an integer, which is the number of variables you want to generate. So here I'm passing ten. And you can see that the vector that's produced will be random, normal numbers which have mean zero and standard deviation one. If I wanted to generate a vector that had mean 20 and standard deviation two, I, I just need to specify that explicitly in my call to rnorm. So here, this vector has a, is, are, ten random normal vi, sorry, normal random variables and their mean is roughly 20 and their stand deviation is two. So when you, any time you simulate random numbers wi, from any distribution for any purpose, it's very important that you set the random number generator seed. And this can be done with the set dot seed function. So, what's important to know that on computers when you generate random numbers, the numbers are not actually random but they appear random and that's the important thing. And, if so the idea is that if you wanted to generate the same set of random numbers again, you could if you wanted to because the numbers are not actually random. They're called, they're wit, they're what are called pseudo random numbers. And so here I'm setting the seed to be one. So the seed can be any integer you want. You just pass in an integer, and that's the seed. So here I'm going to set seed equal to one. And then I'm going to generate five ra, random normal random variables. And so here I've got my ran, my five normal random variables. They have mean zero and standard deviation one. If I generate another five, you'll see that the vector is totally different, because it's another random sample of five. However if I reset the seed to be one, and I draw five again, you'll see that they're exactly the same as the first five that I drew. So anytime you, so when you set the seed it kind of sets the, the sequence of random variable that's just going to occur. And if you reset the seed, you kind of set the sequence to go back to where you started, and then it will continue to kind of generate random variables from there. so, this is important because it allows for you to reproduce random numbers that you generate. Now that might sound strange, because why would you want to, to re, generate the same random numbers twice? But in many applications you do want to generate the same random numbers twice so that people can reproduce what you've done. And particular if there are some errors or problems in what you've done, you want to be able to get, just to kind of go back to the exact situation that produced those problems. So whenever you do a simulation, you always want to set the random number c, so that you can go back and get the same results. So I've demonstrated how to generate normal random variables, but of course you can generate random variables for other probability distributions. So the Poisson distribution is of course very popular. Here I'm generating a ten Poisson random variables with the rate of one. And and so of course Poisson data are going to be integer. Here I'm generating a pois, ten Poisson random variables at the rate of two, so you can see they're slightly larger. And then here I'm generating ten random variables Poisson random variables with a, with a rate of 20. And so, so for the Poisson distribution, the mean is going to be equal to the rate. So you can see that roughly in each of these three cases, the mean is roughly equal to the rate that I specified. I could also evaluate the cumulative distribution function for the Poisson distribution. So here I'm in this first example I want to know what is the probability that a Poisson random variable is less than or equal to two if the rate is two. And so this is the probability. It's 0.67 roughly. If I wanted to know what's the probability that, that a Poisson random variable with rate two is less than four, less than or equal to four. You can see the probability's getting bigger. And here I can see the probability that a Poisson random variable is less than six. Less than or equal to six, and it's very close to one. So the cumulative distribution allows you to, to evaluate these probabilities. 

5 - 3 - Simulation - Simulating a Linear Model [4_31]
Now, we've talked about how to simulate random numbers from simple probability solutions. But the question now is how, what if we want to assimilate data from a, from a model. So for example, like a linear model. So I've got a fairly simple linear model here. It has a single predictor, x and it's going to have random noise, what I call epsilon that, that has a normal distribution with standard deviation two. There is, the outcome is going to be generated by, by, use, using these two regression coefficients around intercept beta knot and, and a slope beta one. And I've got I'm going to assume that beta knot is equal to 0.5 and beta 1 is equal to 2. So the question is, how do I simulate from this model now that I've specified what it is? So I here, at first I set the seed. It's always very important to set that seed. So I set it to 20. I generate x the predictor, which is, has a standard normal distribution. I generate epsilon, which is going to have a standard a normal distribution with mean zero of standard deviation two. And then I'm going to add them all together by, and after multiplying the regression coefficients to generate my y. And so, from the summary here, you see that y has roughly a mean of 0.68. And it ha, and it ranges from about minus 6 to plus 6. And then I can plot the data to see what they look like. And here they are on the next slide. So this is the plot of the x that I simulated. And the y that I simulated from the linear model. And you can see that they very clearly have a linear relationship according that follows the model that we specify So just a slight variation of the previous example. What if x is a, instead of x being a normal random variable, what if x is a binary random variable, so member it, maybe it represents gender or maybe it's some treatment versus control or something like that. So here, and it's very simple, I can generate binary data from the, using the binomial distribution and the rbinom function. So, I set the seed again. And I generate a 100 binomial random variables and these are going to have these, this, this if from, this comes from the binomial distribution which is n equals to 1 and p equals to half. So, the probability of one is going to be equal to 0.5. So I generate a hundred of those. And then I generate my normal random variables. My normal error term which is going to be mean zero and standard deviation two. And then I add them all together which should produce my y. So now I look at the summary of y. I see the mean is about 1.4, and the range is about from minus 3 to six or seven. So when I, now when I plot the data, of course they'll look very different, because the x variable is binary. But the y variable is still continuous, it's normal. So here you can see that there's, there appears to be a pretty clear, again, linear trend when, between going from x equals to 0 and x equals to 1. Now suppose you want to simulate from a slightly more complicated model a generalized linear model perhaps with a Poisson distribution. And so, for example, you might want to simulate some outcome data that are, that count variables, instead of continuous variable. So we have to use a slightly more complicated approach, to do this in particular, because the error distribution is not going to be normal. It's going to be a a Poisson distribution. And so, let's assume that the outcome y has a Poisson distribution with mean mu. And that the log of mu follows a linear model with a intercept beta knot and a slope beta one. So x is going to be one of our predictors. So let's assume that beta knot is 0.5. And beta one is 0.3. So how do we simulate from this model to get our Poisson on data? So so we need to use the rpois function for this. And so we first set the seed as always, and we generate our predictor variable, x. Which is going to have a standard normal distribution. Then we're going to simulate, generate our lin, linear predictor log of mu. Which is just adding the slope and this, the intercept and the slope coefficient times x. So that's the log of our linear predictor. But when we, but in order to get the mean for our Poisson random variable, we need to exponentiate that. So we, we simulate 100 of these Poisson random variables using the rpois function, and we give it the ex, the exponential of our log mean. So when we summarize this, you'll see that the mean is about 1.5 and our range is between zero and six. When I plot this data, you'll see that they look like Poisson data, and that there's clearly a linear relationship between x and y, as x increases, the count for y generally gets larger. But the data are still count variables here. 

5 - 4 - Simulation - Random Sampling [2_37]
So, the last function I want to talk about is the sample function. And the way, and the sample function allows you to draw randomly from a, a specific set of objects that you specify. So if you give it a vector of numbers, it allows you to draw a random sample from that vector of numbers. And so you can kind of create any arbitrary distribution that you want, by specifying a vector of objects and then sampling from it. So here for example, I'm going to sample from the integers one to ten. So I pass the vector of integers of one through ten. And I tell it that I want to sample randomly four of them, without replacement. So so I'm just choosing four random entries from one to ten, and here I get 3, 4, 5, 7. If I do it again, I get 3, 9, 8, 5. So in this, ex, example, I, I will, I won't get repeated numbers, because I'm not sampling with replacement. I don't have to just sample numbers, I can sample letters if I wanted to, so here I'm taking the letters. A through z, and I'm just going to sample five of them without replacement, and I just get q, b, e, x and p. now, what happens if I don't specify anything, I just give it the vector of objects. So here I'm [INAUDIBLE] passing sample the vector one through ten, and if I don't specify anything else, what it does, is it gives me a permutation of those. So here the vector one through ten is just permuted in a random order. If I call it again I get a, I get yet another permutation. So lastly, if I want to sample from one through ten but with replacement, I can specify the replace equals true argument, so now I'm sampling one through ten, I'm getting a vector of ten numbers from the vector one through ten, but because it's with replacement, I can get repeats. So, you can see I got eight, three times and I got nine multiple times. So, that's how you sample with replacement. So, that's a very quick summary of the simulation functions in r. You can draw random samples from specific probability distributions with the R functions. So r norm, r plus I'm sorry, r poiss, r binom we saw already. All the standard distributions are going to be built in that you ha, have, probably you will need. Things like the Normal, the Poisson and the Binomial, the Exponential, Gamma, etc. All those functions are built in. And you can use the corresponding r functions to simulate from them. The sample function can be used to draw random samples from arbitrary vectors, if you want to kind of create your own distribution here. And it's very important to, to remember to set the random number generator seed, anytime you simulate data in r, so that you can reproduce the results that you got, at a later date. 

5 - 5 - R Profiler (part 1) [10_39]
The profiler in R is a really handy tool for when you're developing larger programs or, or doing really big data analyses. and, and you're basically, essentially running R code that's taking a lot of time, or longer than, you know, than you want to wait. And of course that's all relative depending on kind of what you're working on and what, maybe there are some other things that you can do in, while you're running a program. But if something's taking a long time the profiler is a really handy tool to figure out exactly why it's taking so much time and how to, and to suggest kind of strategies for fixing your problem. So I'm going to talk a little bit about using the R profiler and our, and, and kind of talking about when you might need to use it. There're also some other tools that I'll talk about that'll help you kind of time your programs, time your functions, and, and so the conjunction of, of the profile with these other tools, is a really handy toolbox for figuring out how to optimize your software. So, the first question you want to ask yourself is, you know, is your code actually running slowly? And sometimes you can solve this problem by just you know, running your program then going and doing something else. But sometimes that's not an option and you need your program to really run quickly. And so profiling is a general, is a systematic way to examine how much time is being spent in various parts of your program. And it's particularly useful when you're trying to optimize your code, you're trying to squeeze, you know, a lot of efficiency out of some code, And, and a lot of times when you first start writing code it, it, it runs fine, you know, when you're running it once, and maybe you're running a small piece of, of, of a function or a small piece of a larger program, and it looks great when you're running it, it seems to run very quickly when you're doing it. But then sometimes these pieces get embedded in a much larger program. It may be a larger program is running your piece a thousand times or five thousand times, or even ten thousand times. And then your one little piece, which was running great when you were running it, is kind of slowing down everything else because it's being run ten thousand times. And so now you need to make it a lot faster because it's being iterated over a lot. And so it, if profiling can come into play when, for example if you you have a piece of code that runs great, but then when it gets embedded in a larger piece it starts, it, it, the, the it, it's speed becomes much more noticeable. So in general when it comes to optimizing your code, the, the general rule is that you shouldn't do it. And what I mean by that is that you shouldn't think about it at first. It should and, the first thing that you, you should think about, is is that, is kind of how, how to get the code to run, how to make it readable, how to make sure that other people can understand what you're doing. And because, and one of the reasons is that it's often difficult to understand, where exactly your program is spending all of it's time. And in order for you to speed up your program, you need to be able to know where it's spending it's time. And so this can't be done without any kind of, it's difficult to do this, I should say, without a formal performance analysis or profiling. And and so the basic idea is you should always design your code first, and make it so it's understandable and and then after you've got something working, then try to optimize it. and, and then the famous phrase is, you know, premature optimization is the root of all evil. If you try to optimize first the chances are that you'll introduce bugs before you even have a, get a chance to kind of get things working in the first place. Once you've decided that you want to optimize your code, though, you should, you know, act like a scientist. Just like you would in any other context, you should collect some data. Alright, so if you have a sense of, of where your program is kind of being bogged down or where it's spending all it's time, you should collect the data to figure it out, and the way you collect the data is by profiling. [BLANK_AUDIO] So, the first tool I'm going to talk about is actually not the profiler it's a very simple function called system.time in R. And what system.time does is it takes an arbitrary R expression and evaluates that expression and then tells you the amount of time it took to evaluate that expression. Now this expression could be very simple like a single function call, or could be very complicated if it have to be wrapped in curly braces. So, it could actually be a very long expression if you wanted to be. So, the basic idea is that you take this expression and it gives you the time in seconds, that was, that was needed to execute the expression. If there's an error, you know, in the code while the expression's being evaluated, then you'll get the time until the error occured. now, there's two very important notions of time when you're exe, executing expression on, on the computer. The first is called the user time and this is the amount of time that's charged to the CPU or CPUs for this, for running this expression. Okay, so this is the kind of time the computer experiences, roughly speaking. The elapsed time is sometimes called the wall clock time and this is the amount of time that you experience. It's alright, so the, the, so even though you're the user you're not the user time, you, you experience the elapsed time. And so the two different notions of time can kind of different importance depending on what you care about. So usually the user time and the elapsed time are relatively close, because the amount of time that the computer spends to do using, you know, executing your fu, your function or expression, is roughly equal to the amount of time you spend waiting for it, right. These are for standard kind of computing types of tasks. however, there are times when the elapsed time will be greater than the user time, and there will be times when the elapsed time is smaller than the user time. So in the ca, the elapsed time can be greater than the user time, so that means that you spend kind of more time waiting around than the, the computer actually spent you know, dealing with your code and the reason, if, and the idea that the c, the computer may spend a lot of time reading around for other things to happen, things that are maybe external to the program itself. And, and so the CPU doesn't actually spend a lot of time working on your code, it may be spending a lot of time on other things that are going on in the background. If the elapsed time is smaller than the user time this most commonly occurs if your machine has multiple cores or processor and is capab, and is capable of exploiting them. So this, so most of the computers these days, have at least two, or four cores or multi core machines and so this is a very common situation. However, it's not always that the compute, the program that you're running will be all to kind of exploit the use of multiple cores. In particular, R, the basic R program does not use multiple cores as of yet. However, it often links to libraries that do use multiple cores, and the most common one would be the linear algebra type of library. So if you're doing something like regression, or a lot, a lot of these prediction routines or, or matrix computations, these all involve linear algebra libraries. And many of these libraries have been optimized to use multiple cores. And so they're, they're called multi-threaded BLAS libraries or, for the basic linear algebra standard libraries, subroutines libraries and on the MAC sometimes called vecLib or Accelerate. There are more general libraries like ATLAS for AMD machines, there's ACML or ACML, and for INTEL machines there's MKL. There's also parallel processing libraries, for example the parallel package which doesn't use, which can use multiple cores but it can also use multiple computers. And so this will, will lead to, potentially lead to a program that takes more user time than it does elapse time, and I'll give an example of how this will work. So, one example when elapsed time will be bigger than the user time, is if you read something from the web. So here I'm just using the read lines function to read a web page off off, off, off a remote server. And you can see the elapsed time is about 0.4 seconds but the user time is about 0.004 seconds. So the CPU actually doesn't spend a lot of time running this code because the chunk of the time is just spent waiting for the network to, or waiting for the data to kind of go over the network and to come back to your computer. And so waiting for the, the network to kind of deal with the data coming, going there and coming back, is not really part of your program, is part of a different thing the computer is doing, and so the, the amount of time executing your program, in the case just the readLines function, is relatively small. And the second example, this is where the elapsed time is less than the user time, I've created a simple function which creates which creates a hilbert type matrix. And I calculate the singular value decomposition of this ma, matrix with the svd. So the svd function makes use of the accelerate fr framework on the Mac and, which is a multi-threaded linear algebra library. And so it can take advantage of, of the two different cores of this computer that I'm using. And so you can see that the user time was roughly almost double of the elapsed time. So the elapsed time was about 0.7 seconds and the user time was about 1.6 seconds. And the pa, and the reason is because the the underlying linear algebra library split the computation across the two cores. And so you can think about of it is, but basically the elapsed time was multiplied times two, because it was being executed on two different CPUs. So the amount of time that the user, the CPU spent working on your program was actually more than the amount of time that you spent waiting for it to come back. You can time longer expressions by just wrapping everything in curly, a set of curly braces. So here I've got a four loop here that's just generating some random normal variables. And you can wrap that whole thing in curly braces and call system time around it. And you can see that here this is a very simple expression, it's not multi threaded, there's no network activity, and so the user's time and the elapsed time are basically the same. So, this is sometimes a really handy function if you just want to take a little bit, a little piece of code, figure out how long it takes to run it and, and may kind of go through a program, maybe, expression by expression or line by line to see which parts are taking a lot of time. Now the part of problem with system time is that it assumes that you know where to look. Assumes that you know where the problem is and that you can call system time on a given expression. And so, this may be useful for smaller programs for less complicated programs where you have a very good sense of, kind of where the bottlenecks are. But the question's you know what if you don't know where to start. What if you don't know where the problems might be and where to start looking. And so you need another functioner to kind of help you along with that. 

5 - 6 - R Profiler (part 2) [10_26]
So that's the R Profiler. And the R Profiler has a function in R that's called Rprof. And it, an Rprof is used to start the profiler in R. One could note is that R must be compiled with profiler support and so it's not something that's going to built in all cases. However, and I'd say 99.9% of the cases this is the true, this is the truth, so mu, you will only, R will only be compiled without profiler support in some very cer, special circumstances. And so I wouldn't, the chances are your version of R use, it can use the profiler. The other function that's useful is the summary Rprof function, which takes the output from the profiler and summarizes it in a way that's kind of readable, because the raw output from the profiler is generally not very usable. And so the summary Rprof function is very important. It's important to realize that you should not use the system time function and the R Profiler function together. they, these are not really designed to be worked together, to be used together. So you should always use one or the other and not both. So the Rprof function keeps track, basically what it does is it keeps track of the function call stack, at regularly sampled intervals, right? And so basically it as you're function is running, it kind of goes it, it, it queries the function call stack, so how many functions you, functions that call other functions that call other functions. And it just prints it out. Basically, that's all it does is it prints out the function call stack at, at very quick intervals, so, so that every 0.02 seconds and it prints out the function call stack. So first thing you'll notice is that if your function takes less than 0.02 seconds to run, then this R, the profiler will be useless. And in general, because it will never sample the function call stack. And in general if your program is runs very quickly, the profiler is not useful. Well, and but of course that if your program runs very quickly, you probably wouldn't think to run the profiler in the first place. So it's usually not a problem. But you really need to use the profiler in situations where your code is taking much longer on the order, at least on the order of seconds. So here's just a quick example of the raw output that comes from the profiler. Now you generally speaking you will not ever use this output, but I thought it might be interesting to look at what's going on. So you can see that I'm, you, I'm just calling the lm function, which is kind of a univariate outcome and a univariate predictor. And, and what happens here, as you can see, that each line of this output is the function call stack. So you can see at the very right, is kind of the top. and, and at the very left is kind of the bottom, so to speak. And the, so the very right, you can see that lm was called, and lm called eval, and eval called eval. So I'm going from right to left here. And eval called model frame, which called model frame default, which called eval again and eval in the list. So all these functions call each other. So you can see that the function calls back goes out for the deep. As you go further in the evaluation you can see that that the function calls that changes, so at the very bottom you can see that lm called lm.fit. And if you're not familiar with the LM function, lm.fit is really the workhorse of this function, it does all the really kind of computation. And so, you, you wouldn't suspect that it would spend a reasonable amount of time in the lm.fit function. So, that kind of raw output is not particularly easy to read, so we use the sumaryRprof function to tabulate the Rprof or the output and calculate how much is spent in which function. So, the idea is that once you see that the function call stack, you know that the, that each line of the con, the function call stack is separated out by 0.02 seconds. Access the frequency which is sampled. So, given that you can calculate how many seconds are spent in each of the functions, because if it appears in the function call stack then you're actually spend, then you must be spending some time in it. So there are two methods for, for normalizing the data that you get the R Profiler. One is called by.total, which divides the time spent in each function by a total, by the total run time. And by.self, which does the same thing, but at first subtracts out time spent in functions above in the call stack. So, its important to realize that the two separate concepts here of kind of, by.total and by self. The basic idea is that by total, I, I mean, the, the normalizing by the total amount of time spent in a function gives you basically, how much time was be, was spent that that how many basically, how many times that function appeared in the calls, in the kind of printout here. And so for example, a 100% of your time is spent in the top-level function, right, so the function that you call, suppose it's lm, you spend a 100% of your time in that function, because it was at the top level. And so, but the reality is that often the top level functions don't really do anything with that's kind of important, all they do is they call helper functions that do the real work, right? So chances are if your function is spending a lot of time doing something, it's spending a lot of time in those helper functions which is just being called by this top function to kind of do, to do all the work. And so often it's not very interesting to know how much is time is spent in these top level functions, because that's not where the, where the real, where the real work occurs. All right, so you really want to know kind of how much time is spent in the top level function, but subtracting out all the low, the functions that it calls right? So it turns out that it spends a lot of time in the top level function, but even after you subtract out all of the lower level functions, then that has something that's interesting. But most of the time you will notice that when you subtract out all the lower level functions that get, that get called there's very little time it spends in the top level function. And because all the work and all the kind of the computations is being done at the lower level function, so that's, that's kind of where you want to focus your efforts. So, the, the buy.self format is, I, I think, the most interesting format to use because it tells you how much time is being spent in a given function, but after subtracting out all of the other, all of the time spent in, in lower level functions that it calls. So it gives you I think a more accurate picture of, you know, which functions are really, are truly taking up the most amount of time and which functions that you might want to target for optimization, later on. So here's an example of some output in the by.total format and you can see very clearly at the very top that 100% of the time is spent in the lm function. So the total time was 7.41 seconds for this run. And all of it was spent in lm. Of course, because lm was the top level function. But you can see that and so you can see that the second place winner was the lm.fit function. I mentioned lm.fit is where a lot of the computation occurs. And so that was three and a half seconds, so about half of the time in that function. Now, now you also see that a number of functions here model.frame, model.frame.default, eval, all these functions don't really involve computation but there is a reasonable amount of time spent within those functions, so that's kind of interesting. Now, I think a more useful output is the by.self output which kind of subtracts out any lower level function calls from, so and calculates the amount of time spent in a, it's kind of truly spent in a given function. And here you can see that lm.fit is the clear winner, because that's really where all the computation occurs. In particular, lm.fit calls, calls a four trend routine for inverting a matrix. And so, that's usually where in most large scale regression problems, that's where all the computation occurs. The next function that takes a lot of time ap, ap, apparently, or 11% of the time is the as.list function, for the as.list.data.frame method. It's not immediately clear why so much time is being spent in this, but, spent in this function, but it's maybe something you want to investigate. Because it maybe something that's not very important to the kind of core computation. for, and so you can kind of go down the list here and see how much time is being spent in various functions. And then you'll see a lot of these functions don't directly pertain to computation or kind of core computation, but they're really more kind of pertain to data, formatting of the data and things like that. The last part of the summaryRprof output is just the sample interval, so you can see how, what, what time interval the sampling took place for printing out the function call stack. So you can see, it's 0.02 seconds. And the sampling time, which is just the total amount of time that the expression took to run. This is the same kind of, this is so this is the, I think equivalent to the kind of elapse time in the system.time function. So that's a quick tour of the R profiler in R, it's a very handy tool for doing performance analysis, R code to give you some useful feedback and I find often highlights functions that you may not have suspected as being kind of time hogs or bottlenecks. And because they're not really core to the kind of, the real computation that you're working on. So the profiler can be really useful, I think for highlighting these kinds of situations and, and often finding things that you are kind of unexpected. The summary Rprof function summarizes the output from Rprof and gives you the percent time spent in in each functions. And I think the by.self kind of [UNKNOWN] normalization is the most useful for kind of highlighting bottlenecks in your, in your code. One of the, one of the implications of using the profiler is that it's useful to break your code into functions. So rather than have one massive function, it's useful to break your code into kind of logical pieces of different functions. And so the profiler can use this information to tell you where the time is being spent. So remember the profiler prints, prints out the function call stack. And if you break your code into mul, multiple little functions, the function names that you give will kind of serve as little identifiers. In the function call stack to tell you kind of where the, where the code is spending the most amount of time. So that's another little strategy that's kind of that's can be useful when you're profiling your R code. The last thing that's worth learning is that if your R code, or any other R code call C or Fortran code, this C and Fortran code is can, is like a black box. It's not profiled. You, you won't see any information about that code. All you will know is that some time is spent there, but you won't know any details about that. So overall I think the profiler is very useful. I encourage you to use it rather than just try to guess at, you know, where to optimize your code and, and just, the profiler can be used to kind of collect data about where time is being spent. 

